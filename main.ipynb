{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install tqdm  # pip install ipywidgets or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpetern0408\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "USING_WANDB = True  # Set to false if not Peter\n",
    "\n",
    "if USING_WANDB:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    # !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ConvModel' from '/home/petern/Documents-WSL/dna-ml-model/ConvModel.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dna_dataset, constants, utils, ConvModel\n",
    "import torch.nn as nn, torch.optim as optim, torch\n",
    "from tqdm.notebook import tqdm\n",
    "import importlib, os\n",
    "from datetime import datetime\n",
    "\n",
    "importlib.reload(dna_dataset)\n",
    "importlib.reload(constants)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(ConvModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip $constants.DATA_ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = dna_dataset.DNADataset(constants.ACCESSIBLE_FILE, constants.NOT_ACCESSIBLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sequences 525688\n",
      "num accessible 47239\n",
      "num not accessible 478449\n",
      "example entry 0\n",
      "label 0\n",
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "# ensure the DNADataset is loaded properly\n",
    "print('total sequences', len(full_dataset.sequences))\n",
    "print('num accessible', full_dataset.accessible_count)\n",
    "print('num not accessible', full_dataset.not_accessible_count)\n",
    "i = 0\n",
    "print(f\"example entry {i}\")\n",
    "item = full_dataset[i]\n",
    "print(\"label\", item['labels'])\n",
    "# print(item['sequences'])\n",
    "\n",
    "# ensure dataset was shuffled properly\n",
    "# check that not all the accessible labels are at the front\n",
    "for i in range(full_dataset.accessible_count):\n",
    "    if full_dataset[i]['labels'] != constants.ACCESSIBLE_LABEL:\n",
    "        print('shuffled')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446835 78853\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "full_size = len(full_dataset)\n",
    "val_size = round(constants.VALIDATION_SPLIT * full_size)\n",
    "train_size = full_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "assert(len(train_dataset) + len(val_dataset) == full_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
    "model = ConvModel.CNNModel(kernel_size=2, embed_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "epochs = constants.EPOCHS\n",
    "batch_size = constants.BATCH_SIZE\n",
    "n_eval = constants.N_EVAL\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING LOOP\n",
    "if USING_WANDB:\n",
    "    wandb.init(\n",
    "        project=\"dna_ml_model\",\n",
    "        # name=f\"experiment_{run}\"\n",
    "        config = {\n",
    "            \"architecture\": model.__class__.__name__,\n",
    "            \"epochs\": constants.EPOCHS,\n",
    "            \"learning_rate\": constants.LEARNING_RATE,\n",
    "            \"notes\": \"none\"\n",
    "    })\n",
    "\n",
    "\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "\n",
    "    for batch in tqdm(train_loader):  # show the times for each batch\n",
    "        # Forward propagate\n",
    "        samples, labels = batch[\"sequences\"].to(device), batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(samples)\n",
    "\n",
    "        labels = labels.reshape(-1,1).float()\n",
    "        # Backpropagation and gradient descent\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  # reset gradients before next iteration\n",
    "\n",
    "\n",
    "        # Periodically evaluate our model + log to Tensorboard\n",
    "        if step % n_eval == 0:\n",
    "            # Compute training loss and accuracy.\n",
    "            # Log the results to Tensorboard.\n",
    "            with torch.no_grad():\n",
    "                # Compute validation loss and accuracy.\n",
    "                accuracy = utils.compute_accuracy(outputs, labels)\n",
    "                val_loss, val_accuracy = utils.evaluate(val_loader, model, loss_fn, device)\n",
    "\n",
    "                wandb.log({\"Train Loss\": loss,\n",
    "                           \"Train Acc\": accuracy,\n",
    "                           \"Val Loss\": val_loss,\n",
    "                           \"Val Acc\": val_accuracy,\n",
    "                           \"Epoch\": epoch\n",
    "                })\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_save_path pretrained/12-09-15-51-24-CNNModel-model-CNNModel-10-epochs.pt\n",
      "model saved at 12-09-15-51-24\n"
     ]
    }
   ],
   "source": [
    "# Create pretrained directory if not yet created\n",
    "if not os.path.isdir(constants.PRETRAINED_DIR):\n",
    "    os.mkdir(constants.PRETRAINED_DIR)\n",
    "\n",
    "now = datetime.now()\n",
    "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
    "model_save_path = os.path.join(\n",
    "    constants.PRETRAINED_DIR,\n",
    "    f'{datetime_str}-{model.__class__.__name__}-model-{constants.EPOCHS}-epochs.pt'\n",
    ")\n",
    "print('model_save_path', model_save_path)\n",
    "ConvModel.save_CNNModel(model_save_path, model)\n",
    "print(f\"model saved at {datetime_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (Conv1): Conv1d(4, 128, kernel_size=(2,), stride=(1,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2): Conv1d(128, 64, kernel_size=(2,), stride=(1,))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = \"pretrained/12-09-14-48-38-CNNModel-model-10-epochs.pt\"\n",
    "model = ConvModel.load_CNNModel(model_save_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predictions = 0\n",
    "total_correct = 0\n",
    "\n",
    "for batch in tqdm(val_loader):\n",
    "    val_samples, val_labels = batch['sequences'].to(device), batch['labels'].to(device)\n",
    "    val_outputs = model(val_samples)\n",
    "    # print(torch.round(val_outputs))\n",
    "    val_labels = val_labels.reshape(-1, 1).float()\n",
    "\n",
    "    val_loss = loss_fn(val_outputs, val_labels).item()  # change tensor to single val\n",
    "    \n",
    "    total_correct += (torch.round(val_outputs) == val_labels).sum().item()\n",
    "\n",
    "    total_predictions += len(val_outputs)\n",
    "\n",
    "val_accuracy = total_correct / total_predictions\n",
    "print(f\"Final Validation Accuracy: {val_accuracy * 100}%\")\n",
    "\n",
    "# wandb.summary['test_accuracy'] = val_accuracy\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference on Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dna_dataset.TestDataset(constants.TEST_FILE) # TODO\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "print(\"Test dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84a6f453671404a9d25d78b2647b485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished inference\n"
     ]
    }
   ],
   "source": [
    "probs = []  # tuples of probability, id\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "\n",
    "    samples, ids = batch[\"sequences\"].to(device), batch['ids'] # not a tensor\n",
    "\n",
    "    outputs = model(samples)\n",
    "\n",
    "    out_list = outputs.tolist()\n",
    "\n",
    "    for i in range(len(out_list)):\n",
    "        probs.append((out_list[i], ids[i]))\n",
    "\n",
    "print(\"Finished inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 values\n",
      "[0.5        0.49999994 0.49999988 ... 0.48022759 0.48021749 0.47941488]\n",
      "[0.50000024 0.50000042 0.50000054 ... 0.52561206 0.5256992  0.52820438]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_probs = np.array(list(zip(*probs))[0])\n",
    "print(len(np_probs[np_probs==1.0]), \"1.0 values\")  # assumes exactly 1\n",
    "not_zero = np_probs[np_probs<=0.5]\n",
    "not_zero[::-1].sort()\n",
    "not_one = np_probs[np_probs>0.5]\n",
    "not_one.sort()\n",
    "print(not_zero)\n",
    "print(not_one)\n",
    "\n",
    "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.sort(reverse=True)\n",
    "\n",
    "highest_probs = probs[:10000]  # top 10,000\n",
    "\n",
    "with open(constants.SOLUTION_FILE, \"w\") as f:\n",
    "    for pair in highest_probs:\n",
    "        f.write(pair[1])\n",
    "        # f.write(\"a\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(list(zip(*probs[:10000]))[0])  # probs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acm_sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
