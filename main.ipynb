{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db31f37-547d-4ca0-bb36-eef5a444efae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpetern0408\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "965b068f-ad12-4318-95e7-3236026bb2c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380efe17-2d87-4f2a-91ac-69f06c061839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "!unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# assert(self.accessible_count + self.not_accessible_count == len(self.sequences))\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = True\n",
        "\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    acc_seq_train += upsampled_acc_seq\n",
        "    acc_lab_train += upsampled_acc_lab\n",
        "\n",
        "elif DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    # downsampled_not_seq, downsampled_not_lab = not_seq_train[:len(acc_seq_train)], not_lab_train[:len(acc_seq_train)]\n",
        "    not_seq_train += downsampled_not_seq\n",
        "    not_lab_train += downsampled_not_lab\n",
        "\n",
        "    # consider upweighting for calibration\n",
        "\n",
        "    # consider adding rest of data to test and val\n",
        "    # rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[:len(acc_seq_train):]\n",
        "\n",
        "print(len(acc_seq_train), len(acc_lab_train))\n",
        "assert(len(acc_seq_train) == len(acc_lab_train))  # ensure the data is now equal"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = acc_seq_train + not_seq_train\n",
        "labels_train = acc_lab_train + not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "# sequences_val, labels_val = dna_dataset.shuffle_lists(sequences_val, labels_val)\n",
        "# df_val = pd.DataFrame({\"sequences\": sequences_val, \"labels\": labels_val})\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "# sequences_test, labels_test = dna_dataset.shuffle_lists(sequences_test, labels_test)\n",
        "# df_test = pd.DataFrame({\"sequences\": sequences_test, \"labels\": labels_test})\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "\n",
        "# assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "# full_dataset = dna_dataset.DNADataset(accessible_file, reduced_nonaccessible_file)"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e704073f-7c99-48a7-8297-3651c250b87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 94478\n",
            "num accessible 47239\n",
            "num not accessible 47239\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "num_filters1 = 64  # 128\n",
        "num_filters2 = 128  # 64\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 128\n",
        "hidden_dense2 = 32  # 64\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "model = CNNModel.CNNModel(kernel_size,\n",
        "                           embed_dim,\n",
        "                           num_filters1,\n",
        "                           num_filters2,\n",
        "                           pool_kernel_size,\n",
        "                           hidden_dense1,\n",
        "                           hidden_dense2,\n",
        "                           dropout_rate_Dense\n",
        "                           )\n",
        "\n",
        "model.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights for loss function\n",
        "USE_WEIGHTED_LOSS = False  # Note may not work correctly if used with resampling\n",
        "# USE_WEIGHTED_LOSS = False\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "weight_class0 = num_train / len(acc_seq_train) * 2\n",
        "weight_class1 = num_train / len(not_seq_train) * 2\n",
        "print(\"weights for class 0\", weight_class0)\n",
        "print(\"weights for class 1\", weight_class1)"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce08d67-247d-4a6d-c5c8-1f331c6416ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights for class 0 4.0\n",
            "weights for class 1 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = .0001\n",
        "if USE_WEIGHTED_LOSS:\n",
        "    loss_fn = nn.BCELoss()\n",
        "    # loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "else:\n",
        "    loss_fn = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XsGb6Nm49Rm8"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, # shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "T03ne9nhwETI"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8z_gnhTp9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00a95f70-c1bf-4f7f-8726-c66a4d1e5275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpetern0408\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240105_195400-phmbwch1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/petern0408/dna_ml_model/runs/phmbwch1' target=\"_blank\">reduced data</a></strong> to <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/petern0408/dna_ml_model/runs/phmbwch1' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/phmbwch1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n",
            "Training Loss: 0.6411 Acc: 0.5937 F1: 0.4605\n",
            "          Precision 0.6850 Recall: 0.3468\n",
            "Validation Loss: 131.2078 Acc: 0.7062 F1: 0.7009\n",
            "          Precision 0.7137 Recall: 0.6885\n",
            "\n",
            "Epoch 2 of 20\n",
            "Training Loss: 0.6236 Acc: 0.6066 F1: 0.4822\n",
            "          Precision 0.7053 Recall: 0.3663\n",
            "Validation Loss: 127.7263 Acc: 0.7362 F1: 0.7592\n",
            "          Precision 0.6983 Recall: 0.8318\n",
            "\n",
            "Epoch 3 of 20\n",
            "Training Loss: 0.6084 Acc: 0.6200 F1: 0.5049\n",
            "          Precision 0.7243 Recall: 0.3875\n",
            "Validation Loss: 125.0140 Acc: 0.7449 F1: 0.7703\n",
            "          Precision 0.7007 Recall: 0.8552\n",
            "\n",
            "Epoch 4 of 20\n",
            "Training Loss: 0.6010 Acc: 0.6260 F1: 0.5132\n",
            "          Precision 0.7350 Recall: 0.3943\n",
            "Validation Loss: 122.7360 Acc: 0.7449 F1: 0.7757\n",
            "          Precision 0.6922 Recall: 0.8822\n",
            "\n",
            "Epoch 5 of 20\n",
            "Training Loss: 0.5941 Acc: 0.6276 F1: 0.5139\n",
            "          Precision 0.7397 Recall: 0.3937\n",
            "Validation Loss: 119.2265 Acc: 0.7499 F1: 0.7782\n",
            "          Precision 0.6991 Recall: 0.8775\n",
            "\n",
            "Epoch 6 of 20\n",
            "Training Loss: 0.5915 Acc: 0.6317 F1: 0.5200\n",
            "          Precision 0.7465 Recall: 0.3989\n",
            "Validation Loss: 117.2647 Acc: 0.7576 F1: 0.7689\n",
            "          Precision 0.7346 Recall: 0.8065\n",
            "\n",
            "Epoch 7 of 20\n",
            "Training Loss: 0.5843 Acc: 0.6344 F1: 0.5217\n",
            "          Precision 0.7541 Recall: 0.3987\n",
            "Validation Loss: 117.7825 Acc: 0.7645 F1: 0.7737\n",
            "          Precision 0.7447 Recall: 0.8051\n",
            "\n",
            "Epoch 8 of 20\n",
            "Training Loss: 0.5792 Acc: 0.6375 F1: 0.5246\n",
            "          Precision 0.7619 Recall: 0.4000\n",
            "Validation Loss: 116.3263 Acc: 0.7581 F1: 0.7840\n",
            "          Precision 0.7082 Recall: 0.8781\n",
            "\n",
            "Epoch 9 of 20\n",
            "Training Loss: 0.5757 Acc: 0.6407 F1: 0.5272\n",
            "          Precision 0.7706 Recall: 0.4007\n",
            "Validation Loss: 114.1515 Acc: 0.7607 F1: 0.7508\n",
            "          Precision 0.7832 Recall: 0.7210\n",
            "\n",
            "Epoch 10 of 20\n",
            "Training Loss: 0.5696 Acc: 0.6449 F1: 0.5323\n",
            "          Precision 0.7794 Recall: 0.4041\n",
            "Validation Loss: 112.0143 Acc: 0.7639 F1: 0.7772\n",
            "          Precision 0.7358 Recall: 0.8236\n",
            "\n",
            "Epoch 11 of 20\n",
            "Training Loss: 0.5667 Acc: 0.6467 F1: 0.5342\n",
            "          Precision 0.7838 Recall: 0.4052\n",
            "Validation Loss: 115.7925 Acc: 0.7475 F1: 0.7823\n",
            "          Precision 0.6877 Recall: 0.9070\n",
            "\n",
            "Epoch 12 of 20\n",
            "Training Loss: 0.5640 Acc: 0.6486 F1: 0.5366\n",
            "          Precision 0.7876 Recall: 0.4069\n",
            "Validation Loss: 110.7997 Acc: 0.7715 F1: 0.7851\n",
            "          Precision 0.7408 Recall: 0.8352\n",
            "\n",
            "Epoch 13 of 20\n",
            "Training Loss: 0.5596 Acc: 0.6508 F1: 0.5396\n",
            "          Precision 0.7920 Recall: 0.4091\n",
            "Validation Loss: 110.9867 Acc: 0.7706 F1: 0.7788\n",
            "          Precision 0.7519 Recall: 0.8076\n",
            "\n",
            "Epoch 14 of 20\n",
            "Training Loss: 0.5550 Acc: 0.6544 F1: 0.5449\n",
            "          Precision 0.7977 Recall: 0.4137\n",
            "Validation Loss: 111.0978 Acc: 0.7688 F1: 0.7839\n",
            "          Precision 0.7360 Recall: 0.8384\n",
            "\n",
            "Epoch 15 of 20\n",
            "Training Loss: 0.5551 Acc: 0.6565 F1: 0.5482\n",
            "          Precision 0.8009 Recall: 0.4167\n",
            "Validation Loss: 108.5469 Acc: 0.7726 F1: 0.7831\n",
            "          Precision 0.7486 Recall: 0.8209\n",
            "\n",
            "Epoch 16 of 20\n",
            "Training Loss: 0.5509 Acc: 0.6575 F1: 0.5481\n",
            "          Precision 0.8052 Recall: 0.4154\n",
            "Validation Loss: 109.7013 Acc: 0.7689 F1: 0.7779\n",
            "          Precision 0.7487 Recall: 0.8095\n",
            "\n",
            "Epoch 17 of 20\n",
            "Training Loss: 0.5499 Acc: 0.6560 F1: 0.5447\n",
            "          Precision 0.8054 Recall: 0.4115\n",
            "Validation Loss: 110.9314 Acc: 0.7659 F1: 0.7856\n",
            "          Precision 0.7246 Recall: 0.8579\n",
            "\n",
            "Epoch 18 of 20\n",
            "Training Loss: 0.5467 Acc: 0.6609 F1: 0.5523\n",
            "          Precision 0.8126 Recall: 0.4183\n",
            "Validation Loss: 109.8465 Acc: 0.7697 F1: 0.7800\n",
            "          Precision 0.7466 Recall: 0.8164\n",
            "\n",
            "Epoch 19 of 20\n",
            "Training Loss: 0.5417 Acc: 0.6619 F1: 0.5535\n",
            "          Precision 0.8145 Recall: 0.4192\n",
            "Validation Loss: 109.0154 Acc: 0.7664 F1: 0.7807\n",
            "          Precision 0.7355 Recall: 0.8319\n",
            "\n",
            "Epoch 20 of 20\n",
            "Training Loss: 0.5427 Acc: 0.6624 F1: 0.5537\n",
            "          Precision 0.8163 Recall: 0.4190\n",
            "Validation Loss: 107.0764 Acc: 0.7702 F1: 0.7828\n",
            "          Precision 0.7420 Recall: 0.8284\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"reduced data\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "    # total_outputs = torch.empty(0).to(device)\n",
        "    # total_labels = torch.empty(0).to(device)\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "        # Forward propagate\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        if USE_WEIGHTED_LOSS:\n",
        "            acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "            not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "            acc_weight[acc_weight==0] = 1\n",
        "            not_weight[not_weight==0] = 1\n",
        "\n",
        "            outputs *= acc_weight\n",
        "            outputs *= not_weight\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        # print(outputs.shape, preds.shape)\n",
        "        CM += confusion_matrix(labels.flatten().detach().numpy(), preds.flatten().detach().numpy())\n",
        "\n",
        "    #     total_outputs = torch.cat((total_outputs, outputs))\n",
        "    #     total_labels = torch.cat((total_labels, labels))\n",
        "    # f1 = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        # Compute validation loss and accuracy.\n",
        "        # accuracy = utils.compute_accuracy(outputs, labels)  # only does current batch\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": precision,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "f350aaddeeea4fda89180c5165fdf1de",
            "e1be7981eb554d849776479e34b38790",
            "28d6ff3962ff4ee9881a815b28286293",
            "7ab81ddf04194250a04925bb7d1d3b72",
            "6a942874759c4fee819f60683c26aec6",
            "54b5ff8adeda4690803ef936bfc42bb9",
            "d8cb391aeee0417faa045e80d778d8c8",
            "bb00e50728aa404493561f384133aadb"
          ]
        },
        "outputId": "abbf8134-02f3-4327-cfd9-4eaa68dae8a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.09850340136054422, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f350aaddeeea4fda89180c5165fdf1de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">weighted_loss_unbalanced_data</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/bxxold0k' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/bxxold0k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240105_054017-bxxold0k/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "# which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().detach().numpy()))\n",
        "\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(\"Best Threshold\", thresholds[ix], \" with F-Score\", fscores[ix])\n",
        "# Best Threshold 42.7"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "f5dfe256-fe64-46f6-8625-01129ee9ddd7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e7ea5901af13>:29: RuntimeWarning: invalid value encountered in divide\n",
            "  fscores = (2 * precisions * recalls) / (precisions + recalls)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBa0lEQVR4nO3de3QU9f3/8ddmSTYJkIBFwiWRiMQrCgqBExVRG4pcothWsVLlpqWK/QHxigqoVFArCq0goAFsjwqK1C8IxUIEK4oFwfBtBREkkURMAC8EEnLbnd8f+83CkgSym9md3c3zcc6cM5nM7rx3BPfF5/OZz8dmGIYhAACACBFldQEAAABmItwAAICIQrgBAAARhXADAAAiCuEGAABEFMINAACIKIQbAAAQUVpYXUCwuVwuHThwQK1bt5bNZrO6HAAA0AiGYejo0aPq1KmToqJO3zbT7MLNgQMHlJKSYnUZAADAD4WFhUpOTj7tOc0u3LRu3VqS++YkJCRYXA0AACcpK5M6dXLvHzggtWxpbT0hpLS0VCkpKZ7v8dNpduGmtisqISGBcAMACC12+4n9hATCTT0aM6SEAcUAACCiEG4AAEBEaXbdUgAAhKwWLaSRI0/swy/cOQAAQoXDIS1ZYnUVYY9uKQAAEFFouQEAIFQYhlRe7t6Pj5eYbNYvtNwAABAqysulVq3cW23Igc8INwAAIKIQbgAAQEQh3AAAgIhiabj517/+paysLHXq1Ek2m03vvvvuGV+zceNGXXHFFXI4HOrWrZuW8MgcAAA4iaXhpqysTD169NDcuXMbdX5+fr6GDBmi6667Tnl5eZo4caLuuusuvf/++wGutHGKioq0YcMGFRUVWV0KAADNlqWPgg8aNEiDBg1q9Pnz58/Xueeeq1mzZkmSLrroIm3atEkvvviiBg4cGKgyG13b+PHj5XK5FBUVpYULF2rs2LGW1gQAQHMUVmNuNm/erMzMTK9jAwcO1ObNmxt8TWVlpUpLS702sxUVFXmCjSS5XC6NGzeOFhwAgG/sdunXv3ZvJ68QDp+EVbgpLi5WUlKS17GkpCSVlpbq+PHj9b5m5syZSkxM9GwpKSmm17Vnzx5PsKnldDq1d+9e068FAIhgsbHS22+7t9hYq6sJW2EVbvwxefJkHTlyxLMVFhaafo20tDRFRXnfSrvdrm7dupl+LQAAcHphFW46dOigkpISr2MlJSVKSEhQXFxcva9xOBxKSEjw2syWnJyshx9+2POz3W7XggULlJycbPq1AADA6YVVuMnIyFBubq7XsXXr1ikjI8Oiik648cYbJUkdO3ZUQUEBg4kBAL4rK3OvJ2WzuffhF0vDzbFjx5SXl6e8vDxJ7ke98/LytH//fknuLqU777zTc/7vf/977du3Tw899JC+/PJLzZs3T2+99ZYmTZpkRfn1iouLo8UGAAALWRpuPvvsM11++eW6/PLLJUnZ2dm6/PLLNXXqVEnSd9995wk6knTuuedq9erVWrdunXr06KFZs2bp1VdftfwxcF8NGDBAcXFxGjBggNWlAAAQcWyGYRhWFxFMpaWlSkxM1JEjR0wdf/Ppp58qIyNDXbt21ddff93gebZ6lq9PSkrSkCFDlJOTY1o9AIAwVFbmXhFcko4dk1q2tLaeEOLL93dYjbkJd/UFG8k9KHrRokWyM6cBAABNRrgJkoaCzclcLpdaktIBAGgSS5dfiEQ1NTV66623JElXXnmlkpOTGxVsapWXl3ua3QAAgO8INybbv3+/hg8fLsndWuPPuJ7S0lLZbDbZbDa1bdtWV111laZMmaL09HTPOe+9957WrFmjwYMHa+jQoabVDwCwkN0uDR58Yh9+YUCxSVauXKmbbrrJtPerz/XXX69LL71Uc+bM8Tpus9l02WWXaffu3br66qu1bt26gNYBAECwMaDYAh999FHAr/HBBx/UCTaSZBiGduzYoYqKCq1fv142m00vvPBCwOsBACAUEW5McvJ8PKHg/vvv93Rtde3aVTNmzGCVcgBAs0C4MUlMTIxP58+aNctrDE0g5efn67HHHlNKSoratWvn9buJEyfq3HPP1cSJE7VkyRK1bNlSNptNDodD5557ricg2Wy2BicdnDp1qtq0aaP4+HiWnQCApigrc89t07Ilyy80AWNuTDJ8+HDPU1JnMmvWLGVnZ0tyz1a8fv160+oINdHR0XrmmWc8nxcAcBpM4tcgxtxY4Kyzzmr0uSd/0c+YMSMQ5YSM6upqry6yM7UCAQDQVIQbk7SqTdpncMkll3j9nJ6erpEjR3odczgcatu2rWm1haLagc8AAJiNcBNkDzzwQJ1jS5Ys0ZYtW/Tiiy9qy5Ytqqio0A8//CDDMGQYhhwOR53XDB8+XIZh6KKLLgpG2QFjs9l02223WV0GACCCEG6CqEuXLho1alS9v0tPT9fEiRPrHWRcUVGhVatWafz48Vq1apUMw9DSpUslSTt37vSEoKuvvjqQ5QfMsmXL6nRb2Ww29evXz+rSAABhiHATJGeffbYKCgr8fv3QoUP10ksvnXY24o8++sgTdAzDUFZWVlh3/WzatMkr7KSlpVldEgAgDBBugiQzMzPo11y5cqVcLpcMw9CWLVsaPY4nPj7es9+6dWtlZWUpKsr6Pyp79+4N67AGAGcUFSX17+/eQuD/u+GKO2eSxMTE0/7+mmuuCVIl9UtPT/cax3O6rayszLNfWlqqlStXyul0yjCMOt1j9W2144e6desWkM9is9nUokULZmEGEHni4qSNG91bXJzV1YQt5rkxyaJFi047gV1hYaGSk5NNu1442rp1q/r06WP6+7Zv314JCQnau3fvac+z2+169NFH9dRTT5leAwAgsJjnxgLHjx9v8HfXXnttsw82Uv2PvZvh4MGDZww2kuR0OjV9+nTW3gKACEe4MUncaZoPA9U9E45qH3tPTU21tI5TJxbs1KkTa28BsF5ZmXT22e6N5Rf8RrgxyelabuAtPT1d+fn5dcbqFBYWasOGDRozZozsdntQa/ruu++UkpLiFXjatWvnCTxpaWlev4uKitIVV1xBIAJgvsOH3Rv81sLqAiLF6VpuunbtGsRKwldycrKSk5N17bXXKicnx3Pcqiekvv/+e6WkpNT7O8Mw9Pnnn3v9PjMzU/Hx8br55psbnM8IABB4tNyYJDc3t8HfRfpSCoFmGIbGjBkT8o+Br1+/XitXrtTo0aPrTEgYHR2tqVOnWl0iADQLhBsTFBUV6c0332zw9z/++GMQq4lMOTk5njl7gt1lZYaamhrPYObarXv37nRrAUAAEG5MsGfPHp3uifpDhw4FsZrIV1NTo8WLF+v888/3as1JTEzU4sWLNWPGDI0cOdJrLp761uey2hdffFFnnE9jN+b5AYCGMc+NCYqKitSlSxe5XK56fz9jxgxNnjzZlGvBf1u3btWwYcN04MABq0sJmDFjxniNVwIQZsrKpFat3PvHjkktW1pbTwhhnpsgS05O1g033NDg73kUPDSkp6fr22+/rTObcssI+p/HokWLZLPZ6O4CwlVUlNS7t3tj+QW/cedMUFRUpLVr1zb4e6vndEHD0tPTdezYMa/As2rVKq/1tWp16NBBSUlJIT+wWZKnu+vGG2+0uhQAvoiLk7ZudW8sv+A3wo0J9uzZ02CXlCSVMRFTWBk6dKjX+lq123fffafi4mLPwObazYpFURtr1apV9Y7Z6devn2666SYtWbLE6hIBwHSMuTFBUVGRzjnnnHoHFdvtdhUUFLD8QjP13nvvacyYMSE/qDwrK0uTJk1SWVmZvvrqK/Xr10/p6elWlwUAHr58fxNuTNBQuImKitLChQtPu6Ammp+xY8dq0aJFVpfRKKmpqcrPz7e6DKD5KC+XLr7Yvb9zp1RPF3lzxYDiIGvoUfClS5cSbFBHTk5OnS4vX7ZgDlAvKCio06V1ce3/eAGYzzCkb75xb82r7cFUhBsTpKWlKeqUUe12u10ZGRkWVYRIVhumT946d+4ctOvv2rWr3nE8HTt2DFoNAHA6hBsTJCcn6+GHH/b8bLPZtGDBAsbZIGiKiopUWFho6WPtxcXFXmHntttus6wWAM0b4QaIEMnJyZ7H2rOysqwuR8uWLZPNZlNsbCzz7gAIKgYUm6C+GYp5Sgqh6OKLL9auXbssuz4DlIEzYIbiBjGgOMjqm+fG6XRq7969FlUE1G/nzp1eY3WuvvrqoF7/1AHKdF0BCATCjQkaGlDMsgsIdR999FG9T2RNmTKlzp/pQKjtuoqKivIEnpiYGGZWRvNls7kfBb/4Yvc+/EK4McGpA4qjoqIYUIyw9tRTT8npdHoFnkCO4zm5d7y6urremZV5BB3NQny89MUX7o05bvxGuDHJyf/SfOGFF5jfBhFn5cqV9bbyFBYWKjY2NuDXb+gRdEIPgFMRbkyycuVKz352drZycnIsrAYInuTkZB0/flyGYWjWrFmmDdRvrPpCT8+ePYNaA4DQwtNSJuBpKaCuoqIidevWTZWVlVaXIknq0aOH8vLyrC4DOL3ycql2XbetW+maOglPSwUZT0sBdSUnJ6uiosLTomO32y2tZ8eOHfV2a9HSg5BiGO41pXbuZPmFJiDcmICnpYDTy87OVk1NjQzD0OLFiy2dSbk+tcEnJSXF6lIAmIBwYwKelgIab9SoUZ6ZlCdMmGB5i87JioqKvFp0oqKi1KdPH23dutXq0gD4gHBjkpOflnr77bd5WgpohNmzZ3tadOrbVq1apV69ellWn2EY2rp1q/r06VOnK6tPnz6W1QXg9Ag3AdChQwerSwAiwtChQ/XZZ5/VG3yCPbvyqbZu3Von8EydOtXSmgC4EW4C4NChQ1aXAES8+mZXnjBhgmwWzuo6ffr0Bgcts9QEEDyEG5OcPM/NL3/5S+a5ASwwe/ZsuVyukGrhqVW71ETtFhcXp4kTJ1pdFkKNzSZ16eLeWH7Bb8xzYwLmuQHCU1paWkhO2XD11Vfro48+sroMIKQwz02QMc8NEJ727NkT8HWz/LFp0yavVp7o6Gi99957VpcFhA3CjQmY5wYIbyevm1VYWKhBgwYFZVX0xqqpqVFWVhaDl4FGCp2/vWGMeW6AyJGcnKw1a9bUWRU91MbwnDp4mfE7EeL4cffyC+np7n34hXBjkpPnuVm7di3z3AAR6uSntLZs2aIXX3xRbdq0sboszZkzh2UlIoHLJX32mXs7ZbgDGo9wEwCdOnWyugQAQZCenq6JEyfqxx9/bHAiQivH85y8nhbdWGhOCDcBEEp99QCsdfJ4nuHDhys6OtqSOk7uxjq5pRmIRHwLBwDhBkB9li5dqqqqqgZbeTIzM4NSx6pVq+i+QkTjWzgACDcA/LFu3TqvsLNlyxa1atUq4Nc9ufvKZrMxZhBhz/Jv4blz5yo1NVWxsbHq27evtmzZctrzZ8+erQsuuEBxcXFKSUnRpEmTVFFREaRqG6e4uNjqEgBEgPT0dB09etQr8Jx99tkBv+6iRYsaXEaC4INwYGm4WbZsmbKzszVt2jRt375dPXr00MCBA3Xw4MF6z3/jjTf0yCOPaNq0adq1a5dycnK0bNkyPfroo0GuvK6Tl1+49tprWX4BQEAcPHjQK+ycddZZQb3+ycGnffv2Qb12s9GunXuD3yxdfqFv375KT0/XSy+9JElyuVxKSUnRH/7wBz3yyCN1zr/vvvu0a9cu5ebmeo7df//9+ve//61NmzbVe43KykpVVlZ6fi4tLVVKSgrLLwCIWD179tSOHTuCft0JEyZo9uzZQb8umoewWH6hqqpK27Zt8xpAFxUVpczMTG3evLne11x55ZXatm2bp+tq3759WrNmjQYPHtzgdWbOnKnExETPlpKSYu4HEcsvAAgteXl5npad1NTUoF23dq4duq5gNcvCzeHDh+V0OpWUlOR1PCkpqcExK7fffrueeuopXX311YqOjtZ5552na6+99rTdUpMnT9aRI0c8W2FhoamfQ2L5BQChKz8/3xN0evToEZRr1nZdDRgwICjXA05l+YBiX2zcuFEzZszQvHnztH37dq1YsUKrV6/W9OnTG3yNw+FQQkKC12a2U5dfsNvtLL8AIOSc3KITjKUk1q9f7xmf87Of/Syg14oYx49L117r3lh+wW+WhZt27drJbrerpKTE63hJSYk6dOhQ72umTJmiO+64Q3fddZcuvfRS3XzzzZoxY4ZmzpxZp1so2E6eFGvz5s00ywIIeScvJVFYWFinJd1MP/zwA09eNYbLJX34oXtj+QW/WRZuYmJi1KtXL6/BwS6XS7m5ucrIyKj3NeXl5fV2/0iSheOi6+jYsaPVJQCAT5KTk1VcXNzgBIOBWD/r5CevrJq5GZHJ0m6p7OxsvfLKK3rttde0a9cu3XPPPSorK9Po0aMlSXfeeacmT57sOT8rK0svv/yyli5dqvz8fK1bt05TpkxRVlaWJ+SEApvNZnUJAGCqk9fPmjVrlunvX1NT49Wq069fP9OvgeajhZUXHz58uA4dOqSpU6equLhYPXv21Nq1az1No/v37/dqqXn88cdls9n0+OOP69tvv9XZZ5+trKwsPf3001Z9hHoRbgBEsuzsbGVnZ3t+jouLM30y1U2bNslmsyk+Pl5lZWWmvjcin6Xz3FjBl+fkffHpp596utMOHDhA1xSAZsdutwd0/GOLFi30ySefKD09PWDXsFxZmVS75MaxY1LLltbWE0LCYp4bAEBkcTqdAZ01uaamRn369PF0XcXFxQXkOgh/hJsAoFsKQHP2/fffe8bnZGVlBew6FRUVXuN0Lr744oBdK6ji490b/Ea4CQDCDQC4rVy5ss6TV4GaA2zXrl2eoFNUVBSQawRcy5burqmyMrqkmoBwEwCEGwBoWGFhYcBbdlJSUphLpxkj3JikmY3LBgBTnNqyY/Z4nZPn0rHZbAFZXxChh3ATALTcAIB/asfrDB8+PCDvX1RU5BV2Qm5ZiIoKacgQ92by4/XNCeHGJCe33Hz33XcWVgIA4W/p0qWe1pwtW7bI4XAE5DonLwsREgt9Op3SmjXuzem0upqwRbgxyapVqzz7l19+uXJyciysBgAiR3p6uioqKjxhZ9WqVQFpIT95oc+pU6ea/v4IHibxM0FRUZG6dOniNXmV3W5XQUEBK4MDQID17NlTO3bsCNj7n3322Tp48GDA3t8Lk/g1iEn8gmzPnj11ZuV0Op3au3evRRUBQPORl5fnWdk8EA4dOiSbzabWrVsH5P1hPsKNCdLS0updrbxbt24WVQQAzU9ycnLAnrqSpGPHjrGoZ5gg3JggOTlZDzzwgOdnu92uBQsW0CUFABY5eZZks+fTqV3Us23btqa9J8xFuDHJkCFDPPs7duxg4igACCGnzqdjxuKbP/30k2w2m9q3b29ChTAT4cYkJ4/LpsUGAELbli1bPEGnRYsWTXqv2jE5tVuTWnRatpQMw70xmNhvhBuTnBxumMQPAMJHdXW1J+jExsY2+f1qW3ROHYuJ4OHOm6SZPVEPABHp+PHjnqDT1IdCDMPwtOaYEZrQeISbAKDlBgDC3549e2QYhnr06NHk96qsrJTNZtPWrVtPf2JFhXTLLe6N5Rf8RrgxCd1SABCZaufRMWMJiD59+shmsykmJqb+E5xOafly98byC34j3JiEcAMAka12CYgGg4kPqqurPV1WaWlpJlSHkxFuAADwQWVlpQzD0JgxY0x5v71798pmsykuLs6U9wPhxjS03ABA85KTk+M1d05mZmaT3q+iokIta9eVkvTQQw81tcRmi3BjEsINADRv69atk2EYmjVrlinvN3fePL5P/ES4MQnhBgAgSdnZ2Z7WnFYntcT4i+8U3xFuAAAIkKNHj6qwsLDJE/rVDj7u2bOnOYVFOMKNSWi5AQDUJzk5WU6nU4ZhaMqUKac9t1xSy//byuv5/Y4dO/iOaQTCjUkINwCAM3nqqac8XVYNzZtTrvqDzclqW3JQP8INAAAWqJ03p7Cw0O/3sNlsmjp1qolVRQbCjUlouQEA+CM5OdnTmrN6xQotlrRYUmOnCpw+fTrfO6do2jrv8CDcAACaavAvfuHZHy+pyofX2mw2ORwOVbAmFS03ZiHcAADMtPztt31+Te0CnWasgxXOCDcAAISgQYMGebqrfFVVVdWs/6FNuDEJLTcAgEAxDEPp6ek+v665fh8RbkxCuAEABNKWLVtkGIYSEhJ8ep3NZlOLFs1riC3hJgAINwCAQDly5IjPXVVOp1M2m00xMY19Biu8EW5McvIftKKiIgsrAQA0B/50VVVXV8tmszV5OYhQF9mfLoj++c9/eva7dOminJwcC6sBAISl+Hjp4EH3Fh9/xtNru6quvvpqny5jGIZsNpu2bt3qb6UhzWb4Mww7jJWWlioxMVFHjhzxud+yIUVFRTrnnHO8Wm/sdrsKCgqUnJxsyjUAADgTf4ZFjBw5UkuWLDG/GJP58v1Ny40J9uzZU6f/0+l0au/evRZVBABojvxpr3jttdcirgWHcGOCtLS0OmnZbrerW7duFlUEAAhLlZXS+PHurbLSr7cwDEOzZs3y6TV9+vTx61qhinBjguTkZN17772en+12uxYsWECXFADANzU10rx57q2mxu+3yc7OlmEYGjNmTKNfE0lP+hJuTPLzn//cs19QUKCxY8daWA0AAFJOTo4Mw2h0T0KkBBzCTQDQYgMACCW1Y0Ojo6PPeG4kBBzCDQAAzURVVePWGW9MCAplhBuTNLMn6gEAYaox31c1NTW68cYbg1BNYBBuAABoZhoTcFatWhW2XVSEGwAAmqHG9jiEY8Ah3JiEbikAQJPFxUn5+e4tLi7gl2vso+JpaWkBrsRchBsAAEJFVJSUmuregrC4ZU5OTqMW0Qy3GfcJNwAANGNOp1OtWrU643nh1D1FuAEAIFRUVUkPPujeGvnYthmOHj2qxYsXB+16gUa4MQljbgAATVZdLT3/vHurrg7qpUeNGqXU1NTTnhMurTeEGwAAIEnKz88/4znhEHAINwAAwGPVqlVnPCcnJycIlfiPcGMSuqUAAJFg6NChZ2ydueuuu1RUVBSkinxHuAEAAF5cLtcZz0lJSdHEiRMDX4wfCDcAAKCO9PT0M54zZ84cxcbGBqEa31gebubOnavU1FTFxsaqb9++2rJly2nP/+mnnzR+/Hh17NhRDodD559/vtasWROkahtGtxQAIJKc6fu4VmVlZci14FgabpYtW6bs7GxNmzZN27dvV48ePTRw4EAdPHiw3vOrqqo0YMAAFRQUaPny5dq9e7deeeUVde7cOciVAwAQAHFx0n//696CsPzCmTT2H+5z5swJcCW+aWHlxV944QXdfffdGj16tCRp/vz5Wr16tRYtWqRHHnmkzvmLFi3SDz/8oE8++UTR0dGSdMZn8isrK1VZWen5ubS01LwPAACAmaKipEsusboKL4ZhNOrxb5vNFjK9GJa13FRVVWnbtm3KzMw8UUxUlDIzM7V58+Z6X7Ny5UplZGRo/PjxSkpKUvfu3TVjxgw5nc4GrzNz5kwlJiZ6tpSUFNM/i0S3FAAgcoXbd5xl4ebw4cNyOp1KSkryOp6UlKTi4uJ6X7Nv3z4tX75cTqdTa9as0ZQpUzRr1iz98Y9/bPA6kydP1pEjRzxbYWGhqZ8DAADTVFVJTzzh3oK4/EJjhFPAsbRbylcul0vt27fXwoULZbfb1atXL3377bf605/+pGnTptX7GofDIYfDEeRKAQDwQ3W19OST7v0HH5RiYqyt5xRn6qIKla4py8JNu3btZLfbVVJS4nW8pKREHTp0qPc1HTt2VHR0tOx2u+fYRRddpOLiYlVVVSkmxP4QAACA4LOsWyomJka9evVSbm6u55jL5VJubq4yMjLqfc1VV12lvXv3ek0u9NVXX6ljx46WB5tQSKoAAARamzZtTvv7UFh7ytJHwbOzs/XKK6/otdde065du3TPPfeorKzM8/TUnXfeqcmTJ3vOv+eee/TDDz9owoQJ+uqrr7R69WrNmDFD48ePt+ojAADQrPz4449Wl3BGlo65GT58uA4dOqSpU6equLhYPXv21Nq1az2DjPfv36+oqBP5KyUlRe+//74mTZqkyy67TJ07d9aECRP08MMPW/URAADAKawee2Mzmll/SmlpqRITE3XkyBElJCSY9r5vvvmmbr/9dkl0UQEA/FRWJrVq5d4/dkxq2dLaek7jTN1PZn8X+vL97VfLjdPp1JIlS5Sbm6uDBw/WWWDrgw8+8OdtAQBAmEhNTVVBQYHVZdTLr3AzYcIELVmyREOGDFH37t1DYvAQAABhLzZWql3TKQQXpDxZfn5+yD4W7le4Wbp0qd566y0NHjzY7HrCFl1RAIAms9ulRqzGjdPz62mpmJgYdevWzexaAABAGDl53rlQ4le4uf/++zVnzhxaKwAAMFNVlfSnP7m3EFt+oT41NTVWl1Avv7qlNm3apA0bNugf//iHLrnkEs8K3bVWrFhhSnEAADQr1dXSQw+59++9N+SWXwgXfoWbNm3a6Oabbza7lrBGKxYAAKHBr3CzePFis+sAAAAR5sYbb9TKlSuDft0mzVB86NAh7d69W5J0wQUX6OyzzzalKAAAEP5WrVplyXX9GlBcVlamMWPGqGPHjrrmmmt0zTXXqFOnTho7dqzKy8vNrjEs0C0FAEBo8CvcZGdn68MPP9SqVav0008/6aefftL//M//6MMPP9T9999vdo0AACBEheI/7v3qlnrnnXe0fPlyXXvttZ5jgwcPVlxcnG699Va9/PLLZtUHAADgE7/CTXl5uWfl7pO1b9+ebikAAPwVGytt2HBiH37xq1sqIyND06ZNU0VFhefY8ePH9eSTTyojI8O04gAAaFbsdunaa91biM7+Gw78armZM2eOBg4cqOTkZPXo0UOStGPHDsXGxur99983tUAAAABf+BVuunfvrj179uj111/Xl19+KUn6zW9+oxEjRiguLs7UAgEAaDaqq6WFC937v/uddMoKAGgcv+e5iY+P1913321mLWGNMTcAgCarqpLuu8+9P2pURIQbm80W9O/IRoeblStXatCgQYqOjj7jbIM33nhjkwsDAADwR6PDzbBhw1RcXKz27dtr2LBhDZ5ns9nkdDrNqA0AAISBCRMmaM6cOVaX4dHop6VcLpfat2/v2W9oa67Bhm4pAEBzNXv2bKtL8OLXo+D1+emnn8x6KwAAAL/5FW6effZZLVu2zPPzLbfcorPOOkudO3fWjh07TCsOAADAV36Fm/nz5yslJUWStG7dOq1fv15r167VoEGD9OCDD5paYLigWwoAgNDg16PgxcXFnnDz3nvv6dZbb9UvfvELpaamqm/fvqYWGI6KioqUnJxsdRkAgHDjcEjvvXdiH37xq+Wmbdu2KiwslCStXbtWmZmZktytF811QPG//vUvz36XLl2Uk5NjYTUAgLDUooU0ZIh7a+H3VHTNnl/h5pe//KVuv/12DRgwQN9//70GDRokSfr888/VrVs3UwsMB0VFRVqyZInnZ5fLpXHjxqmoqMi6ogAAaKb8ioUvvviiUlNTVVhYqOeee06tWrWSJH333Xe69957TS0wHOzZs6fOmBun06m9e/fSPQUAaLzqaun11937I0ZExAzFVrAZzWwkbGlpqRITE3XkyBElJCSY8p5FRUU655xzvAKO3W5XQUEB4QYA0HhlZdL/NRjo2DGpZUtr6/GBzWZr8HdmRA1fvr9ZfsEEycnJGjlypKdrym63a8GCBQQbAECzYRhGvQHHijYUll8wyTXXXOMJN7TYAACao1MDjlWdQ40ONy6Xq9591EWwAQA0V6Ew2sW05RcAAABCgV/h5v/9v/+nP//5z3WOv/TSS5o4cWJTawIAAPCbX+HmnXfe0VVXXVXn+JVXXqnly5c3uSgAAAB/+TXPzffff6/ExMQ6xxMSEnT48OEmFwUAQLPkcEhvvXViH37xq+WmW7duWrt2bZ3j//jHP9S1a9cmFwUAQLPUooV0yy3ujeUX/ObXncvOztZ9992nQ4cO6frrr5ck5ebmatasWZo9e7aZ9YWNUBgdDgAA/Aw3Y8aMUWVlpZ5++mlNnz5dkpSamqqXX35Zd955p6kFAgDQbNTUSH//u3v/5ptpvfGT33ftnnvu0T333KNDhw4pLi7Os74UAADwU2WldOut7v1jxwg3fvJ7npuamhqtX79eK1as8HTJHDhwQMeOHTOtOAAAAF/5FQm/+eYb3XDDDdq/f78qKys1YMAAtW7dWs8++6wqKys1f/58s+sEAABoFL9abiZMmKDevXvrxx9/VFxcnOf4zTffrNzcXNOKAwAA8JVfLTcfffSRPvnkE8XExHgdT01N1bfffmtKYQAAAP7wq+XG5XLVu/J3UVGRWrdu3eSiAAAA/OVXuPnFL37hNZ+NzWbTsWPHNG3aNA0ePNis2gAAAHzmV7fU888/rxtuuEEXX3yxKioqdPvtt2vPnj1q166d3nzzTbNrBACgeYiJkRYvPrEPv/gVblJSUrRjxw4tW7ZMO3bs0LFjxzR27FiNGDHCa4Bxc8IMxQCAJouOlkaNsrqKsOdzuKmurtaFF16o9957TyNGjNCIESMCURcAAIBffA430dHRqqioCEQtAAA0bzU10vvvu/cHDmSGYj/5NaB4/PjxevbZZ1VTU2N2PQAANF+VldLQoe6tstLqasKWX5Fw69atys3N1T//+U9deumlatmypdfvV6xYYUpxAAAAvvIr3LRp00a/+tWvzK4FAACgyXwKNy6XS3/605/01VdfqaqqStdff72eeOKJZvuEFAAACD0+jbl5+umn9eijj6pVq1bq3Lmz/vznP2v8+PGBqg0AAMBnPoWbv/71r5o3b57ef/99vfvuu1q1apVef/11uVyuQNUHAADgE5/Czf79+72WV8jMzJTNZtOBAwdMLwwAAMAfPoWbmpoaxcbGeh2Ljo5WdXV1k4qYO3euUlNTFRsbq759+2rLli2Net3SpUtls9k0bNiwJl0fAICQEBMjvfSSe2P5Bb/5NKDYMAyNGjVKDofDc6yiokK///3vvR4H9+VR8GXLlik7O1vz589X3759NXv2bA0cOFC7d+9W+/btG3xdQUGBHnjgAfXr18+XjxAwLL8AAGiy6GiJsaxN5lPLzciRI9W+fXslJiZ6tt/+9rfq1KmT1zFfvPDCC7r77rs1evRoXXzxxZo/f77i4+O1aNGiBl/jdDo1YsQIPfnkk+ratatP1wMAAJHNp5abxbUrlZqkqqpK27Zt0+TJkz3HoqKilJmZqc2bNzf4uqeeekrt27fX2LFj9dFHH532GpWVlao8aZbH0tLSphcOAEAgOJ1S7fdav36S3W5tPWHK0kUrDh8+LKfTqaSkJK/jSUlJ+vLLL+t9zaZNm5STk6O8vLxGXWPmzJl68sknm1oqAACBV1EhXXede//YMemUFQDQOH6tLWWVo0eP6o477tArr7yidu3aNeo1kydP1pEjRzxbYWFhgKsEAABWsrTlpl27drLb7SopKfE6XlJSog4dOtQ5/+uvv1ZBQYGysrI8x2rn2GnRooV2796t8847z+s1DofDawA0AACIbJa23MTExKhXr17Kzc31HHO5XMrNzVVGRkad8y+88EL95z//UV5enme78cYbdd111ykvL08pKSnBLB8AAIQgS1tuJCk7O1sjR45U79691adPH82ePVtlZWUaPXq0JOnOO+9U586dNXPmTMXGxqp79+5er2/Tpo0k1TkOAACaJ8vDzfDhw3Xo0CFNnTpVxcXF6tmzp9auXesZZLx//35FRYXV0CAAAGAhm9HMZp8rLS1VYmKijhw5ooSEBNPe99VXX9Xdd98tiQn9AAB+KiuTWrVy7/O0lBdfvr8tb7mJFAQaAECTRUdLzz13Yh9+IdwAABAqYmKkBx+0uoqwx2AWAAAQUWi5AQAgVDid0vbt7v0rrmD5BT8RbgAACBUVFVKfPu59BhT7jW4pAAAQUQg3AAAgohBuAABARCHcAACAiEK4AQAAEYVwAwAAIgqPgpuE5RcAAE0WHS1Nm3ZiH34h3AAAECpiYqQnnrC6irBHtxQAAIgotNwAABAqXC5p1y73/kUXSVG0QfiDcAMAQKg4flzq3t29z/ILfiMSAgCAiEK4AQAAEYVwAwAAIgrhBgAARBTCDQAAiCiEG5MwQzEAAKGBR8EBAAgV0dHSAw+c2IdfCDcAAISKmBjpT3+yuoqwR7cUAACIKLTcAAAQKlwuaf9+9/4557D8gp8INwAAhIrjx6Vzz3Xvs/yC34iEAAAgohBuAABARCHcAACAiEK4AQAAEYVwAwAAIgrhxiQsvwAAQGjgUXAAAEJFixbSvfee2IdfuHMAAIQKh0OaO9fqKsIe3VIAACCi0HIDAECoMAzp8GH3frt2ks1mbT1hinADAECoKC+X2rd377P8gt/olgIAABGFcAMAACIK4QYAAEQUwg0AAIgohBuTMEMxAAChgXADAAAiCo+CAwAQKlq0kEaOPLEPv3DnAAAIFQ6HtGSJ1VWEPbqlAABARKHlBgCAUGEY7lmKJSk+nuUX/ETLDQAAoaK8XGrVyr3Vhhz4jHADAAAiCuEGAABEFMINAACIKIQbAAAQUQg3JmH5BQAAQgPhBgAARBTmuQEAIFTY7dKvf31iH34JiZabuXPnKjU1VbGxserbt6+2bNnS4LmvvPKK+vXrp7Zt26pt27bKzMw87fkAAISN2Fjp7bfdW2ys1dWELcvDzbJly5Sdna1p06Zp+/bt6tGjhwYOHKiDBw/We/7GjRv1m9/8Rhs2bNDmzZuVkpKiX/ziF/r222+DXDkAAAhFloebF154QXfffbdGjx6tiy++WPPnz1d8fLwWLVpU7/mvv/667r33XvXs2VMXXnihXn31VblcLuXm5ga5cgAAEIosDTdVVVXatm2bMjMzPceioqKUmZmpzZs3N+o9ysvLVV1drbPOOqve31dWVqq0tNRrAwAgJJWVudeTstnc+/CLpeHm8OHDcjqdSkpK8jqelJSk4uLiRr3Hww8/rE6dOnkFpJPNnDlTiYmJni0lJaXJdQMAgNBlebdUUzzzzDNaunSp/v73vyu2gYFXkydP1pEjRzxbYWFhkKsEAADBZOmj4O3atZPdbldJSYnX8ZKSEnXo0OG0r33++ef1zDPPaP369brssssaPM/hcMjhcJhSLwAACH2WttzExMSoV69eXoOBawcHZ2RkNPi65557TtOnT9fatWvVu3fvYJR6RsxQDABAaLB8Er/s7GyNHDlSvXv3Vp8+fTR79myVlZVp9OjRkqQ777xTnTt31syZMyVJzz77rKZOnao33nhDqampnrE5rVq1UqtWrSz7HAAAIDRYHm6GDx+uQ4cOaerUqSouLlbPnj21du1azyDj/fv3KyrqRAPTyy+/rKqqKv26dgbH/zNt2jQ98cQTwSwdAACEIMvDjSTdd999uu++++r93caNG71+LigoCHxBAABYwW6XBg8+sQ+/hES4AQAAci+5sHq11VWEvbB+FBwAAOBUhBsAABBRCDcAAISKsjKpZUv3xvILfmPMDQAAoaS83OoKwh4tNwAAIKIQbgAAQEQh3JiE5RcAAAgNhBsAABBRCDcAACCi8LQUAAChIipK6t//xD78QrgBACBUxMVJp6ypCN8RCwEAQEQh3AAAgIhCuAEAIFSUlUlnn+3eWH7Bb4y5AQAglBw+bHUFYY+WGwAAEFEINyZhhmIAAEID4QYAAEQUwg0AAIgohBsAABBReFoKAIBQERUl9e59Yh9+IdwAABAq4uKkrVutriLsEQsBAEBEIdwAAICIQrgBACBUlJdLqanurbzc6mrCFmNuAAAIFYYhffPNiX34hZYbAAAQUQg3JmH5BQAAQgPhBgAARBTCDQAAiCiEGwAAEFF4WgoAgFBhs0kXX3xiH34h3AAAECri46UvvrC6irBHtxQAAIgohBsAABBRCDcAAISK8nLpkkvcG8sv+I0xNwAAhArDkHbuPLEPv9ByYxJmKAYAIDQQbgAAQEQh3AAAgIhCuAEAABGFcAMAACIKT0sBABAqbDapS5cT+/AL4QaAKQzDUE1NjZxOp9WlhAS73a4WLVrIxhcUfBEfLxUUWF1F2CPcAGiyqqoqfffddypn0jEv8fHx6tixo2JiYqwuBWhWCDcAmsTlcik/P192u12dOnVSTExMs2+tMAxDVVVVOnTokPLz85WWlqaoKIY4AsFCuAHQJFVVVXK5XEpJSVF8fLzV5YSMuLg4RUdH65tvvlFVVZViY2OtLgnh4Phx6Zpr3Pv/+pcUF2dtPWGKcAPAFLRM1MU9gc9cLumzz07swy/8zTMJyy8AABAaCDcAACCiEG4AwE+pqamaPXu21WUAOAXhBgAARBTCDYCQUVRUpA0bNqioqMjqUgCEMcINAFMZhqGysjKft3nz5qlLly66/vrr1aVLF82bN8/n9/BlYP/ChQvVqVMnuU55IuWmm27SmDFj9PXXX+umm25SUlKSWrVqpfT0dK1fv97s2wXU1a6de4PfeBQcgKnKy8vVqlWrJr2Hy+XS+PHjNX78eJ9ed+zYMbVs2bJR595yyy36wx/+oA0bNujnP/+5JOmHH37Q2rVrtWbNGh07dkyDBw/W008/LYfDob/+9a/KysrS7t27dc455/j8mYBGadlSOnTI6irCXki03MydO1epqamKjY1V3759tWXLltOe//bbb+vCCy9UbGysLr30Uq1ZsyZIlQKIFG3bttWgQYP0xhtveI4tX75c7dq103XXXacePXpo3Lhx6t69u9LS0jR9+nSdd955WrlypYVVA2gMy8PNsmXLlJ2drWnTpmn79u3q0aOHBg4cqIMHD9Z7/ieffKLf/OY3Gjt2rD7//HMNGzZMw4YN03//+98gV94wxgugOYuPj9exY8d82nbv3l1nwju73a7du3f79D6+zpA8YsQIvfPOO6qsrJQkvf7667rtttsUFRWlY8eO6YEHHtBFF12kNm3aqFWrVtq1a5f2799v2r0CECCGxfr06WOMHz/e87PT6TQ6depkzJw5s97zb731VmPIkCFex/r27WuMGzeuUdc7cuSIIck4cuSI/0XXY/jw4YYkQ5IRFRVlvPrqq6a+PxCqjh8/buzcudM4fvx4k97n1VdfNex2uyHJsNvtQfk7dPz4cSMhIcF45513jP379xs2m83Ytm2bYRiGMW7cOKNr167GihUrjP/93/819uzZY/To0cOYMGGC5/VdunQxXnzxxdO+vxn3Bs1Ieblh9O/v3srLra4mpPjy/W3pmJuqqipt27ZNkydP9hyLiopSZmamNm/eXO9rNm/erOzsbK9jAwcO1Lvvvlvv+ZWVlZ5/lUlSaWlp0ws/RVFRkd566y3Pzy6XS+PGjdPAgQOVnJxs+vWASDR27FgNHDhQe/fuVbdu3YLydyc2Nla//OUv9frrr2vv3r264IILdMUVV0iSPv74Y40aNUo333yzJPd4noKCgoDXhGbO5ZI+/PDEPvxiabg5fPiwnE6nkpKSvI4nJSXpyy+/rPc1xcXF9Z5fXFxc7/kzZ87Uk08+aU7BDdizZ0+dpzScTqf27t1LuAF8kJycHPS/MyNGjNDQoUP1xRdf6Le//a3neFpamlasWKGsrCzZbDZNmTKlzpNVAEKT5WNuAm3y5Mk6cuSIZyssLDT9GmlpafWOF+jWrZvp1wJgruuvv15nnXWWdu/erdtvv91z/IUXXlDbtm115ZVXKisrSwMHDvS06gAIbZa23LRr1052u10lJSVex0tKStShQ4d6X9OhQwefznc4HHI4HOYU3IDk5GQtXLhQ48aNk9PplN1u14IFC2i1AcJAVFSUDhw4UOd4amqqPvjgA69jpz6aTjcVEJosbbmJiYlRr169lJub6znmcrmUm5urjIyMel+TkZHhdb4krVu3rsHzg2Xs2LEqKCjQhg0bVFBQoLFjx1paDwAAzZXlk/hlZ2dr5MiR6t27t/r06aPZs2errKxMo0ePliTdeeed6ty5s2bOnClJmjBhgvr3769Zs2ZpyJAhWrp0qT777DMtXLjQyo8hyZrxAgAAwJvl4Wb48OE6dOiQpk6dquLiYvXs2VNr1671DBrev3+/13iWK6+8Um+88YYef/xxPfroo0pLS9O7776r7t27W/URAAAwj4/zNaEum3HqYz4RrrS0VImJiTpy5IgSEhKsLgcIexUVFcrPz9e5556r2NhYq8sJKdwbwDy+fH9H/NNSAIKjmf07qVG4J4A1CDcAmiQ6OlqSe8FMeKu9J7X3CEBwWD7mBkB4s9vtatOmjWc9uPj4eNlsNourspZhGCovL9fBgwfVpk0b2e12q0tCuKiokH71K/f+O+9IdGf6hXADoMlq55lqaMHb5qpNmzYNzsEF1MvplNasObEPvxBuADSZzWZTx44d1b59e1VXV1tdTkiIjo6mxQawCOEGgGnsdjtf6AAsx4BiAAAQUQg3AAAgohBuAABARGl2Y25qJ9UqLS21uBIAAE5RVnZiv7SUJ6ZOUvu93ZjJMZtduDl69KgkKSUlxeJKAAA4jU6drK4gJB09elSJiYmnPafZrS3lcrl04MABtW7d2vSJxkpLS5WSkqLCwkLWrQog7nNwcJ+Dg/scPNzr4AjUfTYMQ0ePHlWnTp28FtSuT7NruYmKilJycnJAr5GQkMBfnCDgPgcH9zk4uM/Bw70OjkDc5zO12NRiQDEAAIgohBsAABBRCDcmcjgcmjZtmhwOh9WlRDTuc3Bwn4OD+xw83OvgCIX73OwGFAMAgMhGyw0AAIgohBsAABBRCDcAACCiEG4AAEBEIdz4aO7cuUpNTVVsbKz69u2rLVu2nPb8t99+WxdeeKFiY2N16aWXas2aNUGqNLz5cp9feeUV9evXT23btlXbtm2VmZl5xv8ucPP1z3OtpUuXymazadiwYYEtMEL4ep9/+uknjR8/Xh07dpTD4dD555/P/zsawdf7PHv2bF1wwQWKi4tTSkqKJk2apIqKiiBVG57+9a9/KSsrS506dZLNZtO77757xtds3LhRV1xxhRwOh7p166YlS5YEvE4ZaLSlS5caMTExxqJFi4wvvvjCuPvuu402bdoYJSUl9Z7/8ccfG3a73XjuueeMnTt3Go8//rgRHR1t/Oc//wly5eHF1/t8++23G3PnzjU+//xzY9euXcaoUaOMxMREo6ioKMiVhxdf73Ot/Px8o3Pnzka/fv2Mm266KTjFhjFf73NlZaXRu3dvY/DgwcamTZuM/Px8Y+PGjUZeXl6QKw8vvt7n119/3XA4HMbrr79u5OfnG++//77RsWNHY9KkSUGuPLysWbPGeOyxx4wVK1YYkoy///3vpz1/3759Rnx8vJGdnW3s3LnT+Mtf/mLY7XZj7dq1Aa2TcOODPn36GOPHj/f87HQ6jU6dOhkzZ86s9/xbb73VGDJkiNexvn37GuPGjQtoneHO1/t8qpqaGqN169bGa6+9FqgSI4I/97mmpsa48sorjVdffdUYOXIk4aYRfL3PL7/8stG1a1ejqqoqWCVGBF/v8/jx443rr7/e61h2drZx1VVXBbTOSNKYcPPQQw8Zl1xyidex4cOHGwMHDgxgZYZBt1QjVVVVadu2bcrMzPQci4qKUmZmpjZv3lzvazZv3ux1viQNHDiwwfPh330+VXl5uaqrq3XWWWcFqsyw5+99fuqpp9S+fXuNHTs2GGWGPX/u88qVK5WRkaHx48crKSlJ3bt314wZM+R0OoNVdtjx5z5feeWV2rZtm6frat++fVqzZo0GDx4clJqbC6u+B5vdwpn+Onz4sJxOp5KSkryOJyUl6csvv6z3NcXFxfWeX1xcHLA6w50/9/lUDz/8sDp16lTnLxRO8Oc+b9q0STk5OcrLywtChZHBn/u8b98+ffDBBxoxYoTWrFmjvXv36t5771V1dbWmTZsWjLLDjj/3+fbbb9fhw4d19dVXyzAM1dTU6Pe//70effTRYJTcbDT0PVhaWqrjx48rLi4uINel5QYR5ZlnntHSpUv197//XbGxsVaXEzGOHj2qO+64Q6+88oratWtndTkRzeVyqX379lq4cKF69eql4cOH67HHHtP8+fOtLi2ibNy4UTNmzNC8efO0fft2rVixQqtXr9b06dOtLg0moOWmkdq1aye73a6SkhKv4yUlJerQoUO9r+nQoYNP58O/+1zr+eef1zPPPKP169frsssuC2SZYc/X+/z111+roKBAWVlZnmMul0uS1KJFC+3evVvnnXdeYIsOQ/78ee7YsaOio6Nlt9s9xy666CIVFxerqqpKMTExAa05HPlzn6dMmaI77rhDd911lyTp0ksvVVlZmX73u9/pscceU1QU//Y3Q0PfgwkJCQFrtZFouWm0mJgY9erVS7m5uZ5jLpdLubm5ysjIqPc1GRkZXudL0rp16xo8H/7dZ0l67rnnNH36dK1du1a9e/cORqlhzdf7fOGFF+o///mP8vLyPNuNN96o6667Tnl5eUpJSQlm+WHDnz/PV111lfbu3esJj5L01VdfqWPHjgSbBvhzn8vLy+sEmNpAabDkomks+x4M6HDlCLN06VLD4XAYS5YsMXbu3Gn87ne/M9q0aWMUFxcbhmEYd9xxh/HII494zv/444+NFi1aGM8//7yxa9cuY9q0aTwK3gi+3udnnnnGiImJMZYvX2589913nu3o0aNWfYSw4Ot9PhVPSzWOr/d5//79RuvWrY377rvP2L17t/Hee+8Z7du3N/74xz9a9RHCgq/3edq0aUbr1q2NN99809i3b5/xz3/+0zjvvPOMW2+91aqPEBaOHj1qfP7558bnn39uSDJeeOEF4/PPPze++eYbwzAM45FHHjHuuOMOz/m1j4I/+OCDxq5du4y5c+fyKHgo+stf/mKcc845RkxMjNGnTx/j008/9fyuf//+xsiRI73Of+utt4zzzz/fiImJMS655BJj9erVQa44PPlyn7t06WJIqrNNmzYt+IWHGV//PJ+McNN4vt7nTz75xOjbt6/hcDiMrl27Gk8//bRRU1MT5KrDjy/3ubq62njiiSeM8847z4iNjTVSUlKMe++91/jxxx+DX3gY2bBhQ73/v629tyNHjjT69+9f5zU9e/Y0YmJijK5duxqLFy8OeJ02w6D9DQAARA7G3AAAgIhCuAEAABGFcAMAACIK4QYAAEQUwg0AAIgohBsAABBRCDcAACCiEG4AAEBEIdwAgCSbzaZ3331XklRQUCCbzaa8vDxLawLgH8INAMuNGjVKNptNNptN0dHROvfcc/XQQw+poqLC6tIAhKEWVhcAAJJ0ww03aPHixaqurta2bds0cuRI2Ww2Pfvss1aXBiDM0HIDICQ4HA516NBBKSkpGjZsmDIzM7Vu3TpJksvl0syZM3XuuecqLi5OPXr00PLly71e/8UXX2jo0KFKSEhQ69at1a9fP3399deSpK1bt2rAgAFq166dEhMT1b9/f23fvj3onxFAcBBuAISc//73v/rkk08UExMjSZo5c6b++te/av78+friiy80adIk/fa3v9WHH34oSfr22291zTXXyOFw6IMPPtC2bds0ZswY1dTUSJKOHj2qkSNHatOmTfr000+VlpamwYMH6+jRo5Z9RgCBQ7cUgJDw3nvvqVWrVqqpqVFlZaWioqL00ksvqbKyUjNmzND69euVkZEhSeratas2bdqkBQsWqH///po7d64SExO1dOlSRUdHS5LOP/98z3tff/31XtdauHCh2rRpow8//FBDhw4N3ocEEBSEGwAh4brrrtPLL7+ssrIyvfjii2rRooV+9atf6YsvvlB5ebkGDBjgdX5VVZUuv/xySVJeXp769evnCTanKikp0eOPP66NGzfq4MGDcjqdKi8v1/79+wP+uQAEH+EGQEho2bKlunXrJklatGiRevTooZycHHXv3l2StHr1anXu3NnrNQ6HQ5IUFxd32vceOXKkvv/+e82ZM0ddunSRw+FQRkaGqqqqAvBJAFiNcAMg5ERFRenRRx9Vdna2vvrqKzkcDu3fv1/9+/ev9/zLLrtMr732mqqrq+ttvfn44481b948DR48WJJUWFiow4cPB/QzALAOA4oBhKRbbrlFdrtdCxYs0AMPPKBJkybptdde09dff63t27frL3/5i1577TVJ0n333afS0lLddttt+uyzz7Rnzx797W9/0+7duyVJaWlp+tvf/qZdu3bp3//+t0aMGHHG1h4A4YuWGwAhqUWLFrrvvvv03HPPKT8/X2effbZmzpypffv2qU2bNrriiiv06KOPSpJ+9rOf6YMPPtCDDz6o/v37y263q2fPnrrqqqskSTk5Ofrd736nK664QikpKZoxY4YeeOABKz8egACyGYZhWF0EAACAWeiWAgAAEYVwAwAAIgrhBgAARBTCDQAAiCiEGwAAEFEINwAAIKIQbgAAQEQh3AAAgIhCuAEAABGFcAMAACIK4QYAAESU/w91S5ZVNnuBJAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.4274745285511017  with F-Score 0.7895359701027717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca35544-5ba9-430b-dea1-5b58c5a0a683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 75.94552639006493 %\n",
            "Final Test Precision: 70.34414075467522 %\n",
            "Final Test Recall: 89.71210838272651 %\n",
            "Final Test F1 Score: 78.85629225330273 %\n"
          ]
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "    test_preds = utils.get_preds(test_outputs)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_correct += (test_preds == test_labels).sum().item()\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().detach().numpy(), test_preds.flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "tn, tp, fp, fn = CM[0][0], CM[1][1], CM[0][1], CM[1][0]  # true negative, ... false positive, etc\n",
        "acc_score = (tp + tn)/ (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "\n",
        "# model.train()\n",
        "test_accuracy = total_correct / total_predictions\n",
        "assert(test_accuracy == acc_score)\n",
        "# test_f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "print(f\"Final Test Accuracy: {test_accuracy * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = test_accuracy\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    # wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import roc_curve, plot_roc_curve,\n"
      ],
      "metadata": {
        "id": "ZT0UR8kxTws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "rest_nonacc_loader = torch.utils.data.DataLoader(rest_nonacc_dataset, batch_size=batch_size)#, shuffle=True)"
      ],
      "metadata": {
        "id": "4PrWYjD56kUY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "total_probs = torch.empty(0)  # tuples of probability, id\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in rest_nonacc_loader:  # tqdm()\n",
        "    samples, _ = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = torch.cat((total_probs, outputs))\n",
        "    # out_list = outputs.tolist()\n",
        "    # for i in range(len(out_list)):\n",
        "    #     probs_out.append(out_list[i])\n",
        "\n",
        "# falses = len(probs_out[probs_out<0.5])  # corrects\n",
        "preds = utils.get_preds(total_probs)\n",
        "corrects = len(preds[preds==NOT_ACCESSIBLE_LABEL])\n",
        "print(\"correctly predicted \", corrects, \" non_accessible values out of \", len(total_preds), \" total\")\n",
        "rest_non_correct = corrects / len(total_preds)\n",
        "\n",
        "print(rest_non_correct, \" correct (all not accessible)\")\n",
        "\n",
        "# wandb.summary['rest_nonacc_accuracy'] = rest_non_correct\n",
        "\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add87bdc-bc6a-4f1b-8105-a36451b8c8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/proper_rest_notacc01-04-20-24-24-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-04-20-24-24\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "CNNModel.save_CNNModel(model_save_path, model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"/content/pretrained/proper_rest_notacc01-04-20-24-24-CNNModel-model-0.0001lr-20epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e379b88a-2034-41f6-a0f2-6417c1598972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(\n",
        "    competition_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f38037-6ccc-4a7c-9a3f-358962af03b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd2EaK1Z9Rm9",
        "outputId": "52f23f40-3e07-4dc1-c2af-88b82f3b1442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 86495 true values out of  269315  total\n",
            "not accessible probs [7.72003546e-07 1.22001074e-06 1.32544631e-06 ... 4.99994636e-01\n",
            " 4.99995589e-01 4.99998689e-01]\n",
            "accessible probs [0.99668294 0.99629837 0.99512321 ... 0.500009   0.50000852 0.50000155]\n"
          ]
        }
      ],
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "print(\"Predicted\", len(np_probs[np_probs>0.5]), \"true values out of \", len(np_probs), \" total\")\n",
        "not_zero = np_probs[np_probs<=0.5]\n",
        "not_zero.sort()\n",
        "not_one = np_probs[np_probs>0.5]\n",
        "not_one[::-1].sort()\n",
        "print(\"not accessible probs\", not_zero)\n",
        "print(\"accessible probs\", not_one)\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG7R8WVS9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090d3a56-c2e7-45df-fe5e-9a2d77d38b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first 10\n",
            " ([0.9966829419136047], [0.9962983727455139], [0.9951232075691223], [0.99391770362854], [0.9935550093650818], [0.9931140542030334], [0.9928942322731018], [0.9927329421043396], [0.9923359751701355], [0.9920458793640137])\n",
            "last 10 of top 10000\n",
            " ([0.8520146012306213], [0.852008044719696], [0.8520078063011169], [0.8519814610481262], [0.8519793152809143], [0.8519764542579651], [0.8519759178161621], [0.8519702553749084], [0.8519678115844727], [0.8519659042358398])\n"
          ]
        }
      ],
      "source": [
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000\n",
        "\n",
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "2a6172f2-d9df-447c-a9d0-4ff78e4a251d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "5d48ac61-2cb3-4acd-e6b4-e45f77d17137"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8efd0a43-85cf-4068-a236-f23743916f04\", \"proper_rest_notacc01-04-20-24-24-CNNModel-model-0.0001lr-20epochs.pt\", 1758199)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "dir = 'pretrained'\n",
        "model_file = os.path.join(dir, os.listdir(dir)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "6e85f353-e9bf-4aca-dd3c-5151e99ceac9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36194848-fe7d-4944-a8dd-ed0b73321641\", \"predictions.zip\", 33505)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIQHJZ0gMsx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f350aaddeeea4fda89180c5165fdf1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1be7981eb554d849776479e34b38790",
              "IPY_MODEL_28d6ff3962ff4ee9881a815b28286293"
            ],
            "layout": "IPY_MODEL_7ab81ddf04194250a04925bb7d1d3b72"
          }
        },
        "e1be7981eb554d849776479e34b38790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a942874759c4fee819f60683c26aec6",
            "placeholder": "​",
            "style": "IPY_MODEL_54b5ff8adeda4690803ef936bfc42bb9",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "28d6ff3962ff4ee9881a815b28286293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8cb391aeee0417faa045e80d778d8c8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb00e50728aa404493561f384133aadb",
            "value": 1
          }
        },
        "7ab81ddf04194250a04925bb7d1d3b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a942874759c4fee819f60683c26aec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54b5ff8adeda4690803ef936bfc42bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8cb391aeee0417faa045e80d778d8c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb00e50728aa404493561f384133aadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}