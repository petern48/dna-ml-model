{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer\n",
        "- early stopping (less epochs)"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "# !pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ea32192c-83d7-4e34-d95f-85286d8783f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "5ce4780c-bd12-4b61-c81c-26b374f06332"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "# rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190a3687-840b-471a-c264-534c5bed2d86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd, random\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "# from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/sberbank-ai/ru-dalle/blob/e96631a867fcadcfaa52eecb20b1e42b88aa4386/rudalle/utils.py\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(1)"
      ],
      "metadata": {
        "id": "TqvTd3Ano27X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24ac8f8-c897-4fe2-bf7d-886ddceff79e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ef9974-ee2f-46c6-ce90-ac1c4af91827"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d3d75d-0160-4693-a321-719215082972"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "60952a43-906e-4c97-a386-fd7954e6f8fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ed356c-33c1-4925-c358-6d85ef9b98f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "l7SLRPi59Rm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd44a6e-08dd-4ce9-a29b-77d8859a3e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3344 total hidden\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (Convs): ModuleList(\n",
              "    (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=3200, out_features=32, bias=True)\n",
              "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "conv_filters = [32, 64]  # [64, 128]\n",
        "# num_filters1 = 64  # 64\n",
        "# num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "# hidden_dense1 = 64  # 64\n",
        "# hidden_dense2 = 32  # 32\n",
        "linear_neurons = [32, 16]  #[64,32]\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "# CNN = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "#                            hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                           linear_neurons, dropout_rate_Dense)\n",
        "total_hidden = sum(conv_filters) + sum(linear_neurons) - (4 + 1)\n",
        "print(f\"{total_hidden} total hidden\")\n",
        "CNN.to(device)  # quiet output\n",
        "# sum(linear_neurons)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Based on a test, using [1,pos_weight] gives the same results as [weight0, weight1]"
      ],
      "metadata": {
        "id": "Kx6jTrrcqZ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "# WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "WEIGHTED_LOSS = \"sklearn type weight\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weighted_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weighted_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()  # (reduction='none') ??\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = utils.macro_double_soft_f1\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ccaa0f-8865-486b-dfbf-85d9244c00b8"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor([10.1283], device='cuda:0')\n",
            "weight for class 0 tensor([2.1975], device='cuda:0')\n",
            "weight for class 1 tensor([22.2567], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "weight_decay = .01\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "# def seed_worker(worker_id):\n",
        "#     worker_seed = torch.initial_seed() % 2**32\n",
        "#     np.random.seed(worker_seed)\n",
        "#     random.seed(worker_seed)\n",
        "# g = torch.Generator()\n",
        "# g.manual_seed(0)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True\n",
        "note = f\"{conv_filters}-conv-{linear_neurons}-lin-{weight_decay}-weight-decay-adamW-{WEIGHTED_LOSS}\"\n",
        "note"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50419d3a-26bf-48a5-9fc6-6534c7c654ef"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[4, 32, 64]-conv-[3200, 32, 16, 1]-lin-0.01-weight-decay-adamW-sklearn type weight'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b5a0cc0-592c-4713-fe1a-a2690ada185a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240109_051018-1xlidor7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/petern0408/dna_ml_model/runs/1xlidor7' target=\"_blank\">[4, 32, 64]-conv-[3200, 32, 16, 1]-lin-0.01-weight-decay-adamW-sklearn type weight</a></strong> to <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/petern0408/dna_ml_model/runs/1xlidor7' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/1xlidor7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n",
            "Training Loss: 1.0244 Acc: 0.8193 F1: 0.2994\n",
            "          Precision 0.2298 Recall: 0.4298\n",
            "Validation Loss: 609.7683 Acc: 0.8431 \n",
            "          Precision 0.2573 Recall: 0.3943 F1: 0.3114\n",
            "\n",
            "Epoch 2 of 20\n",
            "Training Loss: 0.9476 Acc: 0.8252 F1: 0.3464\n",
            "          Precision 0.2608 Recall: 0.5157\n",
            "Validation Loss: 573.0140 Acc: 0.8568 \n",
            "          Precision 0.3069 Recall: 0.4703 F1: 0.3714\n",
            "\n",
            "Epoch 3 of 20\n",
            "Training Loss: 0.9104 Acc: 0.8365 F1: 0.3773\n",
            "          Precision 0.2868 Recall: 0.5512\n",
            "Validation Loss: 561.7834 Acc: 0.8617 \n",
            "          Precision 0.3212 Recall: 0.4821 F1: 0.3855\n",
            "\n",
            "Epoch 4 of 20\n",
            "Training Loss: 0.8901 Acc: 0.8412 F1: 0.3910\n",
            "          Precision 0.2982 Recall: 0.5674\n",
            "Validation Loss: 553.8445 Acc: 0.8656 \n",
            "          Precision 0.3339 Recall: 0.4961 F1: 0.3991\n",
            "\n",
            "Epoch 5 of 20\n",
            "Training Loss: 0.8731 Acc: 0.8444 F1: 0.4017\n",
            "          Precision 0.3069 Recall: 0.5812\n",
            "Validation Loss: 546.8661 Acc: 0.8670 \n",
            "          Precision 0.3395 Recall: 0.5055 F1: 0.4062\n",
            "\n",
            "Epoch 6 of 20\n",
            "Training Loss: 0.8582 Acc: 0.8469 F1: 0.4114\n",
            "          Precision 0.3143 Recall: 0.5954\n",
            "Validation Loss: 541.3402 Acc: 0.8682 \n",
            "          Precision 0.3448 Recall: 0.5159 F1: 0.4133\n",
            "\n",
            "Epoch 7 of 20\n",
            "Training Loss: 0.8454 Acc: 0.8493 F1: 0.4196\n",
            "          Precision 0.3209 Recall: 0.6063\n",
            "Validation Loss: 537.0410 Acc: 0.8697 \n",
            "          Precision 0.3499 Recall: 0.5220 F1: 0.4189\n",
            "\n",
            "Epoch 8 of 20\n",
            "Training Loss: 0.8342 Acc: 0.8512 F1: 0.4275\n",
            "          Precision 0.3267 Recall: 0.6180\n",
            "Validation Loss: 533.0868 Acc: 0.8697 \n",
            "          Precision 0.3521 Recall: 0.5337 F1: 0.4243\n",
            "\n",
            "Epoch 9 of 20\n",
            "Training Loss: 0.8246 Acc: 0.8529 F1: 0.4337\n",
            "          Precision 0.3316 Recall: 0.6268\n",
            "Validation Loss: 529.6742 Acc: 0.8698 \n",
            "          Precision 0.3541 Recall: 0.5424 F1: 0.4285\n",
            "\n",
            "Epoch 10 of 20\n",
            "Training Loss: 0.8160 Acc: 0.8543 F1: 0.4389\n",
            "          Precision 0.3356 Recall: 0.6342\n",
            "Validation Loss: 526.1651 Acc: 0.8698 \n",
            "          Precision 0.3557 Recall: 0.5510 F1: 0.4323\n",
            "\n",
            "Epoch 11 of 20\n",
            "Training Loss: 0.8082 Acc: 0.8557 F1: 0.4435\n",
            "          Precision 0.3394 Recall: 0.6398\n",
            "Validation Loss: 522.3123 Acc: 0.8688 \n",
            "          Precision 0.3548 Recall: 0.5600 F1: 0.4344\n",
            "\n",
            "Epoch 12 of 20\n",
            "Training Loss: 0.8010 Acc: 0.8571 F1: 0.4481\n",
            "          Precision 0.3431 Recall: 0.6455\n",
            "Validation Loss: 519.2028 Acc: 0.8687 \n",
            "          Precision 0.3560 Recall: 0.5678 F1: 0.4376\n",
            "\n",
            "Epoch 13 of 20\n",
            "Training Loss: 0.7943 Acc: 0.8580 F1: 0.4510\n",
            "          Precision 0.3455 Recall: 0.6491\n",
            "Validation Loss: 516.0587 Acc: 0.8682 \n",
            "          Precision 0.3562 Recall: 0.5761 F1: 0.4402\n",
            "\n",
            "Epoch 14 of 20\n",
            "Training Loss: 0.7880 Acc: 0.8591 F1: 0.4549\n",
            "          Precision 0.3487 Recall: 0.6542\n",
            "Validation Loss: 512.8840 Acc: 0.8668 \n",
            "          Precision 0.3549 Recall: 0.5875 F1: 0.4425\n",
            "\n",
            "Epoch 15 of 20\n"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"weight decay\": weight_decay,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "        if loss_fn.__class__.__name__ == \"function\":  # custom loss function\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels) #, [weight_class0, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "6678753525c14872ad6c96a120289e68",
            "3b4f94baef4c465892ec6eac7c509d21",
            "059456712d1241439d9bc497d0877e95",
            "44568e457c4f4931869975b403a559ae",
            "e41355aab7264abdbd81d9971ee026d8",
            "df48c1b7d4ed499294ef152e72b8f46d",
            "0c5406c1b9484500af1401fc2f692823",
            "3e6dc15844344c51b8d5c0cf6a5b833f"
          ]
        },
        "id": "fvZAvEIsoFo7",
        "outputId": "575c55c7-2c9a-40d6-a5bc-609865757378"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6678753525c14872ad6c96a120289e68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">[4, 16, 32, 64]-conv-[3200, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/7963j3om' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/7963j3om</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240109_050734-7963j3om/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# [4, 32, 64, 128]-conv-[6400, 64, 32, 1] resulted in\n",
        "# mat1 and mat2 shapes cannot be multiplied (128x3200 and 6400x64)\n",
        "\n",
        "# [4, 16, 32, 64]-conv-[3200, 64, 32, 1]-lin\n",
        "# mat1 and mat2 shapes cannot be multiplied (128x1600 and 3200x64)  # inside for loop of linears # flatten size prob not righ"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "# total_labels = np.empty(0)  # don't need to have same order\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "    # total_labels = np.concatenate((total_labels, labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "cb31e0fd-209d-4a70-8895-2773426d48a2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.8197534680366516 with F-Score 0.4757458899939111 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564,
          "referenced_widgets": [
            "61da0eb2943f4664a993a297eb9b0204",
            "301513c42d054f4387f0e78659d7c759",
            "fb49f659a8f742b2b24d417ef2897b99",
            "3640f89cb1454b10b78be18579cf829e",
            "cda0a553078c4a7592b293eb38b8061a",
            "730ce43e10cc4f0d9a8d55364e6cffe4",
            "ca9b5251d1ba4065bd0e723235cee4a9",
            "ae206ced482b45ba85f6e61046571163"
          ]
        },
        "outputId": "345fcfea-8210-468a-bda4-52d17d47143e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.8197534680366516\n",
            "Final Test Accuracy: 90.15873820874329 %\n",
            "Final Test Precision: 45.69166882948352 %\n",
            "Final Test Recall: 49.60552268244576 %\n",
            "Final Test F1 Score: 47.568224804107 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61da0eb2943f4664a993a297eb9b0204"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Train F1</td><td>▁▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▆▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Val Acc</td><td>▁▄▅▅▃▃▄▄▅▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>Val F1</td><td>▁▄▆▆▆▆▆▇▇▇██████████</td></tr><tr><td>Val Loss</td><td>▄▂▁▁▁▁▁▁▂▂▃▃▄▄▄▅▆▆▇█</td></tr><tr><td>Val Precision</td><td>▁▄▅▅▄▄▅▅▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>Val Recall</td><td>▁▂▄▅▇██▇▆▆▅▅▄▅▄▄▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.90185</td></tr><tr><td>Train F1</td><td>0.60046</td></tr><tr><td>Train Loss</td><td>0.49949</td></tr><tr><td>Train Precision</td><td>0.47339</td></tr><tr><td>Val Acc</td><td>0.87598</td></tr><tr><td>Val F1</td><td>0.46909</td></tr><tr><td>Val Loss</td><td>622.81818</td></tr><tr><td>Val Precision</td><td>0.38148</td></tr><tr><td>Val Recall</td><td>0.60893</td></tr><tr><td>test_accuracy</td><td>0.90159</td></tr><tr><td>test_f1_score</td><td>0.47568</td></tr><tr><td>test_precision</td><td>0.45692</td></tr><tr><td>test_recall</td><td>0.49606</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/0xtuzcz4' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/0xtuzcz4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240109_045102-0xtuzcz4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        test_outputs = sigmoid(test_outputs)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note: Actual Test {len(acc_seq_test)} accessible and {len(not_seq_test)} notaccessible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iniAmj4jhpX",
        "outputId": "a51d0cdf-cce0-452e-f200-6a6d28ace571"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Actual Test 7086 accessible and 71768 notaccessible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test on rest of nonaccessible\n",
        "# if DOWNSAMPLE:\n",
        "#     # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "#     rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "#     # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "#     CM = 0\n",
        "#     total_correct = 0\n",
        "#     total_predictions = 0\n",
        "#     model.eval()\n",
        "#     for batch in rest_notacc_loader:  # tqdm()\n",
        "#         samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "#         outputs = model(samples)\n",
        "#         preds = utils.get_preds(outputs)\n",
        "#         total_predictions += len(outputs)\n",
        "#         CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "#     # Computer accuracy, precision, recall, and f1 metrics\n",
        "#     acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "#     print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "#     print(f\"Rest not Precision: {precision * 100} %\")\n",
        "#     print(f\"Rest not Recall: {recall * 100} %\")\n",
        "#     print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "#     # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "#     # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r pretrained\n",
        "# !rm predictions.zip"
      ],
      "metadata": {
        "id": "N_USYmjft93K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f79f56-b7fe-4b72-f6bc-6e5ed74ca610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-05-05-08-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-09-05-05-08\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "CNNModel.save_CNNModel(model_save_path, CNN)  # model\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "QwvJ7kqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "fca51986-fa71-4490-d81b-d459a5be5875"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for CNNModel:\n\tMissing key(s) in state_dict: \"Convs.2.weight\", \"Convs.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tsize mismatch for Convs.0.weight: copying a param with shape torch.Size([128, 4, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3]).\n\tsize mismatch for Convs.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for Convs.1.weight: copying a param with shape torch.Size([256, 128, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3]).\n\tsize mismatch for Convs.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for linears.0.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([12800, 12800]).\n\tsize mismatch for linears.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([12800]).\n\tsize mismatch for linears.1.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([64, 12800]).\n\tsize mismatch for linears.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for linears.2.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for linears.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([32]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-6a4c75863c77>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the new path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/pretrained/[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-04-59-28-CNNModel-model-0.0001lr-20epochs.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_CNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CNNModel.py\u001b[0m in \u001b[0;36mload_CNNModel\u001b[0;34m(model_save_path)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mdropout_rate_Dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dropout_rate_Dense\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNModel:\n\tMissing key(s) in state_dict: \"Convs.2.weight\", \"Convs.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tsize mismatch for Convs.0.weight: copying a param with shape torch.Size([128, 4, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3]).\n\tsize mismatch for Convs.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for Convs.1.weight: copying a param with shape torch.Size([256, 128, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3]).\n\tsize mismatch for Convs.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for linears.0.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([12800, 12800]).\n\tsize mismatch for linears.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([12800]).\n\tsize mismatch for linears.1.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([64, 12800]).\n\tsize mismatch for linears.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for linears.2.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for linears.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([32])."
          ]
        }
      ],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"/content/pretrained/[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-04-59-28-CNNModel-model-0.0001lr-20epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef58b2ee-75ae-4d0c-a7ee-7ca570f3156e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64ff514-a4e5-49d8-eff1-a01d0c782b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=0.7]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.7]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "cb5ead5b-50b9-46b7-f7a6-8d78735af09d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 39832 true values out of  269315  total 14.790115663813749 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [4.43731841e-17 1.39795972e-16 1.48277114e-16 ... 6.99953020e-01\n",
            " 6.99996710e-01 6.99996889e-01]\n",
            "accessible probs [1.         0.99999988 0.99999976 ... 0.70002598 0.70001978 0.70001554]\n",
            "\n",
            "first 10\n",
            " ([1.0], [0.9999998807907104], [0.9999997615814209], [0.9999994039535522], [0.9999992847442627], [0.9999992847442627], [0.9999992847442627], [0.9999991655349731], [0.9999991655349731], [0.999998927116394])\n",
            "last 10 of top 10000\n",
            " ([0.9793400764465332], [0.9793400764465332], [0.9793326258659363], [0.9793269634246826], [0.9793263673782349], [0.9793241024017334], [0.9793235063552856], [0.9793227910995483], [0.9793142676353455], [0.9793060421943665])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "673e19d5-f384-4863-9539-40eb170e8e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "6dc7f784-d366-4149-f599-4715ee71907a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c483cfa7-f05a-4f14-b798-492f02132fab\", \"[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-04-59-28-CNNModel-model-0.0001lr-20epochs.pt\", 3693518)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "be4ce88f-c8c4-4a88-f213-b3f5ff726e1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a52adc2-f15e-4acd-94ec-e6fa11d06dde\", \"predictions.zip\", 33513)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6678753525c14872ad6c96a120289e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b4f94baef4c465892ec6eac7c509d21",
              "IPY_MODEL_059456712d1241439d9bc497d0877e95"
            ],
            "layout": "IPY_MODEL_44568e457c4f4931869975b403a559ae"
          }
        },
        "3b4f94baef4c465892ec6eac7c509d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41355aab7264abdbd81d9971ee026d8",
            "placeholder": "​",
            "style": "IPY_MODEL_df48c1b7d4ed499294ef152e72b8f46d",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "059456712d1241439d9bc497d0877e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5406c1b9484500af1401fc2f692823",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e6dc15844344c51b8d5c0cf6a5b833f",
            "value": 1
          }
        },
        "44568e457c4f4931869975b403a559ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41355aab7264abdbd81d9971ee026d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df48c1b7d4ed499294ef152e72b8f46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c5406c1b9484500af1401fc2f692823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6dc15844344c51b8d5c0cf6a5b833f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61da0eb2943f4664a993a297eb9b0204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_301513c42d054f4387f0e78659d7c759",
              "IPY_MODEL_fb49f659a8f742b2b24d417ef2897b99"
            ],
            "layout": "IPY_MODEL_3640f89cb1454b10b78be18579cf829e"
          }
        },
        "301513c42d054f4387f0e78659d7c759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cda0a553078c4a7592b293eb38b8061a",
            "placeholder": "​",
            "style": "IPY_MODEL_730ce43e10cc4f0d9a8d55364e6cffe4",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "fb49f659a8f742b2b24d417ef2897b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca9b5251d1ba4065bd0e723235cee4a9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae206ced482b45ba85f6e61046571163",
            "value": 1
          }
        },
        "3640f89cb1454b10b78be18579cf829e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda0a553078c4a7592b293eb38b8061a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730ce43e10cc4f0d9a8d55364e6cffe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca9b5251d1ba4065bd0e723235cee4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae206ced482b45ba85f6e61046571163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}