{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e23fcb-7340-4732-f7fa-9333882cd169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpetern0408\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "99a504a1-d28a-44bf-ebfa-6c44e9e25954"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca84a195-f1d6-4b08-9e47-1538df19acba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "!unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# assert(self.accessible_count + self.not_accessible_count == len(self.sequences))\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = True\n",
        "\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "assert(len(actual_acc_seq_train) == len(actual_not_seq_train))  # ensure the data is now equal\n",
        "\n",
        "print(\"Actual acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))\n",
        "assert(len(actual_acc_seq_train) == len(actual_not_seq_train))  # ensure the data is now equal"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd60d71d-0c6f-442f-c8ee-a163de5fc78d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rest not seq and labs  301847 301847\n",
            "Actual not seq and labs  33067 33067\n",
            "Actual acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326dd332-c561-4080-d3b9-150f400e8f2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 66134\n",
            "val samples 78853\n",
            "test samples 78854\n",
            "rest not samples 301847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "# except:\n",
        "#   print(rest_not_sequences)\n",
        "#   raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "cc23b752-a83f-4532-d282-710e31ba7d17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd30d7d-3194-417c-9076-6d96d5a68014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "num_filters1 = 64  # 128\n",
        "num_filters2 = 128  # 64\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 128\n",
        "hidden_dense2 = 32  # 64\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "model = CNNModel.CNNModel(kernel_size,\n",
        "                           embed_dim,\n",
        "                           num_filters1,\n",
        "                           num_filters2,\n",
        "                           pool_kernel_size,\n",
        "                           hidden_dense1,\n",
        "                           hidden_dense2,\n",
        "                           dropout_rate_Dense\n",
        "                           )\n",
        "\n",
        "model.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "USE_WEIGHTED_LOSS = True\n",
        "# USE_WEIGHTED_LOSS = True  # Note may not work correctly if used with resampling bc my code\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "# weight_class0 = num_train / len(actual_acc_seq_train) * 2\n",
        "# weight_class1 = num_train / len(actual_not_seq_train) * 2\n",
        "weight_class1 = torch.Tensor([len(actual_not_seq_train) / len(actual_acc_seq_train)])\n",
        "# print(\"weights for class 0\", weight_class0)\n",
        "print(\"weights for class 1\", weight_class1)\n",
        "\n",
        "\n",
        "if USE_WEIGHTED_LOSS:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=weight_class1)\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # loss_fn = nn.BCELoss()\n",
        "\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\":\n",
        "    model = nn.Sequential(\n",
        "      model,\n",
        "      nn.Softmax()\n",
        "    )\n",
        "    print(\"Added softmax\")"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1986c9-85b3-41ac-d991-58a727f3b7d6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights for class 1 tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = .0001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "XsGb6Nm49Rm8"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"weighted-bcelogits-loss\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.flatten().detach().numpy(), preds.flatten().detach().numpy())\n",
        "\n",
        "    # f1 = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "# which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(\"Best Threshold\", thresholds[ix], \" with F-Score\", fscores[ix])\n",
        "# Best Threshold 42.7"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "bca07795-134c-4699-bb27-9b1235247b5b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.5762635469436646  with F-Score 0.43242542153047986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d1ee7d-f812-4b1d-f15c-4b54e5a810e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 85.08002130519695 %\n",
            "Final Test Precision: 32.602067375622816 %\n",
            "Final Test Recall: 61.86847304544172 %\n",
            "Final Test F1 Score: 42.70199191545318 %\n"
          ]
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().detach().numpy(), test_preds.flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "# test_f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    # wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import roc_curve, plot_roc_curve,\n"
      ],
      "metadata": {
        "id": "ZT0UR8kxTws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "\n",
        "    # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "    CM = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch in rest_notacc_loader:  # tqdm()\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "        outputs = model(samples)\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "\n",
        "        total_predictions += len(outputs)\n",
        "\n",
        "        CM += confusion_matrix(labels.flatten().detach().numpy(), preds.flatten().detach().numpy())\n",
        "\n",
        "    # Computer accuracy, precision, recall, and f1 metrics\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "    print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "    print(f\"Rest not Precision: {precision * 100} %\")\n",
        "    print(f\"Rest not Recall: {recall * 100} %\")\n",
        "    print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "\n",
        "    # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad01e06-5545-437d-8656-ce65522a45af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/bce-loss-42.7-threshold01-06-00-00-21-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-06-00-00-21\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "CNNModel.save_CNNModel(model_save_path, model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"/content/pretrained/bce_logits-loss01-05-22-23-56-CNNModel-model-0.0001lr-20epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae334ad-5bfb-4ebb-8610-af1ca5f988e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(\n",
        "    competition_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc56de9-a270-4026-feb2-ebe5dbacee90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    outputs = sigmoid(outputs)\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "print(\"Predicted\", len(np_probs[np_probs>0.5]), \"true values out of \", len(np_probs), \" total\")\n",
        "not_zero = np_probs[np_probs<=0.5]\n",
        "not_zero.sort()\n",
        "not_one = np_probs[np_probs>0.5]\n",
        "not_one[::-1].sort()\n",
        "print(\"not accessible probs\", not_zero)\n",
        "print(\"accessible probs\", not_one)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "beacbed4-5160-4838-9e13-d00fb208487c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 82911 true values out of  269315  total\n",
            "not accessible probs [1.32548794e-05 1.45798476e-05 1.60629115e-05 ... 4.99996543e-01\n",
            " 4.99998093e-01 4.99998748e-01]\n",
            "accessible probs [0.99272341 0.98870754 0.98862106 ... 0.50000262 0.50000191 0.50000042]\n",
            "\n",
            "first 10\n",
            " ([0.9927234053611755], [0.9887075424194336], [0.9886210560798645], [0.9885435104370117], [0.9880626201629639], [0.9875513911247253], [0.9871780872344971], [0.9863091707229614], [0.9859872460365295], [0.9858021140098572])\n",
            "last 10 of top 10000\n",
            " ([0.8112214803695679], [0.811202347278595], [0.811194658279419], [0.8111787438392639], [0.8111633658409119], [0.8111633062362671], [0.8111633062362671], [0.8111603856086731], [0.8111596703529358], [0.811154842376709])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "ae7efe0b-b1fb-4c36-d35b-9f9771e39e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "6ba0f991-7ce0-4a58-ea18-100ec767944e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4aff0d4-4734-4aa5-a76b-3ba3ae008bd5\", \"bce_logits-loss01-05-22-23-56-CNNModel-model-0.0001lr-20epochs.pt\", 1757886)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(dir)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "4154450f-515c-42f1-bb04-e59cae931530"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3efa407e-3d4d-45a1-b8c6-479cfef0c2f5\", \"predictions.zip\", 33472)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}