{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "dc9a5681-76a8-40a1-b548-140aa38db65b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "e123c7ed-17fa-418f-cfca-1a98703d5a01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb7e1ab-f826-4e0d-93ba-581158064a3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "!unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# assert(self.accessible_count + self.not_accessible_count == len(self.sequences))\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "\n",
        "print(\"Actual not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62a2ff6-2977-4e5c-d347-7bbccd78dddf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual not seq and labs  334914 334914\n",
            "Actual acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d895e2c-4727-4d62-edaa-1c512b10407b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "# except:\n",
        "#   print(rest_not_sequences)\n",
        "#   raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "cc23b752-a83f-4532-d282-710e31ba7d17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28570f4-731b-461d-b99b-fd8c6a9616ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "num_filters1 = 64  # 64\n",
        "num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 64\n",
        "hidden_dense2 = 32  # 32\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "model = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "                           hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "\n",
        "model.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "USE_WEIGHTED_LOSS = True\n",
        "# USE_WEIGHTED_LOSS = True  # Note may not work correctly if used with resampling bc my code\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "# weight_class0 = num_train / len(actual_acc_seq_train) * 2\n",
        "# weight_class1 = num_train / len(actual_not_seq_train) * 2\n",
        "weight_class1 = torch.Tensor([len(actual_not_seq_train) / len(actual_acc_seq_train)]).to(device)\n",
        "# print(\"weights for class 0\", weight_class0)\n",
        "print(\"weights for class 1\", weight_class1)\n",
        "\n",
        "\n",
        "if USE_WEIGHTED_LOSS:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=weight_class1)\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # loss_fn = nn.BCELoss()\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\":\n",
        "    model = nn.Sequential(\n",
        "      model,\n",
        "      nn.Softmax()\n",
        "    )\n",
        "    print(\"Added softmax\")\n",
        "    model.to(device)"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f52a53-6298-4b65-bffd-2184e6a73eae"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights for class 1 tensor([10.1283,  0.0000], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = .0001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "XsGb6Nm49Rm8"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "8z_gnhTp9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "1f222258-93a7-4cd8-ed27-e9d6751af935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (2) must match the size of tensor b (64) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-3635a009116a>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#     outputs *= not_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    726\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (64) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"weighted-bcelogits-loss\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # f1 = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(\"Best Threshold\", thresholds[ix], \" with F-Score\", fscores[ix])\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "caeb261e-72c1-4a23-8a03-a5af3b158efd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.7940000891685486  with F-Score 0.50150640220939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "4cb15afa4fed4e31971ceeeef123c930",
            "b4cde2cb0e834b6d9775a9446f4c3f47",
            "e777fa1a51324f7488566699cebcfd81",
            "9b3de30835bd4670a1746623501ae3b7",
            "21db0736cbe044ffa1713c4b16bc089b",
            "5cf9fec6eba54f5d92a7b40225321ebd",
            "d8c47eb276d542d8b11bbe989aa818ec",
            "eac6739f24c74df7979d30e00375d315"
          ]
        },
        "outputId": "b876ea66-7cf8-47c2-ea70-a2c9b8e94023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 85.55634445684146 %\n",
            "Final Test Precision: 35.03415586226126 %\n",
            "Final Test Recall: 70.80867850098619 %\n",
            "Final Test F1 Score: 46.87558291363552 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cb15afa4fed4e31971ceeeef123c930"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Train F1</td><td>▁▃▄▄▅▆▆▆▆▇▇▇▇▇█▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Val Acc</td><td>▂▅▃▂▃▄█▂▇▇█▆▇▁▅▃▆▆▄▄</td></tr><tr><td>Val F1</td><td>▁▃▄▄▅▆▇▅▇████▅█▆██▇▇</td></tr><tr><td>Val Loss</td><td>█▆▄▄▃▃▅▂▃▂▄▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Val Precision</td><td>▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Val Recall</td><td>▂▂▄▆▆▅▁▇▃▄▂▄▄█▅▇▅▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.88459</td></tr><tr><td>Train F1</td><td>0.37656</td></tr><tr><td>Train Loss</td><td>0.97516</td></tr><tr><td>Train Precision</td><td>0.36591</td></tr><tr><td>Val Acc</td><td>0.85354</td></tr><tr><td>Val F1</td><td>0.46406</td></tr><tr><td>Val Loss</td><td>1346.75211</td></tr><tr><td>Val Precision</td><td>0.36591</td></tr><tr><td>Val Recall</td><td>0.70562</td></tr><tr><td>test_accuracy</td><td>0.85556</td></tr><tr><td>test_f1_score</td><td>0.46876</td></tr><tr><td>test_precision</td><td>0.35034</td></tr><tr><td>test_recall</td><td>0.70809</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">weighted-bcelogits-loss</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/uf4qdgei' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/uf4qdgei</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240106_011517-uf4qdgei/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "# test_f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import roc_curve, plot_roc_curve,\n"
      ],
      "metadata": {
        "id": "ZT0UR8kxTws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "\n",
        "    # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "    CM = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch in rest_notacc_loader:  # tqdm()\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "        outputs = model(samples)\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "\n",
        "        total_predictions += len(outputs)\n",
        "\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Computer accuracy, precision, recall, and f1 metrics\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "    print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "    print(f\"Rest not Precision: {precision * 100} %\")\n",
        "    print(f\"Rest not Recall: {recall * 100} %\")\n",
        "    print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "\n",
        "    # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b06647-78fe-4d57-f4ef-dc29c34e45ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/weighted-bcelogits-loss01-06-01-42-36-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-06-01-42-36\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "CNNModel.save_CNNModel(model_save_path, model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"/content/pretrained/bce_logits-loss01-05-22-23-56-CNNModel-model-0.0001lr-20epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254b63a3-0ac5-4b85-ffeb-620b9c531955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74481a2e-ca30-432a-8da4-fa3ac0400e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "      outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "print(\"Predicted\", len(np_probs[np_probs>0.5]), \"true values out of \", len(np_probs), \" total\")\n",
        "not_probs = np_probs[np_probs<=0.5]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.5]\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "7d57742d-ab3d-4cd5-d1ca-3e634131275e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 83197 true values out of  269315  total\n",
            "\n",
            "not accessible probs [1.98550015e-06 2.92281084e-06 3.61552907e-06 ... 4.99990463e-01\n",
            " 4.99996781e-01 4.99999762e-01]\n",
            "accessible probs [0.99592578 0.99531186 0.99483079 ... 0.50000691 0.50000435 0.50000024]\n",
            "\n",
            "first 10\n",
            " ([0.995925784111023], [0.9953118562698364], [0.9948307871818542], [0.9936961531639099], [0.9934900999069214], [0.9922768473625183], [0.9922347068786621], [0.991955578327179], [0.9913842678070068], [0.9910812973976135])\n",
            "last 10 of top 10000\n",
            " ([0.8389458060264587], [0.8389316201210022], [0.8389198780059814], [0.838890016078949], [0.8388887643814087], [0.8388871550559998], [0.8388866186141968], [0.8388849496841431], [0.8388733863830566], [0.8388683795928955])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "bda39b27-7d8d-498f-b692-00127b69c4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "a09ca10f-5db8-47da-ce7c-2cee355bc5d4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_984cb6d8-573e-4a36-a5f0-16dc6545c29e\", \"weighted-bcelogits-loss01-06-01-42-36-CNNModel-model-0.0001lr-20epochs.pt\", 1758422)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "f7af270c-c526-46b4-ec3f-e2d201aeff14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e09daca5-ac43-4687-ba83-741387c7fc34\", \"predictions.zip\", 33476)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4cb15afa4fed4e31971ceeeef123c930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4cde2cb0e834b6d9775a9446f4c3f47",
              "IPY_MODEL_e777fa1a51324f7488566699cebcfd81"
            ],
            "layout": "IPY_MODEL_9b3de30835bd4670a1746623501ae3b7"
          }
        },
        "b4cde2cb0e834b6d9775a9446f4c3f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21db0736cbe044ffa1713c4b16bc089b",
            "placeholder": "​",
            "style": "IPY_MODEL_5cf9fec6eba54f5d92a7b40225321ebd",
            "value": "0.017 MB of 0.017 MB uploaded\r"
          }
        },
        "e777fa1a51324f7488566699cebcfd81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c47eb276d542d8b11bbe989aa818ec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eac6739f24c74df7979d30e00375d315",
            "value": 1
          }
        },
        "9b3de30835bd4670a1746623501ae3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21db0736cbe044ffa1713c4b16bc089b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf9fec6eba54f5d92a7b40225321ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8c47eb276d542d8b11bbe989aa818ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac6739f24c74df7979d30e00375d315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}