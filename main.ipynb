{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer\n",
        "- early stopping (less epochs)"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "# !pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4616f86a-82f5-4c98-d43f-ae3e84d02b6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "86882de5-ff6f-46c4-cf2a-01ee9eb5e715"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "# rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0f586d-e08a-49db-a91a-a399edbacacf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd, random\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "# from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e35dc63-120e-4628-f708-ec94eaf8f8f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6994a83-8efc-4640-eda0-b69619d82daf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bfd97d-930f-4867-8fc8-1f3f4a026062"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "dbdceab7-c6b8-498f-a099-4486c222c98b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad34bc6-7be0-43f3-8123-f53f0326c665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "l7SLRPi59Rm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53a5185-5fcd-43db-f70e-09a531434d9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (Convs): ModuleList(\n",
              "    (0): Conv1d(4, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=6400, out_features=64, bias=True)\n",
              "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "conv_filters = [64,128]\n",
        "num_filters1 = 64  # 64\n",
        "num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 64\n",
        "hidden_dense2 = 32  # 32\n",
        "linear_neurons = [64, 32]\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "# CNN = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "#                            hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                           linear_neurons, dropout_rate_Dense)\n",
        "\n",
        "CNN.to(device)  # quiet output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure out why list is not working. maybe it's not updating weights?"
      ],
      "metadata": {
        "id": "6HshS-JkAvdt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNNModel(\n",
        "#   (Conv1): Conv1d(4, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
        "#   (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "#   (Conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
        "#   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
        "#   (linear1): Linear(in_features=6400, out_features=64, bias=True)\n",
        "#   (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
        "#   (linear3): Linear(in_features=32, out_features=1, bias=True)\n",
        "#   (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "#   (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
        "#   (sigmoid): Sigmoid()\n",
        "# )"
      ],
      "metadata": {
        "id": "PBVcHu2k9xTp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Based on a test, using [1,pos_weight] gives the same results as [weight0, weight1]"
      ],
      "metadata": {
        "id": "Kx6jTrrcqZ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "# WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "WEIGHTED_LOSS = \"sklearn type weight\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weighted_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weighted_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()  # (reduction='none') ??\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = utils.macro_double_soft_f1\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814cfdd6-eb6d-4f73-ddbd-f09fd1344d35"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor([10.1283])\n",
            "weight for class 0 tensor([2.1975])\n",
            "weight for class 1 tensor([22.2567])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "weight_decay = .01\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"test-list-{weight_decay}-weight-decay-adamW-{WEIGHTED_LOSS}\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "        if loss_fn.__class__.__name__ == \"function\":  # custom loss function\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels) #, [weight_class0, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "# total_labels = np.empty(0)  # don't need to have same order\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "    # total_labels = np.concatenate((total_labels, labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "d113c44d-6834-4b8c-dce7-0f9ccb1bb90d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAd0lEQVR4nO3deXQV9f3/8ddku0mAhH3NlaCAgiIoEA4idflGKAhU2ypVq4CibcX+0IgLLmBFwRWxghuC0H79Fiqlle2LYgSryFcQxGMVWYQIEQJBhJCErPfz+yMmEAjh3pu5d+7yfJwz50wmM5N3RmJe+cxnsYwxRgAAABEixukCAAAA7ES4AQAAEYVwAwAAIgrhBgAARBTCDQAAiCiEGwAAEFEINwAAIKLEOV1AsHk8Hu3du1dNmjSRZVlOlwMAALxgjNHRo0fVvn17xcTU3zYTdeFm7969crvdTpcBAAD8sGfPHqWlpdV7TtSFmyZNmkiqejgpKSkOVwMgIhUVSe3bV+3v3Ss1auRsPUAEKCgokNvtrvk9Xp+oCzfVr6JSUlIINwACIzb2+H5KCuEGsJE3XUroUAwAACIK4QYAAESUqHstBQABFxcnjRp1fB9AUPFTBwB2c7mkefOcrgIhxOPxqKyszOkyQl5CQsIZh3l7g3ADAEAAlZWVadeuXfJ4PE6XEvJiYmLUqVMnJSQkNOg+hBsAsJsxUnFx1X5yssSEoVHLGKN9+/YpNjZWbrfbllaJSFU9ye6+fft01llnNWiiXcINANituFhq3Lhqv7CQoeBRrKKiQsXFxWrfvr2Sk5OdLifktWrVSnv37lVFRYXi4+P9vg8REgCAAKmsrJSkBr9miRbVz6n6ufmLcAMAQICxlqF37HpOhBsAABBRHA03//73vzV8+HC1b99elmXpX//61xmvWbNmjS6++GK5XC517txZ8xhuCQAATuBouCkqKlLPnj01a9Ysr87ftWuXrr76al1xxRXavHmz7r77bo0dO1bvvvtugCv1zogRI9SkSRONGDHC6VIAAIhajo6WGjJkiIYMGeL1+a+++qo6deqk559/XpLUrVs3ffzxx3rhhRc0ePDgQJXplZiYGBljJElLly5VTEwMcxoAAMLW5Zdfrl69emnGjBm23G/06NE6fPiwV29pGiqs+tysW7dOmZmZtY4NHjxY69atO+01paWlKigoqLXZbcSIETXBppoxhhYcIFrFxkq//nXVduIK4UAD5ObmavXq1crNzXW6lJAXVuEmLy9Pbdq0qXWsTZs2Kigo0LFjx+q8Ztq0aUpNTa3Z3G637XWtXr3ap+MAIlxiovT221VbYqLT1SCEGGNUVFTk8/byyy+rY8eOuvLKK9WxY0e9/PLLPt/j5D/C6zN69Gh9+OGHevHFF2VZlizLUk5Ojv7zn/9oyJAhaty4sdq0aaObb75ZBw8erLlu0aJF6tGjh5KSktSiRQtlZmaqqKhIjz32mObPn6933nmn5n5r1qwJwBOuEvGT+E2cOFFZWVk1HxcUFNgecK644gotXbq0zuMAAFQrLi5W4+oJHv3k8Xg0btw4jRs3zqfrCgsL1cjLCSVffPFFbdu2TRdccIEef/xxSVJ8fLwyMjI0duxYvfDCCzp27JgeeOABXX/99frggw+0b98+3XDDDXrmmWd07bXX6ujRo/roo49kjNGECRO0ZcsWFRQU6M0335QkNW/e3Ldv3AdhFW7atm2r/fv31zq2f/9+paSkKCkpqc5rXC6XXC5XQOtasmRJrT43UtVY/SVLlgT06wIAEAipqalKSEhQcnKy2rZtK0l64okndNFFF2nq1Kk1582dO1dut1vbtm1TYWGhKioq9Mtf/lIdO3aUJPXo0aPm3KSkJJWWltbcL5DCKtz0799fK1asqHVs1apV6t+/v0MVHefxeNS+fXvt27dP3bt311dffeV0SQCcUlTE8guoU3JysgoLC3265vvvv1e3bt1qDVKJjY3V119/rQ4dOvj0tRviiy++0OrVq+tsefr22281aNAg/dd//Zd69OihwYMHa9CgQfr1r3+tZs2aNejr+sPRcFNYWKgdO3bUfLxr1y5t3rxZzZs311lnnaWJEyfq+++/11/+8hdJ0u9//3vNnDlT999/v2699VZ98MEH+vvf/67ly5c79S3UcuWVV+qtt97S2LFjnS4FABCCLMvy+tVQta5du+r111/X7373O1VWVio2NlavvfaaunbtGqAq61ZYWKjhw4fr6aefPuVz7dq1U2xsrFatWqVPPvlE7733nl566SU9/PDD+vTTT9WpU6eg1upouPnss89q9Uup7hszatQozZs3T/v27dPu3btrPt+pUyctX75c99xzj1588UWlpaXpjTfecHwYOAAAgXTbbbdp8ODB2rFjhzp37qy0tLSAf82EhIRaazxdfPHF+sc//qH09HTFxdUdHyzL0oABAzRgwABNmjRJHTt21D//+U9lZWWdcr9AcjTcXH755fX23q5r9uHLL79cn3/+eQCrAgAg9KSlpQUl1FRLT0/Xp59+qpycHDVu3Fjjxo3T7NmzdcMNN+j+++9X8+bNtWPHDi1YsEBvvPGGPvvsM2VnZ2vQoEFq3bq1Pv30U+Xn56tbt24193v33Xe1detWtWjRQqmpqQ1a+bs+YTUUPFz4MtwOAIBQNGHCBMXGxqp79+5q1aqVysrKtHbtWlVWVmrQoEHq0aOH7r77bjVt2lQxMTFKSUnRv//9bw0dOlRdu3bVI488oueff75mst7bb79d5557rvr06aNWrVpp7dq1Aas9rDoUhzpWfQUARIquXbvWOUnu4sWL6zy/W7duWrly5Wnv16pVK7333nu21VcfWm4AAEBEoeUGAOwWGysNHXp8H0BQEW4CgD43QJRLTJRCZIoKIBrxWspG9LkBANSFP3q9Y9dzItwAABAgsT+9liwrK3O4kvBQ/ZxiG/g6l9dSAGC3oiKpdeuq/QMHWH4hisXFxSk5OVn5+fmKj49XTAxtCqfj8XiUn5+v5OTk004S6C3CTQDQ/AhAxcVOV4AQYFmW2rVrp127dum7775zupyQFxMTo7POOqvB3TwINzaizw0A4GQJCQnq0qULr6a8kJCQYEvrFuEGAIAAi4mJUWJiotNlRA1e/gEAgIhCuAkA+twAAOAcwo2N6HMDAIDz6HMDAHaLiZEuu+z4PoCgItwEAK+lgCiXlCStWeN0FUDU4k8KG/FaCgAA5xFuAABARCHcAIDdioqkVq2qtqIip6sBog59bgKAPjcAdPCg0xUAUYuWGxvR5wYAAOcRbgAAQEQh3ATAt99+q9zcXKfLAAAgKhFubPTll19KkmbPnq2zzjpLjzzyiKZPn64NGzY4XBkAANGDDsU2ee655/TZZ5/VfGyM0ZNPPlnz8dVXX61ly5Y5URoAAFGFlhsb5Obm6v7776/3nOXLl+vqq68OUkUAHBUTI/XpU7Wx/AIQdPzU2WD79u1eDf9esWIFr6iAaJCUJG3YULUlJTldDRB1CDc26NKli2K8/OvshRdeCHA1AABEN8KNDdLS0nTVVVd5de6nn34a4GoAAIhuhBsb5ObmatWqVV6dW1paGuBqADiuuFhKT6/aioudrgaIOoyWssH27dvl8Xi8OrdVq1YBrgaA44yRvvvu+D6AoKLlxgZdunTxeumFlJSUAFcDAEB0I9zYIC0tTdddd51X56ampga4GgAAohvhxiZDhgzx6rylS5eqSZMmAa4GAIDoRbixyaFDh7w+t7CwUL/5zW8CWA0AANGLcGOT5s2b+3T+woULNWDAgABVAwBA9CLc2GTnzp0+X/PJJ5+w3hQQiSxL6t69avNysAEA+xBubNKuXTu/rps6darNlQBwXHKy9NVXVVtystPVAFGHcGMTt9vt13V79+61uRIAAKIb4cYm27Zt8+u6s846y+ZKAACIboQbmwwcONCv684991ybKwHguOJi6fzzqzaWXwCCjuUXgiApKUnHjh2r83O9e/cOcjUAAs4Y6euvj+8DCCpabmzy0UcfnfZzTzzxxGk/l5iYGIhyAACIWoQbm3Tt2vW0n3O73aftW7N8+fJAlQQAQFQi3NikUaNG9X4+MzOzzuPvvfdeIMoBACBqEW5s0rhx49N+rn///rr22mvr/FxBQYG6desWqLIAAIg6hBubFBYW1nl8woQJSktL0549e0577TfffMNMxQAA2IRwY5MuXbqcciw2Nlbjx4+XJG3durXe65mpGIggliV17Fi1sfwCEHQMBbdJWlraKcd++9vf1hx3uVz1Xr9r166A1AXAAcnJUk6O01UAUYuWG5vk5uaecuy///u/a46fKdzk5eVpzpw5AakNAIBoQrixyfbt2085VllZqR07dkiShg8ffsZ7jB07ts6QBAAAvEe4scnp+tx07txZktS3b18NHjz4jPeZOXOm7bUBCLJjx6S+fau208xODiBwCDc2effdd2t9bFmWXnvttVp9cd54440z3mfp0qW21wYgyDwe6bPPqjaPx+lqgKhDuLFBbm6u7rjjjlrHYmJiTmmpSUtL08MPP1zvvQ4fPmx3eQAARBXCjQ22b98uz0l/nZ3Y3+ZETzzxhGJiTv/Y9+7dqw0bNtheIwAA0YJwY4MuXbqcElhO7G9zsubNm9d7v4yMDEZOAQDgJ8KNDdLS0vT6668rNjZWUlWwObm/zYkuueSSM96TkVMAAPiHcGOT2267TTk5OVq9erVycnJ02223nfbcRx55xKt7rlu3zq7yAACIGoQbG6Wlpenyyy8/bYtNtb59++q666474/1Wr15tV2kAgq1ly6oNQNARbhzy97//XRdddFG957z99tt0LgbCUaNGUn5+1daokdPVAFGHcOOgJUuW1Pv5gwcPKiMjQ+eddx6rhgMA4CXCjYPS0tK8mthv69atGj58uC688MJax5ctW6ZbbrlFU6dOpfMxAAA/sYwxxukigqmgoECpqak6cuSIUlJSnC5HUtXQ8B9//NGrc5s2bar27dvr66+/PuVzb7zxRr0dmQEEybFj0pAhVfv/+79SUpKz9QARwJff34633MyaNUvp6elKTExUv379tH79+nrPnzFjhs4991wlJSXJ7XbrnnvuUUlJSZCqDYxGPryTP3z4cJ3BRqoaPp6YmKjp06fbVRoAf3g80ocfVm0svwAEnaPhZuHChcrKytLkyZO1adMm9ezZU4MHD9aBAwfqPP9//ud/9OCDD2ry5MnasmWL5syZo4ULF+qhhx4KcuX2Ot1kf/4oLS3Vvffeq9atW9t2TwAAwomj4Wb69Om6/fbbNWbMGHXv3l2vvvqqkpOTNXfu3DrP/+STTzRgwADdeOONSk9P16BBg3TDDTecsbUn1N1777223zM/P58WHABAVHIs3JSVlWnjxo3KzMw8XkxMjDIzM087ed0ll1yijRs31oSZnTt3asWKFRo6dOhpv05paakKCgpqbaFm2LBhXs1a7KsXXnjB9nsCABDqHAs3Bw8eVGVlpdq0aVPreJs2bZSXl1fnNTfeeKMef/xxXXrppYqPj9c555yjyy+/vN7XUtOmTVNqamrN5na7bf0+7LJ27VotXbpUHTp0sO2ejKACAEQjxzsU+2LNmjWaOnWqXn75ZW3atEmLFy/W8uXLNWXKlNNeM3HiRB05cqRm27NnTxAr9s2wYcOUm5urxo0b23bPjIwM2+4FAEA4iHPqC7ds2VKxsbHav39/reP79+9X27Zt67zm0Ucf1c0336yxY8dKknr06KGioiLdcccdevjhh09ZmVuSXC6XXC6X/d9AAB09elSTJk3SK6+8ooMHDzboXp999plNVQHwSXKy0xUAUcuxlpuEhAT17t1b2dnZNcc8Ho+ys7PVv3//Oq8pLi4+JcBUr8QdadP1PP7448rPz9eoUaNqHU9MTFRsbKzS09O1fv16GWPUrVu3094n0p4LEBYaNZKKiqo2ll8Ags6xlhtJysrK0qhRo9SnTx9lZGRoxowZKioq0pgxYyRJt9xyizp06KBp06ZJkoYPH67p06froosuUr9+/bRjxw49+uijGj58eE3IiTTz5s3TuHHjtHbtWg0YMEB9+/Y95Zyvv/5acXFxqqysrPMey5Yt07BhwwJdKgAAIcHRcDNy5Ejl5+dr0qRJysvLU69evbRy5cqaTsa7d++u1VLzyCOPyLIsPfLII/r+++/VqlUrDR8+XE8++aRT30JQ9O3bt85Qc6LWrVtr3759dX5u+PDhSktL05gxY/TUU0+pvLxc8fHxev311zV69OgAVAwAgHNYfiFCTJo0qd6O1adzzjnnaMeOHQGoCIhiJSXSr35Vtf+Pf0iJic7WA0QAX35/E24iiGVZfl2XkJAgY4x+/vOfn3GlcgBeKCqSqkc9FhbS7wawQVitLQX7JPm5OF9ZWZnKy8u1dOlSWZalIUOGMEcOACBsEW4iiF1D3leuXCm32y3LslhlHAAQdgg3EeTkYeN2mDt3bp3zBwEAEKr4rRVBZsyYEZAJC40xsixLlmWpe/futt8fAAA7EW4iTElJicaPHx+w+2/ZsoWQAwAIaYyWimDz5s3TO++8o+bNm+vzzz+XJB06dEjfffedbV8jyv75AN5htBRgO4aC1yOaws3p/PGPf9TMmTNtu1+U/RMCADiAcFMPwk2V3NxcLVu2THl5ebr66qvVt29fde/eXVu2bPHrflH2zwgAEGSEm3oQbs7M38kAo+yfEgAgiJjEDw1ijNGll17q83X+hiIg4pSUSNddV7WVlDhdDRB1CDeo00cffSRjjJYuXaorr7xSLVq08Oo6Ag4gqbJSWrSoaqusdLoaIOoQblCvYcOGKTs7WwcPHvT6tZNlWSzfAABwDOEGPvE24Ljdbs2ZMyfA1QAAcCrCDXzmbcAZO3asmjRpog0bNgS4IgAAjiPcwC/eBpzCwkJlZGRo9OjRgS0IAICfEG7gN1+Gfs+fP58WHABAUBBu0CDGGK9XDc/IyAhwNQAAEG5gg8rKSjXycu2cZs2aBbgaIAQkJ1etKVVYWLUPIKjinC4AkaGwsNCrOW4OHz4sy7KYzRiRzbJYLBNwEC03sI0xRsOHD/fqXCb7AwAECuEGtlqyZInefPNNr879zW9+E+BqAIeUlkqjR1dtpaVOVwNEHRbORECkp6fru+++O+N5UfbPD9GiqEhq3Lhqv7CQV1SADVg4E47LyclRenr6Gc/j9RQAwG6EGwTMrl27vAovBBwAgJ0INwgoj8ejzp07n/G8uDgG7gEA7EG4QcBt375dsbGx9Z5TWVkpl8sVpIoAAJGMcIOgqKioOOM5ZWVlsixLV111VRAqAgBEKsINgsbbkVHvv/++LMtSbm5ugCsCAEQiwg2CaunSpV6f63a7NWfOnABWAwRIcrJ04EDVxvILQNARbhBUw4YN0yWXXOL1+WPHjqUFB+HHsqRWrao2RgMCQUe4QdCtXbtWPXv29Pp8t9utefPmBa4gAEBEIdzAEZs3b/bp/DFjxsiyLG3YsCEwBQF2Ki2Vxo2r2lh+AQg6wg0cY4xRZmamT9dkZGRo9OjRgSkIsEtFhfTyy1WbFyMFAdiLcANHrVq1SsYYn9aYmj9/Pi04AIDTItwgZBhjvJ6peMCAAQGuBgAQrgg3CCnl5eXq2LGjV+d16tQpCBUBAMIN4QYhJycnx6v5cHJycmRZlizL0vTp04NQGQAgHBBuEJKGDRvmUz+ce++9V5Zl6e677w5cUQCAsEC4QUh7/vnnfTr/xRdflGVZuu222wJUEQAg1FnGlz+PI0BBQYFSU1N15MgRpaSkOF0OvNC6dWvl5+f7dW2U/fNGqPB4pN27q/bPOkuK4e9IoKF8+f3NTxxC3oEDB3xuwalmMfU9nBATI6WnV20EGyDo+KlDWMjKyvK7FYaAAwDRhXCDsGKM8WldqmoEHARVWZl0331VW1mZ09UAUYdwg7CzefNmGWN8flVlWZZatGgRoKqAE5SXS889V7WVlztdDRB1CDcIW9Wvqm699Vavrzl06JAsy9KvfvUr5ebmBrA6AIBTGC2FiOLr66e4uDiV85c17FZUJDVuXLVfWCg1auRsPUAEYLQUopavWb2iooJZjgEgwhBuEHH8bYy899575XK5bK4GABBshBtEJH8DTllZGSOrACDMEW4QsYwxatWqlV/XVr+qysjIsLkqAECgEW4Q0Q4cOCBjjMaPH+/X9Rs2bJBlWUpNTbW5MkS0pCTpP/+p2pKSnK4GiDqMlkJUadSokYqLi/2+Psp+XAAgZDBaCjiNoqIiGWP06KOP+nU9/XEAIPQRbhCVHn/8cRlj/GqJsSyLCQBRv7Iy6bHHqjaWXwCCjtdSgPxrkUlISFBpaWkAqkHYYxI/wHa8lgJ8ZIxR8+bNfbqmeth4XFycNmzYEKDKAAC+ItwAP/nhhx9kjNHSpUvVpk0br6+rrKxURkaGz+EIABAYhBvgJMOGDVNeXp7P/XF+/PFHOhwDQAgg3AD18KdLWq9evewvBADgNcINcAa+BpwvvvgiQJUAALwR589FlZWVmjdvnrKzs3XgwAF5PJ5an//ggw9sKQ4IFcYYtWjRQocOHfLqfMuymPAPABziV8vN+PHjNX78eFVWVuqCCy5Qz549a21AJKrucDx8+HCvzq9en8qyLN19992BLQ6hJTFRWr++aktMdLoaIOr4Nc9Ny5Yt9Ze//EVDhw5tcAGzZs3Ss88+q7y8PPXs2VMvvfRSvYsVHj58WA8//LAWL16sQ4cOqWPHjpoxY4bXtTDPDeySmpqqgoICr8+3LOuUVk4AgHcCPs9NQkKCOnfu7FdxJ1q4cKGysrI0efJkbdq0ST179tTgwYN14MCBOs8vKyvTVVddpZycHC1atEhbt27V7Nmz1aFDhwbXAvjqyJEjPp1vjJFlWcyJAwAB5lfLzfPPP6+dO3dq5syZDRr62q9fP/Xt21czZ86UJHk8Hrndbv3xj3/Ugw8+eMr5r776qp599ll98803io+P9+tr0nIDu/nzM9CoUSMVFhYGoBqEhLIy6cUXq/bHj5cSEpytB4gAvvz+9ivcXHvttVq9erWaN2+u888//5SgsXjx4jPeo6ysTMnJyVq0aJGuueaamuOjRo3S4cOH9c4775xyzdChQ9W8eXMlJyfrnXfeUatWrXTjjTfqgQceUGxsbJ1fp7S0tNYU+QUFBXK73YQb2MrfkE+n4wjF8guA7XwJN36NlmratKmuvfZav4qrdvDgQVVWVp4yE2ybNm30zTff1HnNzp079cEHH+imm27SihUrtGPHDt15550qLy/X5MmT67xm2rRp+tOf/tSgWoEzqX7l5CtGVQGA/fwKN2+++abddXjF4/GodevWev311xUbG6vevXvr+++/17PPPnvacDNx4kRlZWXVfFzdcgPYzRijLl26aMeOHT5dR8ABAHv5FW6q5efna+vWrZKkc889V61atfL62pYtWyo2Nlb79++vdXz//v1q27Ztnde0a9dO8fHxtV5BdevWTXl5eSorK1NCHe+1XS6XXC6X13UBDbF9+/ZaH3vbmlN9XmxsrCoqKmyvCwCiiV+jpYqKinTrrbeqXbt2+tnPfqaf/exnat++vW677TYVFxd7dY+EhAT17t1b2dnZNcc8Ho+ys7PVv3//Oq8ZMGCAduzYUWs47bZt29SuXbs6gw3gNF9bZCorK2VZlhrRRwMA/OZXuMnKytKHH36opUuX6vDhwzUdgD/88EPde++9Pt1n9uzZmj9/vrZs2aI//OEPKioq0pgxYyRJt9xyiyZOnFhz/h/+8AcdOnRI48eP17Zt27R8+XJNnTpV48aN8+fbAIKieqVxXxQXF7MIJwD4ya/XUv/4xz+0aNEiXX755TXHhg4dqqSkJF1//fV65ZVXvLrPyJEjlZ+fr0mTJikvL0+9evXSypUrazoZ7969WzExx/OX2+3Wu+++q3vuuUcXXnihOnTooPHjx+uBBx7w59sAgmbYsGF+dTquPn/kyJFasGBBIEoDgIjj11Dw5ORkbdy4Ud26dat1/KuvvlJGRoaKiopsK9BuzHMDp/nbIhMTE6PKykqbq0FAVFZKH31UtT9woHSaqSoAeC/gMxT3799fkydPVklJSc2xY8eO6U9/+tNp+8sAqOLvyKjqSS4RBmJjpcsvr9oINkDQ+fVa6sUXX9TgwYOVlpZWs1DmF198ocTERL377ru2FghEImOMz2tTSVJubq4sy1Ljxo119OjRAFUHAOHNr9dSUlWHx7feeqtmwr1u3brppptuUlJSkq0F2o3XUghFkyZN0pQpU3y+zuVy1WpBRYgoL5def71q/447JD+XiwFwXMCXXwhnhBuEMn/748TGxionJ0dpaWk2VwS/sPwCYLuALL+wZMkSDRkyRPHx8VqyZEm9544YMcLb2wI4gTFGGRkZPq8cXllZWdMfJ8r+XgGAU3jdchMTE6O8vDy1bt261vDsU25oWSE9ooOWG4SLhsxzQ8BxGC03gO0CMlqqel2n6v3TbaEcbIBwYoxR3759/bqWCQABRDO/hoLX5fDhw3bdCsBP1q9f73crjGVZId/BHwACwa9w8/TTT2vhwoU1H1933XVq3ry5OnTooC+++MK24gBUMcbIGKNLL73Up+tKSkpoxQEQdfwKN6+++mpN58VVq1bp/fff18qVKzVkyBDdd999thYI4LiPPvpIxhglJyf7dB0BB0A08WsSv7y8vJpws2zZMl1//fUaNGiQ0tPT1a9fP1sLBHCq6iVOBg4cqI8//tirayzLUkpKio4cORLI0iBJLpe0bNnxfQBB5VfLTbNmzbRnzx5J0sqVK5WZmSmpqumcDsVA8FS35HiroKBAlmX5PNQcPoqLk66+umqL8+tvSAAN4NdP3S9/+UvdeOON6tKli3744QcNGTJEkvT555+rc+fOthYI4Mx8XXE8IyNDktS8eXP98MMPgSoLABzhV8vNCy+8oLvuukvdu3fXqlWr1Pin+Rz27dunO++809YCAXjHGKO2bdv6dM2hQ4dkWZZ69eoVmKKiVXm5NG9e1VZe7nQ1QNRh+QUgAvnbgTjK/ncQOEziB9iO5ReAKGeMUVJSks+Lavbq1UubN28OTFEAECQsvwBEsOnTp+vee+/16Rpab2xAyw1gO5ZfACBJysrK8jmsWJalLl26BKgiAAg825ZfABC6jDF6/vnnvT5/x44dDBkHELb8Cjf/7//9P/35z38+5fjMmTN19913N7QmAAFQ3YrjS0tORkaGrr/++gBWBQD28yvc/OMf/9CAAQNOOX7JJZdo0aJFDS4KQGD5EnDefvttlm8AEFb8msTvhx9+UGpq6inHU1JSdPDgwQYXBSDwfJ34z7IsxcTE0K/OGy6X9Pe/H98HEFR+tdx07txZK1euPOX4//7v/+rss89ucFEAgsPXzsYej4dWHG/ExUnXXVe1sfwCEHR+/dRlZWXprrvuUn5+vq688kpJUnZ2tp5//nnNmDHDzvoABJgxRi1atNChQ4e8vsayLLlcLp/n0QGAYPAr3Nx6660qLS3Vk08+qSlTpkiS0tPT9corr+iWW26xtUAAgVe9vpQvrTKlpaWyLIt5cepSUSH9859V+9deS+sNEGQNXn4hPz9fSUlJNetLhTom8QPq52srjiT17dtX69evD1BFYYhJ/ADbBWQSv5NVVFTo/fff1+LFi2v+ctu7d68KCwv9vSWAEPDDDz/4NCeOJG3YsEGWZWnZsmUBqgoAvOdXuPnuu+/Uo0cP/eIXv9C4ceOUn58vSXr66ac1YcIEWwsEEHzVc+L4GnKGDx9OyAHgOL/Czfjx49WnTx/9+OOPSkpKqjl+7bXXKjs727biADjLn+UbpKqQk5iYGICKAODM/Orl9tFHH+mTTz5RQkJCrePp6en6/vvvbSkMQOgwxqhRo0YqLi72+ho6HANwil8tN6dbIDM3N1dNmjRpcFEAQk9RUZFfQcWyrDon/QSAQPEr3AwaNKjWfDaWZamwsFCTJ0/W0KFD7aoNQAgyxigmxrf/dRQUFMiyLF5VAQgKv15LPffcc/r5z3+u7t27q6SkRDfeeKO2b9+uli1b6m9/+5vdNQIIMdUtt77OVlz9qupEcXFxKi8vt622kJCQIL355vF9AEHl9zw3FRUVWrhwob744gsVFhbq4osv1k033VSrg3EoYp4bwF65ublyu90Nvg99cwDUx5ff3z6Hm/Lycp133nlatmyZunXr1qBCnUC4AQLHrnWn3nzzTY0ePdqWewGIDAGdxC8+Pp71ZADUya7WlzFjxoT3Ap0VFdLy5VVbRYXT1QBRx68OxePGjdPTTz+tCn5oAZzEGKP4+Hhb7mVZVs3WokULW+4ZFKWl0rBhVVtpqdPVAFHHrw7FGzZsUHZ2tt577z316NFDjU5aN2Xx4sW2FAcgPJWVlUmSUlNTVVBQYMs9Dx06JMuydOutt2rOnDm23BNAZPIr3DRt2lS/+tWv7K4FQIQ5cuSIJHtDzty5czV37tyajyNytBWABvEp3Hg8Hj377LPatm2bysrKdOWVV+qxxx4L+RFSAJxVHXJOlJiYqFIbXtlUVFQwEzKAWnzqc/Pkk0/qoYceUuPGjdWhQwf9+c9/1rhx4wJVG4AIVlJSoqVLl9p2v+q+OQDg01DwLl26aMKECfrd734nSXr//fd19dVX69ixYz7PWOoUhoIDocmu+XKqOdqSU1QkNW5ctV9YKJ3ULxGA7wI2FHz37t21llfIzMyUZVnau3evf5UCwE/S0tJkjFHTpk1tuV91Sw7r3QHRx6c+NxUVFaesDRMfH09nPgC2+fHHH2t93NBXTYWFhcHvk5OQIM2ceXwfQFD5FG6MMRo9erRcLlfNsZKSEv3+97+vNRycoeAA7FIdShoack68vnnz5vrhhx8adL96xcdL9EcEHONTuBk1atQpx37729/aVgwAnM7JLS8NCTvVc+YwwgqITD6FmzerV7kFAIcZYzRixIgGjbiyLEtLly7VsGHDbKxMUmWl9NFHVfsDB0qxsfbeH0C9wmOIEwDUYcmSJTLGaPz48X7fY/jw4TWdj7t3725PYSUl0hVXVG2sxQcEHeEGQNibMWOGLa+YtmzZIsuy1K5dOxuqAuAUwg2AiGGMqdkaIi8vjwkBgTBGuAEQkYwxatu2bYPuUf26ipYcILz4tXAmAISDffv21frY39aY6pYcRlcB4YGWGwBRo6HhhPWrgPBAuAEQVYwx2rNnT4PuUR1y5s2bZ09RAGzl08KZkYCFMwGcrKGtMaf8b7SsTHrxxar98eNZggGwgS+/v+lzAyDqNXSJh+rrYmNjVVFRURVm7rvPtvoA+IbXUgDwk4Y2ZFdWVtIvBwgBtNwAwAlODDj+hpQYSX1/uvaLmBiVVVbaURoALxFuAOA0jDGKj4+vetXkg0RJG37ab+TxMIwcCDJeSwFAPcrLy2WMUdOmTRt0H15XAcFDuAEAL/z444+2LO1gWZZyc3NtqgpAXQg3AOCjhgYct9tNKw4QQIQbAPCDHYt0EnCAwAiJcDNr1iylp6crMTFR/fr10/r16726bsGCBbIsS9dcc01gCwSAelSHnM6dO/t8rWVZ6tWrl/1FAVHM8XCzcOFCZWVlafLkydq0aZN69uypwYMH68CBA/Vel5OTowkTJmjgwIFBqhQA6rd9+3YZY1RUWOjTdV988QWtOICNHA8306dP1+23364xY8aoe/fuevXVV5WcnKy5c+ee9prKykrddNNN+tOf/qSzzz673vuXlpaqoKCg1gYAARUfL02erGkJCSr34bLqEVUEHaBhHA03ZWVl2rhxozIzM2uOxcTEKDMzU+vWrTvtdY8//rhat26t22677YxfY9q0aUpNTa3Z3G63LbUDwGklJEiPPaaJpaUq87NPDq+rAP85Gm4OHjyoyspKtWnTptbxNm3aKC8vr85rPv74Y82ZM0ezZ8/26mtMnDhRR44cqdkauhowAPjK35XIq19XWZYll8sVgMqAyBRWMxQfPXpUN998s2bPnq2WLVt6dY3L5eJ/CgCCy+ORtmyp2u/WTYqJUVpamowxfr9yKisrqwk5JSUlNhYLRB5Hw03Lli0VGxur/fv31zq+f/9+tW3b9pTzv/32W+Xk5Gj48OE1xzwejyQpLi5OW7du1TnnnBPYogHgTI4dky64oGq/sFBq1KjmU8YYJSYmqrS01K9bl5aWspwDcAaOvpZKSEhQ7969lZ2dXXPM4/EoOztb/fv3P+X88847T19++aU2b95cs40YMUJXXHGFNm/eTH8aAGGhpKTElpmOr7rqKpsqAiKL46+lsrKyNGrUKPXp00cZGRmaMWOGioqKNGbMGEnSLbfcog4dOmjatGlKTEzUBdV/Df2ker2Xk48DQKgzxighIUHl5b6MqTru/fffpxUHqIPj4WbkyJHKz8/XpEmTlJeXp169emnlypU1nYx3796tmBjHR6wDQECUlZXV7PvbH4eAA9RmmSj7iSgoKFBqaqqOHDmilJQUp8sBEImKiqTGjav2T+pz4w1/Q06U/e8cUcaX3980iQBAiPF33SrLstSlS5cAVQWED8INAIQwX0POjh07ZFmWkpKSAlgVENoc73MDABEnPl6aMOH4vg2MMYqPj1dFRYVX55eUlNS83uJ1FaIN4QYA7JaQID37rO23rR5V5WufnOrz+/btq/Xr19teFxBqeC0FAGHG35aYDRs2sCgnogLhBgDs5vFIOTlV20+zqNutIa+aLMvS9OnTbawGCC2EGwCw27FjUqdOVduxYwH7MsYYtWrVyq9r7733XkIOIhbhBgDC2IEDBxrUilMdcnhdhUhCuAGACFA9ZDw5OdnvexByECkINwAQQYqKimxZlBMIZwwFB4AIdGLA8SesMEcOwhktNwAQ4Ro6soqWHIQbwg0ARAFjjPbs2eP39YQchBNeSwGA3eLipDvvPL4fItLS0mSM0YYNG5SRkeHXPSzL4lUVQp5louxfqS9LpgNApGtIa0yU/fqAw3z5/c1rKQCIYr6uOn4iXlUhVBFuAMBuxkj5+VVbmLRuGGN06623+nVtdcgh6CBUEG4AwG7FxVLr1lVbcbHT1Xhtzpw5zJGDiEC4AQDUUv2qKjY21q/rq1txJk2aZHNlgHcINwCAOlVUVDSoJWfKlCmyLEsbNmywsSrgzAg3AIB6GWN06aWX+n19RkYGfXIQVIQbAMAZffTRR7YM/SbkIBhCZ3YpAEDIqw44DQ0oJ17PfDmwGy03AACfVXc6trM1x98OzMDJaLkBALvFxUmjRh3fj3DGGHXq1Ek5OTkNuo/H45FlWYqJiVFlZaU9xSEqRf5PHQAEm8slzZvndBVBtWvXrpr9hr6yqg45Eq+s4B9eSwEAbNXQFchPVP3KasSIEbbcD9GBlhsAsJsxx2cmTk6WonB0UPUK5JI9sxYvXbqU1hx4jZYbALBbcbHUuHHVFkbLLwSKXR2PqzGUHGdCuAEABEUgRlh16tTJhsoQaXgtBQAIuhMDTkNaYnJycnhdhVPQcgMAcJSdrTnzomyUGupGuAEAhAQ7Qs6YMWPokwNeSwEAQosdr6x4VRXdaLkBAISshrbmsFBndKLlBgDsFhsr/frXx/fRYMaYBoUUy7JoxYkitNwAgN0SE6W3367aEhOdriZiVLfiPP/8835dTytO9CDcAADCSlZWVoNeVxFyIh/hBgAQtowxGjlypF/XEnIiF+EGAOxWVFS1npRlVe0joBYsWNDgTseTJk2ysSI4jXADAIgIDXlVNWXKlJqWHFpzwh+jpQAAEcWO1chPvJZRVuGHlhsAQESyK5TQmhN+CDcAgIhl17pV0vGQ43a7bbkfAodwAwCIeHaGnNzcXFpzQhzhBgAQNewMOVJVa04iEzWGHDoUA4DdYmOloUOP7yPkGGOUm5tryyum0tJSlncIMYQbALBbYqK0fLnTVeAM0tLSbFmB/MTrExMTdezYsYaWhgYi3AAAINkSdEpKSmqupSXHOfS5AQDgJHb0zaHDsXMINwBgt6IiqVGjqo3lF8Jadchp6CKdnTp1srky1IfXUgAQCMXFTlcAmzVk5uOcnJyaoOPxeOwuDSeh5QYAAB80pCXHGMMcOUFAuAEAwA929Mkh5AQG4QYAAD/R8Tg0EW4AAGighoYcWnHsRbgBAMAmtOKEBkZLAYDdYmKkyy47vo+o0tDJAC3LUlpamvbs2WNnWVGFcAMAdktKktascboKhAB/h49Xrzx+8n3gHf6kAAAgwOzokwPvEW4AAAgSO2Y7xpkRbgDAbkVFUqtWVRvLL6AOtOIEFn1uACAQDh50ugKEuIYs58DK4/ULiZabWbNmKT09XYmJierXr5/Wr19/2nNnz56tgQMHqlmzZmrWrJkyMzPrPR8AgFDG/Dj2czzcLFy4UFlZWZo8ebI2bdqknj17avDgwTpw4ECd569Zs0Y33HCDVq9erXXr1sntdmvQoEH6/vvvg1w5AAD2sKPD8YYNG2ysKLxZxuE2rX79+qlv376aOXOmJMnj8cjtduuPf/yjHnzwwTNeX1lZqWbNmmnmzJm65ZZbTvl8aWmpSktLaz4uKCiQ2+3WkSNHlJKSYt83AgDVioqkxo2r9gsLpUaNnK0HYcnfFplIfVVVUFCg1NRUr35/O9pyU1ZWpo0bNyozM7PmWExMjDIzM7Vu3Tqv7lFcXKzy8nI1b968zs9PmzZNqampNZvb7baldgAAAqkho6qinaPh5uDBg6qsrFSbNm1qHW/Tpo3y8vK8uscDDzyg9u3b1wpIJ5o4caKOHDlSszHjIwAgXPj7uira++KE9Wipp556SgsWLNCaNWuUmJhY5zkul0sulyvIlQGIajExUp8+x/eBBjLGKDU1VQUFBT5dZ1mW9uzZo7S0tABVFpoc/alr2bKlYmNjtX///lrH9+/fr7Zt29Z77XPPPaennnpK7733ni688MJAlgkAvklKkjZsqNqSkpyuBhHiyJEjfrXiuN1uzZkzJwAVhS5Hw01CQoJ69+6t7OzsmmMej0fZ2dnq37//aa975plnNGXKFK1cuVJ9qv86AgAgCvjzqmrs2LFR9arK8fbSrKwszZ49W/Pnz9eWLVv0hz/8QUVFRRozZowk6ZZbbtHEiRNrzn/66af16KOPau7cuUpPT1deXp7y8vJUWFjo1LcAAEDQGWO0dOlSn6+LhoDjeJ+bkSNHKj8/X5MmTVJeXp569eqllStX1nQy3r17t2JOeGf9yiuvqKysTL/+9a9r3Wfy5Ml67LHHglk6ANStuFjq3r1q/+uvpeRkZ+tBxBo2bJiMMT4HFsuyInbIuBQC89wEmy/j5AHAL8xzAwf40+FYCp95ccJmnhsAAGAPfzscR2JfHMINAAARpCGT/yVFyOg+wg0AABHGGKOmTZv6fF1JSUlEtOIQbgAAiEA//vhjg2Y4DmeEGwAAIly09cVxfCg4AEQcyzo+FDxMfzkg8hhjFBcXp8rKSp+uC8dh44QbALBbcrL01VdOVwGcoqKiQpLvr53CLeDwWgoAgCjjT1+ccHpNRbgBACBK+RtyQh3hBgDsVlwsnX9+1VZc7HQ1wBlFWsChzw0A2M2YqjWlqveBMODrGlWh3A+HlhsAACDJ99dUodqCQ7gBAAC1hHvAIdwAAIBThHPAIdwAAIA6+fKaKpQCDuEGAADUK9wCDqOlAMBuliV17Hh8H4gAvo6mchLhBgDslpws5eQ4XQVgO28CTigMEee1FAAA8Jo3wcXpFh7CDQAAiCiEGwCw27FjUt++VduxY05XA9jOm9ab1NTUIFRSN/rcAIDdPB7ps8+O7wMR6Ez9bwoKCoJYTW203AAAgIBwqu8N4QYAAPjF6VFRp0O4AQAAEYVwAwAA/Ham1hsnXk0RbgAAQERhtBQABELLlk5XAEQtwg0A2K1RIyk/3+kqgKAJtXWneC0FAAAiCuEGAABEFMINANjt2DHp8surNpZfAIKOPjcAYDePR/rww+P7AIKKlhsAABBRCDcAACCiEG4AAECDnW6mYifWnyLcAAAAW5wcZJxaWJMOxQAAwDahsFI44QYAAiE52ekKgKhFuAEAuzVqJBUVOV0FELXocwMAACIK4QYAAEQUwg0A2K2kRLr66qqtpMTpaoCoQ58bALBbZaW0YsXxfQBBRcsNAACIKIQbAAAQUQg3AAAgohBuAABARCHcAACAiBJ1o6Wq17woKChwuBIAEevE2YkLChgxBdig+ve2N2tXRV24OXr0qCTJ7XY7XAmAqNC+vdMVABHl6NGjSk1Nrfccy4TC8p1B5PF4tHfvXjVp0kSWZdl674KCArndbu3Zs0cpKSm23hvH8ZyDg+ccHDzn4OFZB0egnrMxRkePHlX79u0VE1N/r5qoa7mJiYlRWlpaQL9GSkoKPzhBwHMODp5zcPCcg4dnHRyBeM5narGpRodiAAAQUQg3AAAgohBubORyuTR58mS5XC6nS4loPOfg4DkHB885eHjWwREKzznqOhQDAIDIRssNAACIKIQbAAAQUQg3AAAgohBuAABARCHc+GjWrFlKT09XYmKi+vXrp/Xr19d7/ttvv63zzjtPiYmJ6tGjh1asWBGkSsObL8959uzZGjhwoJo1a6ZmzZopMzPzjP9dUMXXf8/VFixYIMuydM011wS2wAjh63M+fPiwxo0bp3bt2snlcqlr1678v8MLvj7nGTNm6Nxzz1VSUpLcbrfuuecelZSUBKna8PTvf/9bw4cPV/v27WVZlv71r3+d8Zo1a9bo4osvlsvlUufOnTVv3ryA1ykDry1YsMAkJCSYuXPnmq+++srcfvvtpmnTpmb//v11nr927VoTGxtrnnnmGfP111+bRx55xMTHx5svv/wyyJWHF1+f84033mhmzZplPv/8c7NlyxYzevRok5qaanJzc4NceXjx9TlX27Vrl+nQoYMZOHCg+cUvfhGcYsOYr8+5tLTU9OnTxwwdOtR8/PHHZteuXWbNmjVm8+bNQa48vPj6nN966y3jcrnMW2+9ZXbt2mXeffdd065dO3PPPfcEufLwsmLFCvPwww+bxYsXG0nmn//8Z73n79y50yQnJ5usrCzz9ddfm5deesnExsaalStXBrROwo0PMjIyzLhx42o+rqysNO3btzfTpk2r8/zrr7/eXH311bWO9evXz/zud78LaJ3hztfnfLKKigrTpEkTM3/+/ECVGBH8ec4VFRXmkksuMW+88YYZNWoU4cYLvj7nV155xZx99tmmrKwsWCVGBF+f87hx48yVV15Z61hWVpYZMGBAQOuMJN6Em/vvv9+cf/75tY6NHDnSDB48OICVGcNrKS+VlZVp48aNyszMrDkWExOjzMxMrVu3rs5r1q1bV+t8SRo8ePBpz4d/z/lkxcXFKi8vV/PmzQNVZtjz9zk//vjjat26tW677bZglBn2/HnOS5YsUf/+/TVu3Di1adNGF1xwgaZOnarKyspglR12/HnOl1xyiTZu3Fjz6mrnzp1asWKFhg4dGpSao4VTvwejbuFMfx08eFCVlZVq06ZNreNt2rTRN998U+c1eXl5dZ6fl5cXsDrDnT/P+WQPPPCA2rdvf8oPFI7z5zl//PHHmjNnjjZv3hyECiODP895586d+uCDD3TTTTdpxYoV2rFjh+68806Vl5dr8uTJwSg77PjznG+88UYdPHhQl156qYwxqqio0O9//3s99NBDwSg5apzu92BBQYGOHTumpKSkgHxdWm4QUZ566iktWLBA//znP5WYmOh0ORHj6NGjuvnmmzV79my1bNnS6XIimsfjUevWrfX666+rd+/eGjlypB5++GG9+uqrTpcWUdasWaOpU6fq5Zdf1qZNm7R48WItX75cU6ZMcbo02ICWGy+1bNlSsbGx2r9/f63j+/fvV9u2beu8pm3btj6dD/+ec7XnnntOTz31lN5//31deOGFgSwz7Pn6nL/99lvl5ORo+PDhNcc8Ho8kKS4uTlu3btU555wT2KLDkD//ntu1a6f4+HjFxsbWHOvWrZvy8vJUVlamhISEgNYcjvx5zo8++qhuvvlmjR07VpLUo0cPFRUV6Y477tDDDz+smBj+9rfD6X4PpqSkBKzVRqLlxmsJCQnq3bu3srOza455PB5lZ2erf//+dV7Tv3//WudL0qpVq057Pvx7zpL0zDPPaMqUKVq5cqX69OkTjFLDmq/P+bzzztOXX36pzZs312wjRozQFVdcoc2bN8vtdgez/LDhz7/nAQMGaMeOHTXhUZK2bdumdu3aEWxOw5/nXFxcfEqAqQ6UhiUXbePY78GAdleOMAsWLDAul8vMmzfPfP311+aOO+4wTZs2NXl5ecYYY26++Wbz4IMP1py/du1aExcXZ5577jmzZcsWM3nyZIaCe8HX5/zUU0+ZhIQEs2jRIrNv376a7ejRo059C2HB1+d8MkZLecfX57x7927TpEkTc9ddd5mtW7eaZcuWmdatW5snnnjCqW8hLPj6nCdPnmyaNGli/va3v5mdO3ea9957z5xzzjnm+uuvd+pbCAtHjx41n3/+ufn888+NJDN9+nTz+eefm++++84YY8yDDz5obr755przq4eC33fffWbLli1m1qxZDAUPRS+99JI566yzTEJCgsnIyDD/93//V/O5yy67zIwaNarW+X//+99N165dTUJCgjn//PPN8uXLg1xxePLlOXfs2NFIOmWbPHly8AsPM77+ez4R4cZ7vj7nTz75xPTr18+4XC5z9tlnmyeffNJUVFQEuerw48tzLi8vN4899pg555xzTGJionG73ebOO+80P/74Y/ALDyOrV6+u8/+31c921KhR5rLLLjvlml69epmEhARz9tlnmzfffDPgdVrG0P4GAAAiB31uAABARCHcAACAiEK4AQAAEYVwAwAAIgrhBgAARBTCDQAAiCiEGwAAEFEINwAAIKIQbgBAkmVZ+te//iVJysnJkWVZ2rx5s6M1AfAP4QaA40aPHi3LsmRZluLj49WpUyfdf//9Kikpcbo0AGEozukCAECSfv7zn+vNN99UeXm5Nm7cqFGjRsmyLD399NNOlwYgzNByAyAkuFwutW3bVm63W9dcc40yMzO1atUqSZLH49G0adPUqVMnJSUlqWfPnlq0aFGt67/66isNGzZMKSkpatKkiQYOHKhvv/1WkrRhwwZdddVVatmypVJTU3XZZZdp06ZNQf8eAQQH4QZAyPnPf/6jTz75RAkJCZKkadOm6S9/+YteffVVffXVV7rnnnv029/+Vh9++KEk6fvvv9fPfvYzuVwuffDBB9q4caNuvfVWVVRUSJKOHj2qUaNG6eOPP9b//d//qUuXLho6dKiOHj3q2PcIIHB4LQUgJCxbtkyNGzdWRUWFSktLFRMTo5kzZ6q0tFRTp07V+++/r/79+0uSzj77bH388cd67bXXdNlll2nWrFlKTU3VggULFB8fL0nq2rVrzb2vvPLKWl/r9ddfV9OmTfXhhx9q2LBhwfsmAQQF4QZASLjiiiv0yiuvqKioSC+88ILi4uL0q1/9Sl999ZWKi4t11VVX1Tq/rKxMF110kSRp8+bNGjhwYE2wOdn+/fv1yCOPaM2aNTpw4IAqKytVXFys3bt3B/z7AhB8hBsAIaFRo0bq3LmzJGnu3Lnq2bOn5syZowsuuECStHz5cnXo0KHWNS6XS5KUlJRU771HjRqlH374QS+++KI6duwol8ul/v37q6ysLADfCQCnEW4AhJyYmBg99NBDysrK0rZt2+RyubR7925ddtlldZ5/4YUXav78+SovL6+z9Wbt2rV6+eWXNXToUEnSnj17dPDgwYB+DwCcQ4diACHpuuuuU2xsrF577TVNmDBB99xzj+bPn69vv/1WmzZt0ksvvaT58+dLku666y4VFBToN7/5jT777DNt375df/3rX7V161ZJUpcuXfTXv/5VW7Zs0aeffqqbbrrpjK09AMIXLTcAQlJcXJzuuusuPfPMM9q1a5datWqladOmaefOnWratKkuvvhiPfTQQ5KkFi1a6IMPPtB9992nyy67TLGxserVq5cGDBggSZozZ47uuOMOXXzxxXK73Zo6daomTJjg5LcHIIAsY4xxuggAAAC78FoKAABEFMINAACIKIQbAAAQUQg3AAAgohBuAABARCHcAACAiEK4AQAAEYVwAwAAIgrhBgAARBTCDQAAiCiEGwAAEFH+P4I2UsdaAlnxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.7998495697975159 with F-Score 0.48366863905325447 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "64d12610-7d6d-4623-e320-55d76775867c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.7998495697975159\n",
            "Final Test Accuracy: 88.92002231463637 %\n",
            "Final Test Precision: 41.64885496183206 %\n",
            "Final Test Recall: 57.65004226542688 %\n",
            "Final Test F1 Score: 48.360219819181 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "You must call wandb.init() before wandb.summary['test_accuracy']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-51398f335644>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSING_WANDB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_precision'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_recall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {self._name}[{key!r}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.summary['test_accuracy']"
          ]
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        test_outputs = sigmoid(test_outputs)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note: Actual Test {len(acc_seq_test)} accessible and {len(not_seq_test)} notaccessible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iniAmj4jhpX",
        "outputId": "f93360cd-575a-43d6-99ba-8c10808755d1"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Actual Test 7086 accessible and 71768 notaccessible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test on rest of nonaccessible\n",
        "# if DOWNSAMPLE:\n",
        "#     # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "#     rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "#     # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "#     CM = 0\n",
        "#     total_correct = 0\n",
        "#     total_predictions = 0\n",
        "#     model.eval()\n",
        "#     for batch in rest_notacc_loader:  # tqdm()\n",
        "#         samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "#         outputs = model(samples)\n",
        "#         preds = utils.get_preds(outputs)\n",
        "#         total_predictions += len(outputs)\n",
        "#         CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "#     # Computer accuracy, precision, recall, and f1 metrics\n",
        "#     acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "#     print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "#     print(f\"Rest not Precision: {precision * 100} %\")\n",
        "#     print(f\"Rest not Recall: {recall * 100} %\")\n",
        "#     print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "#     # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "#     # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r pretrained\n",
        "# !rm predictions.zip"
      ],
      "metadata": {
        "id": "N_USYmjft93K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2bbbe7-52b6-4f22-f150-13a3841856d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/test-list-0.01-weight-decay-adamW-sklearn type weight01-08-06-26-17-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-08-06-26-17\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "CNNModel.save_CNNModel(model_save_path, CNN)  # model\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc8d8be-860e-4fd1-f13f-1c037bae49ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fda915e-06e5-4e89-de08-9e64d813de62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=0.7]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.7]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "dee33646-61cc-4edf-ab4c-4677a9f74ef2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 50137 true values out of  269315  total 18.61648998384791 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [8.54308052e-13 1.61152060e-12 2.39714563e-12 ... 6.99985147e-01\n",
            " 6.99989736e-01 6.99994504e-01]\n",
            "accessible probs [0.99999452 0.99999321 0.99998295 ... 0.70001566 0.70000958 0.70000666]\n",
            "\n",
            "first 10\n",
            " ([0.9999945163726807], [0.9999932050704956], [0.9999829530715942], [0.9999785423278809], [0.9999747276306152], [0.9999709129333496], [0.9999673366546631], [0.9999644756317139], [0.9999603033065796], [0.9999583959579468])\n",
            "last 10 of top 10000\n",
            " ([0.9676263332366943], [0.9676147103309631], [0.9676147103309631], [0.967614471912384], [0.9676129221916199], [0.9676119089126587], [0.9676008820533752], [0.9675981998443604], [0.9675949811935425], [0.9675704836845398])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "cbf751c7-14bc-48df-80a1-35af5e6ebfc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "d7a86a56-9f3a-4880-d79d-f0debafb9b63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_699a7a73-8eef-4967-bc92-d40788f18806\", \"test-list-0.01-weight-decay-adamW-sklearn type weight01-08-06-26-17-CNNModel-model-0.0001lr-20epochs.pt\", 1755598)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "12a19ef7-21b2-4922-b493-ca170043c30f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6cbed4a7-7779-4ed3-bc0e-65180c9a13f1\", \"predictions.zip\", 33607)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}