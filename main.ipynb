{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer\n",
        "- early stopping (less epochs)"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "# !pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0783a4cb-192b-4ed3-e58b-ab1465aa7207"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "380ba89f-1734-465d-9c80-9ab3faaf1425"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "# rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e003e3-189b-4821-cbd8-4aeb957a937e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from torchvision.ops import sigmoid_focal_loss\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd, random\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "# from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/sberbank-ai/ru-dalle/blob/e96631a867fcadcfaa52eecb20b1e42b88aa4386/rudalle/utils.py\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(1)"
      ],
      "metadata": {
        "id": "TqvTd3Ano27X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b1c985-3ced-4273-f6b6-023435925de1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0e18c7-f795-4f40-e8ce-577c2668ba73"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185e74af-6c0c-4502-e8d8-17507e06c89e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "d78aa8d7-99b1-4b35-c07e-c52419f92a45"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef054aa3-7838-449a-ac44-d05301b90953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "l7SLRPi59Rm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f2a57c-cdb3-4304-ea3a-cf62c810d69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3536 total hidden\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (Convs): ModuleList(\n",
              "    (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=3200, out_features=64, bias=True)\n",
              "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (3): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# torch.manual_seed(1)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "conv_filters = [32, 64, 128]  # [64, 128]\n",
        "# num_filters1 = 64  # 64\n",
        "# num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "# hidden_dense1 = 64  # 64\n",
        "# hidden_dense2 = 32  # 32\n",
        "linear_neurons = [64, 32, 16]  #[64,32]\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "# CNN = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "#                            hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                           linear_neurons, dropout_rate_Dense)\n",
        "total_hidden = sum(conv_filters) + sum(linear_neurons) - (4 + 1)\n",
        "print(f\"{total_hidden} total hidden\")\n",
        "CNN.to(device)  # quiet output\n",
        "# sum(linear_neurons)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Based on a test, using [1,pos_weight] gives the same results as [weight0, weight1]"
      ],
      "metadata": {
        "id": "Kx6jTrrcqZ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# All weights were the same\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "# WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "# WEIGHTED_LOSS = \"sklearn type weight\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "WEIGHTED_LOSS = \"sigmoid_focal_loss\"\n",
        "# try sigmoid_focal_loss\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":  # same results as sklearn type weight\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":  # same results as sklearn type weight\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weight_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weight_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "if WEIGHTED_LOSS == \"sigmoid_focal_loss\":\n",
        "    loss_fn = sigmoid_focal_loss\n",
        "\n",
        "elif WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()  # (reduction='none') ??\n",
        "    # loss_fn = utils.f1_loss\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = utils.macro_double_soft_f1\n",
        "\n",
        "# if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "if loss_fn.__class__.__name__ != \"BCEWithLogitsLoss\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Sigmoid to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5b3876-381f-40a0-8851-8cb820464558"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added sigmoid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "weight_decay = .01\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True\n",
        "note = f\"{WEIGHTED_LOSS}-{conv_filters}-conv-{linear_neurons}-lin\"\n",
        "note"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f97dd192-29e0-4395-abcf-a50ae003e4e5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sigmoid_focal_loss-[4, 32, 64, 128]-conv-[3200, 64, 32, 16, 1]-lin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"weight decay\": weight_decay,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        if loss_fn.__class__.__name__ == \"function\" and loss_fn.__name__ == \"weighted_binary_cross_entropy\":\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels, reduction=\"mean\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "fvZAvEIsoFo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [4, 32, 64, 128]-conv-[6400, 64, 32, 1] resulted in\n",
        "# mat1 and mat2 shapes cannot be multiplied (128x3200 and 6400x64)\n",
        "\n",
        "# [4, 16, 32, 64]-conv-[3200, 64, 32, 1]-lin\n",
        "# mat1 and mat2 shapes cannot be multiplied (128x1600 and 3200x64)  # inside for loop of linears # flatten size prob not righ"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "total_labels = np.empty(0)  # don't need to have same order\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "    total_labels = np.concatenate((total_labels, labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# pearson correlation coeffs?\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "1368c1a9-3aa4-4c88-eef5-563246711b1b"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-229-07a454fd5c07>:35: RuntimeWarning: invalid value encountered in divide\n",
            "  fscores = (2 * precisions * recalls) / (precisions + recalls)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.7562729120254517 with F-Score 0.4689147762109136 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "fpr, tpr, roc_thresholds = metrics.roc_curve(total_labels, total_probs)\n",
        "# auc_score = metrics.roc_auc_score(total_labels, total_probs)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr, tpr, roc_auc)\n",
        "\n",
        "# print(auc_score)\n",
        "display.plot()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "TfGw4CB9GcYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546,
          "referenced_widgets": [
            "dda001b4035e4a85a8947774da3a1619",
            "f8378aa1e612430cb3e9d13301386551",
            "18dff8a67eec47e6aa9cdde401dec1a0",
            "9cc6637a0fa84052997803e40f2c64d5",
            "cc3fd6b877834b7abff3b8a39a460eee",
            "737cdbcf6bcc4abf9bc7efe850433bfb",
            "dbeaf4f9eb374ff6b5857f46e70d05a4",
            "eaec0df02b734a3395f984014c81f8c8"
          ]
        },
        "outputId": "a2556570-887f-4801-f24c-d7957364d7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.7562729120254517\n",
            "Final Test Accuracy: 89.00116644690131 %\n",
            "Final Test Precision: 41.46182999458581 %\n",
            "Final Test Recall: 53.9447731755424 %\n",
            "Final Test F1 Score: 46.886671156554215 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dda001b4035e4a85a8947774da3a1619"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▃▅▅▅▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Train F1</td><td>▁▃▄▅▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Val Acc</td><td>▁▇▇▇█████▇▇▆▄▅▄▄▄▃▃▃</td></tr><tr><td>Val F1</td><td>▁▄▄▅▅▆▆▇▇▇▇▇▇███████</td></tr><tr><td>Val Loss</td><td>█▆▄▂▂▁▁▁▁▁▁▂▂▂▂▁▁▂▂▂</td></tr><tr><td>Val Precision</td><td>▁▅▅▆▇▇▇█████████████</td></tr><tr><td>Val Recall</td><td>▁▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.87474</td></tr><tr><td>Train F1</td><td>0.47875</td></tr><tr><td>Train Loss</td><td>1.65238</td></tr><tr><td>Train Precision</td><td>0.38235</td></tr><tr><td>Val Acc</td><td>0.87026</td></tr><tr><td>Val F1</td><td>0.4526</td></tr><tr><td>Val Loss</td><td>263.73219</td></tr><tr><td>Val Precision</td><td>0.36478</td></tr><tr><td>Val Recall</td><td>0.59611</td></tr><tr><td>test_accuracy</td><td>0.89001</td></tr><tr><td>test_f1_score</td><td>0.46887</td></tr><tr><td>test_precision</td><td>0.41462</td></tr><tr><td>test_recall</td><td>0.53945</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sklearn type weight-[4, 32, 64]-conv-[3200, 64, 32, 16, 1]-lin</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/7hi7un32' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/7hi7un32</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240109_063405-7hi7un32/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        test_outputs = sigmoid(test_outputs)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note: Actual Test {len(acc_seq_test)} accessible and {len(not_seq_test)} notaccessible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iniAmj4jhpX",
        "outputId": "a51d0cdf-cce0-452e-f200-6a6d28ace571"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Actual Test 7086 accessible and 71768 notaccessible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r pretrained\n",
        "# !rm predictions.zip"
      ],
      "metadata": {
        "id": "N_USYmjft93K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978a235b-2211-4e18-e593-d9fd5da52135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/f1_loss-[4, 32, 64]-conv-[3200, 64, 32, 16, 1]-lin-0.01-weight-decay-adamW-None01-09-05-49-45-Sequential-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-09-05-49-45\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "CNNModel.save_CNNModel(model_save_path, CNN)  # model\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"/content/pretrained/f1_loss-[4, 32, 64]-conv-[3200, 64, 32, 16, 1]-lin-0.01-weight-decay-adamW-None01-09-05-49-45-Sequential-model-0.0001lr-20epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef58b2ee-75ae-4d0c-a7ee-7ca570f3156e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71027ce-3a1b-49f5-e63c-890f55af5f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=0.7]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.7]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "3dd3de92-a7b0-4855-ac11-ad5e79f09cb5"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 73622 true values out of  269315  total 27.33676178452741 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [0.         0.         0.         ... 0.69957978 0.69974953 0.69990593]\n",
            "accessible probs [1.         1.         1.         ... 0.70086485 0.70057106 0.70030439]\n",
            "\n",
            "first 10\n",
            " ([1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0])\n",
            "last 10 of top 10000\n",
            " ([1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "5c26a070-91f4-443f-97c5-ce1b7d52ee23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 74%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "989ef2eb-b62e-4ff4-f19c-a0a5913e24e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6d7f063c-e7ab-4650-94c1-4103d90262d2\", \".ipynb_checkpoints\", 4096)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "1509ec73-b38f-40d2-b8fb-bf573de59027"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36aeb990-ca97-4bce-85c4-71c95c08816a\", \"predictions.zip\", 23111)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dda001b4035e4a85a8947774da3a1619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8378aa1e612430cb3e9d13301386551",
              "IPY_MODEL_18dff8a67eec47e6aa9cdde401dec1a0"
            ],
            "layout": "IPY_MODEL_9cc6637a0fa84052997803e40f2c64d5"
          }
        },
        "f8378aa1e612430cb3e9d13301386551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc3fd6b877834b7abff3b8a39a460eee",
            "placeholder": "​",
            "style": "IPY_MODEL_737cdbcf6bcc4abf9bc7efe850433bfb",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "18dff8a67eec47e6aa9cdde401dec1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbeaf4f9eb374ff6b5857f46e70d05a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaec0df02b734a3395f984014c81f8c8",
            "value": 1
          }
        },
        "9cc6637a0fa84052997803e40f2c64d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3fd6b877834b7abff3b8a39a460eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "737cdbcf6bcc4abf9bc7efe850433bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbeaf4f9eb374ff6b5857f46e70d05a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaec0df02b734a3395f984014c81f8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}