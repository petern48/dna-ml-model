{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dna_dataset import *\n",
    "from constants import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Files.zip\n",
      "  inflating: Files/accessible.fasta  \n",
      "  inflating: Files/notaccessible.fasta  \n",
      "  inflating: Files/test.fasta        \n"
     ]
    }
   ],
   "source": [
    "!unzip $DATA_ZIP_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DNADataset(ACCESSSIBLE_FILE, NOT_ACCESSIBLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sequences 525688\n",
      "num accessible 47239\n",
      "num not accessible 478449\n",
      "example entry 0\n",
      "label 0\n",
      "GAAATAATACCTATTGGGTTGCTTGAACCCGGGTTTTCATTTTATGATGC\n",
      "TAATTTTATTATACTGCACAGAAGCAGATTCATCTAATTCAGGAGCAACT\n",
      "TCATGTGTTATATCTGCAGGATGTACATAGTCAGTTGTTACAACATTATC\n",
      "TCTCTCCTGAGAAACATAGGCAAAGATTCCATGAAAGAAAATTTCTGCAG\n",
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "# ensure the DNADataset is loaded properly\n",
    "print('total sequences', len(train_dataset.sequences))\n",
    "print('num accessible', train_dataset.accessible_count)\n",
    "print('num not accessible', train_dataset.not_accessible_count)\n",
    "i = 0\n",
    "print(f\"example entry {i}\")\n",
    "item = train_dataset[i]\n",
    "print(\"label\", item['label'])\n",
    "print(item['sequence'])\n",
    "\n",
    "# ensure dataset was shuffled properly\n",
    "# check that not all the accessible labels are at the front\n",
    "for i in range(train_dataset.accessible_count):\n",
    "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
    "        print('shuffled')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "epochs = EPOCHS\n",
    "batch_size = BATCH_SIZE\n",
    "n_eval = N_EVAL\n",
    "loss_fn = nn.BCE.Loss()\n",
    "optimizer = optim.Adam()  # optim.Adam(model.parameters)\n",
    "\n",
    "# model =  insert torch model here, that takes sequence as input and output a label 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# TODO: separate train and val dataset\n",
    "val_dataset = train_dataset\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "writer = SummaryWriter()  # tensorboard log\n",
    "\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "\n",
    "    for batch in tqdm(train_loader):  # show the times for each batch\n",
    "        # Forward propagate\n",
    "        samples, labels = batch[\"sequence\"], batch['label']\n",
    "\n",
    "        samples.to(device)\n",
    "        labels.to(device)\n",
    "        outputs = model(samples)\n",
    "\n",
    "        labels = labels.reshape(-1,1).float()\n",
    "        # Backpropagation and gradient descent\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  # reset gradients before next iteration\n",
    "\n",
    "\n",
    "        # Periodically evaluate our model + log to Tensorboard\n",
    "        if step % n_eval == 0:\n",
    "            # Compute training loss and accuracy.\n",
    "            # Log the results to Tensorboard.\n",
    "            with torch.no_grad():\n",
    "                accuracy = compute_accuracy(outputs, labels)\n",
    "\n",
    "                writer.add_scalar('Training Loss', loss, epoch)\n",
    "                writer.add_scalar('Training Accuracy', accuracy, epoch)\n",
    "\n",
    "\n",
    "                # Compute validation loss and accuracy.\n",
    "                # Log the results to Tensorboard.\n",
    "                # Don't forget to turn off gradient calculations!\n",
    "                val_loss, val_accuracy = evaluate(val_loader, model, loss_fn)\n",
    "                writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "                writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acm_sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
