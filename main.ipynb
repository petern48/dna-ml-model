{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer\n",
        "- early stopping (less epochs)"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "69547448-cfc5-4a96-babd-297415b72cf3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "63e310e8-c8c3-48fe-80b1-5eb74de46f6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "# rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cdf7b8-2f42-4f04-b69e-6e6ba8e07dc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd, random\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "# from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275fe8e7-0472-4d42-dbbb-d85d17692ae4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2721bd3d-0f8d-4565-c908-d03dafb53632"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5cf324-3156-4c0a-db9f-985d6d6d46f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "d291331d-3826-4ab5-a894-36a2e1fdf5ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ac1f7b-db29-406c-aa35-7860ab3a82e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "l7SLRPi59Rm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ef7f41-2496-4eec-b0bd-079ba3dd2d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1d(4, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "Linear(in_features=6400, out_features=64, bias=True)\n",
            "Linear(in_features=64, out_features=32, bias=True)\n",
            "Linear(in_features=32, out_features=1, bias=True)\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "conv_filters = [64,128]\n",
        "# num_filters1 = 64  # 64\n",
        "# num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "# hidden_dense1 = 64  # 64\n",
        "# hidden_dense2 = 32  # 32\n",
        "linear_neurons = [64, 32]\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                           linear_neurons, dropout_rate_Dense)\n",
        "\n",
        "for i in range(len(CNN.Convs)):\n",
        "  print(CNN.Convs[i])\n",
        "for i in range(len(CNN.linears)):\n",
        "  print(CNN.linears[i])\n",
        "CNN.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Based on a test, using [1,pos_weight] gives the same results as [weight0, weight1]"
      ],
      "metadata": {
        "id": "Kx6jTrrcqZ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "# WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "WEIGHTED_LOSS = \"sklearn type weight\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weighted_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weighted_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()  # (reduction='none') ??\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = utils.macro_double_soft_f1\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8e16e6-9e6b-4456-c282-61baaf8a2484"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor([10.1283])\n",
            "weight for class 0 tensor([2.1975])\n",
            "weight for class 1 tensor([22.2567])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "weight_decay = .01\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"test-list-{weight_decay}-weight-decay-adamW-{WEIGHTED_LOSS}\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "        if loss_fn.__class__.__name__ == \"function\":  # custom loss function\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels) #, [weight_class0, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "# total_labels = np.empty(0)  # don't need to have same order\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "    # total_labels = np.concatenate((total_labels, labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "49ad44a7-c454-4a98-cf54-035717439a20"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.758958101272583 with F-Score 0.49299065420560745 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546,
          "referenced_widgets": [
            "7c319a168d27405db4e21376c2e758e3",
            "bbc3abe0b0e84961bfc5c406f6a943e8",
            "e270f6a70b064bf8a1e80edcbce95cc7",
            "44ea5c9466e54f719b9796aed189676d",
            "2340d8fa37054e3f989d2f48478f00c0",
            "8bf3502769884de3b905d6426db61891",
            "4e92f3aee68746469feca690e691f0d6",
            "5d7176bfd52049ed8e0a3c15d59d4ded"
          ]
        },
        "outputId": "226e1269-2b8e-49e4-fa83-94dbd8399e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.758958101272583\n",
            "Final Test Accuracy: 90.07886195354499 %\n",
            "Final Test Precision: 45.637825513020516 %\n",
            "Final Test Recall: 53.57847280924204 %\n",
            "Final Test F1 Score: 49.29038947573067 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.003 MB uploaded\\r'), FloatProgress(value=0.44888408927285817, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c319a168d27405db4e21376c2e758e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>Train F1</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Val Acc</td><td>▄▅▅▆▅▃▅▇▅▃▃▆▆█▁▆▄▃▆▄</td></tr><tr><td>Val F1</td><td>▁▃▄▄▄▆▆▅▆▇▇▇▇▆▇▇████</td></tr><tr><td>Val Loss</td><td>█▇▆▅▄▄▃▃▃▃▂▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Val Precision</td><td>▁▂▃▄▃▂▄▆▄▂▂▅▄█▁▅▃▃▅▃</td></tr><tr><td>Val Recall</td><td>▁▂▃▃▃▅▄▃▅▆▆▅▅▃█▆▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.89073</td></tr><tr><td>Train F1</td><td>0.36081</td></tr><tr><td>Train Loss</td><td>1.0018</td></tr><tr><td>Train Precision</td><td>0.3803</td></tr><tr><td>Val Acc</td><td>0.89326</td></tr><tr><td>Val F1</td><td>0.48492</td></tr><tr><td>Val Loss</td><td>516.62546</td></tr><tr><td>Val Precision</td><td>0.42809</td></tr><tr><td>Val Recall</td><td>0.55913</td></tr><tr><td>test_accuracy</td><td>0.90079</td></tr><tr><td>test_f1_score</td><td>0.4929</td></tr><tr><td>test_precision</td><td>0.45638</td></tr><tr><td>test_recall</td><td>0.53578</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">128-64-conv-0.01-weight-decay-adamW-sklearn type weight</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/kkyrckgj' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/kkyrckgj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240108_005923-kkyrckgj/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note: Actual Test {len(acc_seq_test)} accessible and {len(not_seq_test)} notaccessible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iniAmj4jhpX",
        "outputId": "f93360cd-575a-43d6-99ba-8c10808755d1"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Actual Test 7086 accessible and 71768 notaccessible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "    # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "    CM = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "    model.eval()\n",
        "    for batch in rest_notacc_loader:  # tqdm()\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "        outputs = model(samples)\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "\n",
        "        total_predictions += len(outputs)\n",
        "\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Computer accuracy, precision, recall, and f1 metrics\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "    print(f\"Rest not Precision: {precision * 100} %\")\n",
        "    print(f\"Rest not Recall: {recall * 100} %\")\n",
        "    print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "\n",
        "    # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r pretrained\n",
        "# !rm predictions.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_USYmjft93K",
        "outputId": "ed09515c-5bb6-4705-d014-5b56dbff98cb"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'pretrained': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5edf2026-c943-4a3e-8371-c8d9ee2bd38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/testBCElogits if same thresholdsklearn type loss01-07-20-58-33-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-07-20-58-33\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "CNNModel.save_CNNModel(model_save_path, CNN)  # model\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67282de6-24c4-4e91-dd02-ccf12386194b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ccb3c4-cf81-4d52-a10b-b6159882a1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "      outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=0.7]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.7]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "cd8ca203-1008-4f77-dcb0-b3bd73d5607e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 50718 true values out of  269315  total 18.83222249039229 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [6.06939238e-07 8.41556925e-07 9.11698066e-07 ... 6.99969590e-01\n",
            " 6.99984312e-01 6.99985087e-01]\n",
            "accessible probs [0.99852079 0.99639672 0.99634796 ... 0.70001477 0.70001328 0.70000458]\n",
            "\n",
            "first 10\n",
            " ([0.9985207915306091], [0.9963967204093933], [0.996347963809967], [0.9957489967346191], [0.9950012564659119], [0.9948647618293762], [0.9946529865264893], [0.9945916533470154], [0.9945886135101318], [0.9945071339607239])\n",
            "last 10 of top 10000\n",
            " ([0.8886889815330505], [0.8886885046958923], [0.8886776566505432], [0.8886751532554626], [0.8886736035346985], [0.8886717557907104], [0.8886685371398926], [0.8886619210243225], [0.8886516094207764], [0.8886155486106873])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "983bc37d-bd9e-4f1c-8160-c912f6877e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "025b7062-444a-4f43-cdd7-e1164b01475d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f339813-8796-4dd4-b203-93df9a223f02\", \"testBCElogits if same thresholdsklearn type loss01-07-20-58-33-CNNModel-model-0.0001lr-20epochs.pt\", 1759793)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "cc73ba08-2f2e-48c7-ad45-9c610a675ebd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30e54087-3121-4a77-9444-91b8fe4a889c\", \"predictions.zip\", 33513)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c319a168d27405db4e21376c2e758e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbc3abe0b0e84961bfc5c406f6a943e8",
              "IPY_MODEL_e270f6a70b064bf8a1e80edcbce95cc7"
            ],
            "layout": "IPY_MODEL_44ea5c9466e54f719b9796aed189676d"
          }
        },
        "bbc3abe0b0e84961bfc5c406f6a943e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2340d8fa37054e3f989d2f48478f00c0",
            "placeholder": "​",
            "style": "IPY_MODEL_8bf3502769884de3b905d6426db61891",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "e270f6a70b064bf8a1e80edcbce95cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e92f3aee68746469feca690e691f0d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d7176bfd52049ed8e0a3c15d59d4ded",
            "value": 1
          }
        },
        "44ea5c9466e54f719b9796aed189676d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2340d8fa37054e3f989d2f48478f00c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf3502769884de3b905d6426db61891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e92f3aee68746469feca690e691f0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7176bfd52049ed8e0a3c15d59d4ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}