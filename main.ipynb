{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- fix f1 loss calculation in compute_metrics()  \n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0f20cb49-a029-42af-b225-b0a7e77dd81b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "31a106e4-cf23-4d3a-8532-14c33e15e080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6eca767-51eb-45da-8eb3-b39de9a7d3bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745c7cb3-9280-4f85-9803-86a2711fb090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd61361b-5ab8-450c-c563-6fd2c76971a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0324e0-4ef4-4f5c-e5b6-6f136a5e54a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "# except:\n",
        "#   print(rest_not_sequences)\n",
        "#   raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "b0b728c8-6ee3-43a8-d22e-099ea8014655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8602f07f-6b8f-4172-f331-7b786068af17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "num_filters1 = 64  # 64\n",
        "num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 64\n",
        "hidden_dense2 = 32  # 32\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "                           hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "CNN.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "# WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "WEIGHTED_LOSS = \"sklearn type loss\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type loss\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "if WEIGHTED_LOSS == \"Balanced Class Weight\":\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "\n",
        "\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "\n",
        "# TRY NEXT\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weighted_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weighted_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([weight_class1]).to(device))\n",
        "    loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # loss_fn = nn.BCELoss()\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398912fe-d8c6-4e93-a0b8-793b0fa5b6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight for class 0 tensor([2.1975])\n",
            "weight for class 1 tensor([22.2567], device='cuda:0')\n",
            "Added sigmoid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = utils.macro_double_soft_f1"
      ],
      "metadata": {
        "id": "KYoGe1OkH1o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = .0001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e527ca61-417b-419f-aa89-151bb3123bc8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240107_071137-o6e219cm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/petern0408/dna_ml_model/runs/o6e219cm' target=\"_blank\">custom W BCE loss funct sklearn type loss</a></strong> to <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/petern0408/dna_ml_model/runs/o6e219cm' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/o6e219cm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n",
            "Training Loss: 1.7374 Acc: 0.2523 F1: 0.1905\n",
            "          Precision 0.1055 Recall: 0.9791\n",
            "Validation Loss: 902.0395 Acc: 0.3924 F1: 0.2250\n",
            "          Precision 0.1270 Recall: 0.9812\n",
            "\n",
            "Epoch 2 of 20\n",
            "Training Loss: 1.6789 Acc: 0.2914 F1: 0.1985\n",
            "          Precision 0.1105 Recall: 0.9765\n",
            "Validation Loss: 825.5881 Acc: 0.4572 F1: 0.2431\n",
            "          Precision 0.1390 Recall: 0.9701\n",
            "\n",
            "Epoch 3 of 20\n",
            "Training Loss: 1.6549 Acc: 0.3043 F1: 0.2015\n",
            "          Precision 0.1124 Recall: 0.9770\n",
            "Validation Loss: 917.3468 Acc: 0.3955 F1: 0.2265\n",
            "          Precision 0.1280 Recall: 0.9849\n",
            "\n",
            "Epoch 4 of 20\n",
            "Training Loss: 1.6299 Acc: 0.3180 F1: 0.2046\n",
            "          Precision 0.1143 Recall: 0.9759\n",
            "Validation Loss: 939.8917 Acc: 0.3832 F1: 0.2238\n",
            "          Precision 0.1261 Recall: 0.9893\n",
            "\n",
            "Epoch 5 of 20\n",
            "Training Loss: 1.6065 Acc: 0.3310 F1: 0.2076\n",
            "          Precision 0.1162 Recall: 0.9754\n",
            "Validation Loss: 847.6864 Acc: 0.4653 F1: 0.2472\n",
            "          Precision 0.1415 Recall: 0.9769\n",
            "\n",
            "Epoch 6 of 20\n",
            "Training Loss: 1.5862 Acc: 0.3397 F1: 0.2101\n",
            "          Precision 0.1177 Recall: 0.9772\n",
            "Validation Loss: 779.6310 Acc: 0.5307 F1: 0.2694\n",
            "          Precision 0.1566 Recall: 0.9629\n",
            "\n",
            "Epoch 7 of 20\n",
            "Training Loss: 1.5801 Acc: 0.3458 F1: 0.2114\n",
            "          Precision 0.1186 Recall: 0.9760\n",
            "Validation Loss: 637.4987 Acc: 0.6419 F1: 0.3160\n",
            "          Precision 0.1907 Recall: 0.9204\n",
            "\n",
            "Epoch 8 of 20\n",
            "Training Loss: 1.5694 Acc: 0.3508 F1: 0.2128\n",
            "          Precision 0.1194 Recall: 0.9763\n",
            "Validation Loss: 868.6919 Acc: 0.4768 F1: 0.2516\n",
            "          Precision 0.1444 Recall: 0.9787\n",
            "\n",
            "Epoch 9 of 20\n",
            "Training Loss: 1.5689 Acc: 0.3538 F1: 0.2135\n",
            "          Precision 0.1199 Recall: 0.9761\n",
            "Validation Loss: 600.6754 Acc: 0.6737 F1: 0.3326\n",
            "          Precision 0.2038 Recall: 0.9047\n",
            "\n",
            "Epoch 10 of 20\n",
            "Training Loss: 1.5615 Acc: 0.3567 F1: 0.2144\n",
            "          Precision 0.1204 Recall: 0.9767\n",
            "Validation Loss: 690.5561 Acc: 0.6081 F1: 0.3010\n",
            "          Precision 0.1792 Recall: 0.9389\n",
            "\n",
            "Epoch 11 of 20\n",
            "Training Loss: 1.5537 Acc: 0.3577 F1: 0.2147\n",
            "          Precision 0.1206 Recall: 0.9768\n",
            "Validation Loss: 715.2818 Acc: 0.5820 F1: 0.2904\n",
            "          Precision 0.1713 Recall: 0.9519\n",
            "\n",
            "Epoch 12 of 20\n",
            "Training Loss: 1.5438 Acc: 0.3617 F1: 0.2159\n",
            "          Precision 0.1213 Recall: 0.9777\n",
            "Validation Loss: 711.7994 Acc: 0.5816 F1: 0.2904\n",
            "          Precision 0.1713 Recall: 0.9526\n",
            "\n",
            "Epoch 13 of 20\n",
            "Training Loss: 1.5353 Acc: 0.3641 F1: 0.2164\n",
            "          Precision 0.1217 Recall: 0.9772\n",
            "Validation Loss: 666.0500 Acc: 0.6313 F1: 0.3132\n",
            "          Precision 0.1881 Recall: 0.9355\n",
            "\n",
            "Epoch 14 of 20\n",
            "Training Loss: 1.5294 Acc: 0.3688 F1: 0.2178\n",
            "          Precision 0.1225 Recall: 0.9779\n",
            "Validation Loss: 868.1116 Acc: 0.4816 F1: 0.2539\n",
            "          Precision 0.1458 Recall: 0.9815\n",
            "\n",
            "Epoch 15 of 20\n",
            "Training Loss: 1.5294 Acc: 0.3698 F1: 0.2180\n",
            "          Precision 0.1227 Recall: 0.9776\n",
            "Validation Loss: 751.9106 Acc: 0.5685 F1: 0.2856\n",
            "          Precision 0.1678 Recall: 0.9598\n",
            "\n",
            "Epoch 16 of 20\n",
            "Training Loss: 1.5257 Acc: 0.3730 F1: 0.2189\n",
            "          Precision 0.1233 Recall: 0.9779\n",
            "Validation Loss: 803.3516 Acc: 0.5322 F1: 0.2715\n",
            "          Precision 0.1578 Recall: 0.9699\n",
            "\n",
            "Epoch 17 of 20\n",
            "Training Loss: 1.5189 Acc: 0.3739 F1: 0.2191\n",
            "          Precision 0.1234 Recall: 0.9777\n",
            "Validation Loss: 693.1770 Acc: 0.6080 F1: 0.3025\n",
            "          Precision 0.1800 Recall: 0.9458\n",
            "\n",
            "Epoch 18 of 20\n",
            "Training Loss: 1.5213 Acc: 0.3773 F1: 0.2203\n",
            "          Precision 0.1241 Recall: 0.9791\n",
            "Validation Loss: 697.6114 Acc: 0.6022 F1: 0.2994\n",
            "          Precision 0.1778 Recall: 0.9458\n",
            "\n",
            "Epoch 19 of 20\n",
            "Training Loss: 1.5140 Acc: 0.3759 F1: 0.2198\n",
            "          Precision 0.1238 Recall: 0.9785\n",
            "Validation Loss: 711.3089 Acc: 0.5904 F1: 0.2943\n",
            "          Precision 0.1741 Recall: 0.9506\n",
            "\n",
            "Epoch 20 of 20\n",
            "Training Loss: 1.5099 Acc: 0.3804 F1: 0.2212\n",
            "          Precision 0.1247 Recall: 0.9792\n",
            "Validation Loss: 736.7439 Acc: 0.5803 F1: 0.2909\n",
            "          Precision 0.1715 Recall: 0.9579\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"custom W BCE loss funct {WEIGHTED_LOSS}\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "\n",
        "        loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # f1 = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "d0b5b3da-1c1e-4c1f-d056-f903882a94f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.769035816192627 with F-Score 0.48928931451612906 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546,
          "referenced_widgets": [
            "9d8c92bdb32b49c5a75f275ca74814f8",
            "dc950bc24d1c4b67bc1d2722c63c1e9f",
            "b68849b7c5db47a2b75fe1bfc34dee04",
            "6c39e8f6f5164c799dddc97b07422052",
            "aae78b283bc2408087464f84e8d4b6b1",
            "206d1758a9f2413397fdcb0fcb729342",
            "bb6826ee4a79481193c38a5d9452b766",
            "dd571e737c104562b5a8f0e01cd8b7e1"
          ]
        },
        "outputId": "0319cd07-014f-4025-83a9-1db908f50861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.769035816192627\n",
            "Final Test Accuracy: 89.70610609595293 %\n",
            "Final Test Precision: 44.196885301807434 %\n",
            "Final Test Recall: 54.775993237531694 %\n",
            "Final Test F1 Score: 48.9210443535703 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.032 MB of 0.032 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d8c92bdb32b49c5a75f275ca74814f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Train F1</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Val Acc</td><td>▁▃▁▁▃▅▇▃█▆▆▆▇▃▅▅▆▆▆▆</td></tr><tr><td>Val F1</td><td>▁▂▁▁▃▄▇▃█▆▅▅▇▃▅▄▆▆▆▅</td></tr><tr><td>Val Loss</td><td>▇▆██▆▅▂▇▁▃▃▃▂▇▄▅▃▃▃▄</td></tr><tr><td>Val Precision</td><td>▁▂▁▁▂▄▇▃█▆▅▅▇▃▅▄▆▆▅▅</td></tr><tr><td>Val Recall</td><td>▇▆██▇▆▂▇▁▄▅▅▄▇▆▆▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.38041</td></tr><tr><td>Train F1</td><td>0.2212</td></tr><tr><td>Train Loss</td><td>1.5099</td></tr><tr><td>Train Precision</td><td>0.12468</td></tr><tr><td>Val Acc</td><td>0.58028</td></tr><tr><td>Val F1</td><td>0.29088</td></tr><tr><td>Val Loss</td><td>736.74394</td></tr><tr><td>Val Precision</td><td>0.17147</td></tr><tr><td>Val Recall</td><td>0.95795</td></tr><tr><td>test_accuracy</td><td>0.89706</td></tr><tr><td>test_f1_score</td><td>0.48921</td></tr><tr><td>test_precision</td><td>0.44197</td></tr><tr><td>test_recall</td><td>0.54776</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">custom W BCE loss funct sklearn type loss</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/o6e219cm' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/o6e219cm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240107_071137-o6e219cm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "# test_f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import roc_curve, plot_roc_curve,\n"
      ],
      "metadata": {
        "id": "ZT0UR8kxTws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "\n",
        "    # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "    CM = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch in rest_notacc_loader:  # tqdm()\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "        outputs = model(samples)\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "\n",
        "        total_predictions += len(outputs)\n",
        "\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Computer accuracy, precision, recall, and f1 metrics\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "    print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "    print(f\"Rest not Precision: {precision * 100} %\")\n",
        "    print(f\"Rest not Recall: {recall * 100} %\")\n",
        "    print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "\n",
        "    # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5030ec-3d2d-403b-c4e4-3102115a6947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/custom W BCE loss funct sklearn type loss01-07-07-25-56-Sequential-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-07-07-25-56\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "CNNModel.save_CNNModel(model_save_path, model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8daa35c-bdd4-4a31-c467-46ae597e655c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a507918-5d99-4af4-da34-b3d72c291f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "      outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "print(\"Predicted\", len(np_probs[np_probs>0.5]), \"true values out of \", len(np_probs), \" total\")\n",
        "not_probs = np_probs[np_probs<=0.5]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.5]\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "5351225e-cd07-43f2-dbfe-482a4d9af6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 115909 true values out of  269315  total\n",
            "\n",
            "not accessible probs [6.27759619e-07 1.44199976e-06 2.95829045e-06 ... 4.99992728e-01\n",
            " 4.99992728e-01 4.99998569e-01]\n",
            "accessible probs [0.99853408 0.99636698 0.99572963 ... 0.50001043 0.50000781 0.50000566]\n",
            "\n",
            "first 10\n",
            " ([0.998534083366394], [0.9963669776916504], [0.9957296252250671], [0.9957273006439209], [0.9952033758163452], [0.9948686361312866], [0.9942232966423035], [0.9937678575515747], [0.993413507938385], [0.9933021068572998])\n",
            "last 10 of top 10000\n",
            " ([0.8840652704238892], [0.884062647819519], [0.8840597867965698], [0.8840574622154236], [0.8840485215187073], [0.8840472102165222], [0.8840442895889282], [0.8840397596359253], [0.8840376138687134], [0.8840323686599731])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "b0d18db6-c9a9-4ce2-e1e9-c0947978dfac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "b5908cf1-38d7-4770-e874-79d12bef1a12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e5d36372-f2ff-4d0c-846c-3ee63da82e07\", \"custom W BCE loss funct sklearn type loss01-07-07-25-56-Sequential-model-0.0001lr-20epochs.pt\", 1759698)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "5465123c-83f3-4a3f-8496-9a44d53e649c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_50041b1e-9efd-4cf3-9240-53cc35294dd7\", \"predictions.zip\", 33512)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d8c92bdb32b49c5a75f275ca74814f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc950bc24d1c4b67bc1d2722c63c1e9f",
              "IPY_MODEL_b68849b7c5db47a2b75fe1bfc34dee04"
            ],
            "layout": "IPY_MODEL_6c39e8f6f5164c799dddc97b07422052"
          }
        },
        "dc950bc24d1c4b67bc1d2722c63c1e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aae78b283bc2408087464f84e8d4b6b1",
            "placeholder": "​",
            "style": "IPY_MODEL_206d1758a9f2413397fdcb0fcb729342",
            "value": "0.032 MB of 0.032 MB uploaded\r"
          }
        },
        "b68849b7c5db47a2b75fe1bfc34dee04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6826ee4a79481193c38a5d9452b766",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd571e737c104562b5a8f0e01cd8b7e1",
            "value": 1
          }
        },
        "6c39e8f6f5164c799dddc97b07422052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae78b283bc2408087464f84e8d4b6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206d1758a9f2413397fdcb0fcb729342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb6826ee4a79481193c38a5d9452b766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd571e737c104562b5a8f0e01cd8b7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}