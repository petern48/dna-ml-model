{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- fix f1 loss calculation in compute_metrics()  \n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0f20cb49-a029-42af-b225-b0a7e77dd81b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "31a106e4-cf23-4d3a-8532-14c33e15e080"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6eca767-51eb-45da-8eb3-b39de9a7d3bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745c7cb3-9280-4f85-9803-86a2711fb090"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd61361b-5ab8-450c-c563-6fd2c76971a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0324e0-4ef4-4f5c-e5b6-6f136a5e54a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "# except:\n",
        "#   print(rest_not_sequences)\n",
        "#   raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "b0b728c8-6ee3-43a8-d22e-099ea8014655"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8602f07f-6b8f-4172-f331-7b786068af17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "num_filters1 = 64  # 64\n",
        "num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 64\n",
        "hidden_dense2 = 32  # 32\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "model = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "                           hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "model.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "# USE_WEIGHTED_LOSS = True\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "# WEIGHTED_LOSS = \"sklearn type loss\"\n",
        "# USE_WEIGHTED_LOSS = True  # Note may not work correctly if used with resampling bc my code\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "# weight_class0 = num_train / len(actual_not_seq_train) * 2\n",
        "\n",
        "# not good. suppose to use weight_class0 too\n",
        "if WEIGHTED_LOSS == \"sklearn type loss\":\n",
        "    weight_class1 = torch.Tensor([len(actual_not_seq_train) + len(actual_acc_seq_train) / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "if WEIGHTED_LOSS == \"Balanced Class Weights\":\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = torch.Tensor([len(actual_not_seq_train) / len(actual_acc_seq_train)]).to(device)\n",
        "\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = nn.BCEWithLogitsLoss(pos_weight=weight_class1)\n",
        "    loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # loss_fn = nn.BCELoss()\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(model, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8e4ee6-c9ea-4bbb-df15-53913b6ad289"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight for class 1 tensor([22.2567], device='cuda:0')\n",
            "Added softmax\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): CNNModel(\n",
              "    (Conv1): Conv1d(4, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (Conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    (linear1): Linear(in_features=6400, out_features=64, bias=True)\n",
              "    (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (linear3): Linear(in_features=32, out_features=1, bias=True)\n",
              "    (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (1): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = utils.macro_double_soft_f1"
      ],
      "metadata": {
        "id": "KYoGe1OkH1o5"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = .0001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "8z_gnhTp9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbc1ff2d-ef43-4599-957d-cf7df79555bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240107_064314-vxpf2ow0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/petern0408/dna_ml_model/runs/vxpf2ow0' target=\"_blank\">custom BCE weighted loss function Balanced Class Weights</a></strong> to <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/petern0408/dna_ml_model/runs/vxpf2ow0' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/vxpf2ow0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n",
            "Training Loss: 1.7374 Acc: 0.2522 F1: 0.1905\n",
            "          Precision 0.1055 Recall: 0.9791\n",
            "Validation Loss: 902.1012 Acc: 0.3903 F1: 0.2244\n",
            "          Precision 0.1267 Recall: 0.9817\n",
            "\n",
            "Epoch 2 of 20\n",
            "Training Loss: 1.6787 Acc: 0.2915 F1: 0.1985\n",
            "          Precision 0.1105 Recall: 0.9766\n",
            "Validation Loss: 830.6612 Acc: 0.4543 F1: 0.2423\n",
            "          Precision 0.1384 Recall: 0.9708\n",
            "\n",
            "Epoch 3 of 20\n",
            "Training Loss: 1.6546 Acc: 0.3047 F1: 0.2016\n",
            "          Precision 0.1124 Recall: 0.9767\n",
            "Validation Loss: 921.6591 Acc: 0.3926 F1: 0.2258\n",
            "          Precision 0.1275 Recall: 0.9856\n",
            "\n",
            "Epoch 4 of 20\n",
            "Training Loss: 1.6296 Acc: 0.3178 F1: 0.2045\n",
            "          Precision 0.1142 Recall: 0.9756\n",
            "Validation Loss: 926.7764 Acc: 0.3873 F1: 0.2248\n",
            "          Precision 0.1268 Recall: 0.9884\n",
            "\n",
            "Epoch 5 of 20\n",
            "Training Loss: 1.6074 Acc: 0.3305 F1: 0.2075\n",
            "          Precision 0.1161 Recall: 0.9754\n",
            "Validation Loss: 861.1194 Acc: 0.4533 F1: 0.2438\n",
            "          Precision 0.1392 Recall: 0.9807\n",
            "\n",
            "Epoch 6 of 20\n",
            "Training Loss: 1.5866 Acc: 0.3394 F1: 0.2100\n",
            "          Precision 0.1176 Recall: 0.9770\n",
            "Validation Loss: 808.3027 Acc: 0.5080 F1: 0.2612\n",
            "          Precision 0.1510 Recall: 0.9678\n",
            "\n",
            "Epoch 7 of 20\n",
            "Training Loss: 1.5797 Acc: 0.3452 F1: 0.2111\n",
            "          Precision 0.1184 Recall: 0.9751\n",
            "Validation Loss: 618.1287 Acc: 0.6564 F1: 0.3231\n",
            "          Precision 0.1963 Recall: 0.9124\n",
            "\n",
            "Epoch 8 of 20\n",
            "Training Loss: 1.5695 Acc: 0.3503 F1: 0.2126\n",
            "          Precision 0.1193 Recall: 0.9759\n",
            "Validation Loss: 929.3008 Acc: 0.4474 F1: 0.2427\n",
            "          Precision 0.1384 Recall: 0.9853\n",
            "\n",
            "Epoch 9 of 20\n",
            "Training Loss: 1.5685 Acc: 0.3543 F1: 0.2137\n",
            "          Precision 0.1200 Recall: 0.9764\n",
            "Validation Loss: 628.3191 Acc: 0.6485 F1: 0.3198\n",
            "          Precision 0.1936 Recall: 0.9194\n",
            "\n",
            "Epoch 10 of 20\n",
            "Training Loss: 1.5627 Acc: 0.3556 F1: 0.2139\n",
            "          Precision 0.1201 Recall: 0.9759\n",
            "Validation Loss: 709.5114 Acc: 0.5948 F1: 0.2966\n",
            "          Precision 0.1757 Recall: 0.9505\n",
            "\n",
            "Epoch 11 of 20\n",
            "Training Loss: 1.5529 Acc: 0.3582 F1: 0.2148\n",
            "          Precision 0.1207 Recall: 0.9769\n",
            "Validation Loss: 729.5394 Acc: 0.5714 F1: 0.2860\n",
            "          Precision 0.1682 Recall: 0.9553\n",
            "\n",
            "Epoch 12 of 20\n",
            "Training Loss: 1.5414 Acc: 0.3629 F1: 0.2162\n",
            "          Precision 0.1215 Recall: 0.9776\n",
            "Validation Loss: 746.6940 Acc: 0.5608 F1: 0.2822\n",
            "          Precision 0.1654 Recall: 0.9608\n",
            "\n",
            "Epoch 13 of 20\n",
            "Training Loss: 1.5349 Acc: 0.3646 F1: 0.2164\n",
            "          Precision 0.1217 Recall: 0.9766\n",
            "Validation Loss: 702.8670 Acc: 0.6012 F1: 0.2992\n",
            "          Precision 0.1777 Recall: 0.9474\n",
            "\n",
            "Epoch 14 of 20\n",
            "Training Loss: 1.5296 Acc: 0.3684 F1: 0.2176\n",
            "          Precision 0.1224 Recall: 0.9773\n",
            "Validation Loss: 911.3593 Acc: 0.4535 F1: 0.2446\n",
            "          Precision 0.1396 Recall: 0.9845\n",
            "\n",
            "Epoch 15 of 20\n",
            "Training Loss: 1.5285 Acc: 0.3703 F1: 0.2181\n",
            "          Precision 0.1228 Recall: 0.9776\n",
            "Validation Loss: 792.6904 Acc: 0.5431 F1: 0.2762\n",
            "          Precision 0.1610 Recall: 0.9699\n",
            "\n",
            "Epoch 16 of 20\n",
            "Training Loss: 1.5261 Acc: 0.3725 F1: 0.2185\n",
            "          Precision 0.1230 Recall: 0.9763\n",
            "Validation Loss: 786.2591 Acc: 0.5473 F1: 0.2774\n",
            "          Precision 0.1619 Recall: 0.9670\n",
            "\n",
            "Epoch 17 of 20\n",
            "Training Loss: 1.5167 Acc: 0.3753 F1: 0.2197\n",
            "          Precision 0.1237 Recall: 0.9787\n",
            "Validation Loss: 751.8254 Acc: 0.5668 F1: 0.2856\n",
            "          Precision 0.1676 Recall: 0.9634\n",
            "\n",
            "Epoch 18 of 20\n",
            "Training Loss: 1.5201 Acc: 0.3782 F1: 0.2205\n",
            "          Precision 0.1242 Recall: 0.9786\n",
            "Validation Loss: 700.4876 Acc: 0.6038 F1: 0.3009\n",
            "          Precision 0.1788 Recall: 0.9488\n",
            "\n",
            "Epoch 19 of 20\n",
            "Training Loss: 1.5111 Acc: 0.3775 F1: 0.2203\n",
            "          Precision 0.1241 Recall: 0.9787\n",
            "Validation Loss: 713.8974 Acc: 0.5954 F1: 0.2970\n",
            "          Precision 0.1760 Recall: 0.9512\n",
            "\n",
            "Epoch 20 of 20\n",
            "Training Loss: 1.5077 Acc: 0.3816 F1: 0.2215\n",
            "          Precision 0.1249 Recall: 0.9790\n",
            "Validation Loss: 691.5259 Acc: 0.6179 F1: 0.3077\n",
            "          Precision 0.1838 Recall: 0.9448\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"custom BCE weighted loss function {WEIGHTED_LOSS}\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss\": WEIGHTED_LOSS,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "\n",
        "        loss = loss_fn(outputs, labels, [1, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # f1 = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "6b97eb0b-9232-4bce-93cc-81bb009c48ca"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAQ0lEQVR4nO3de3wU9b3/8ffkngAJIBACWQmKF1SEIgk/RLw1iCLxaKuiUg2CtVb0IMEbasEjFRQVsYKoiAY9tuihqNwKAoqCUkEQq0JBJAgBAgGEkIRcd35/bLMYSWB3M7uzl9fz8ZjHYzLMTD4ZwX3n+/3O92uYpmkKAAAgTETZXQAAAICVCDcAACCsEG4AAEBYIdwAAICwQrgBAABhhXADAADCCuEGAACElRi7Cwg0p9Op3bt3q0WLFjIMw+5yAACAB0zT1JEjR9ShQwdFRZ24bSbiws3u3bvlcDjsLgMAAPhg586dSk9PP+E5ERduWrRoIcn1cJKTk22uBoAtysqkDh1c+7t3S82a2VsPgJMqKSmRw+Fwf46fSMSFm7quqOTkZMINEKmio4/tJycTboAQ4smQEgYUAwCAsEK4AQAAYSXiuqUAQDExUm7usX0AYYV/1QAiT3y8lJ9vdxWIIE6nU1VVVXaXEfTi4uJO+pq3Jwg3AAD4UVVVlQoKCuR0Ou0uJehFRUWpc+fOiouLa9J9CDcAIo9pSuXlrv2kJIkJPeEnpmlqz549io6OlsPhsKRVIlzVTbK7Z88enXrqqU2aaJdwAyDylJdLzZu79ktLeRUcflNTU6Py8nJ16NBBSUlJdpcT9Nq2bavdu3erpqZGsbGxPt+HCAkAgJ/U1tZKUpO7WSJF3XOqe26+ItwAAOBnrGXoGaueE+EGAACEFVvDzaeffqqcnBx16NBBhmHo/fffP+k1K1asUM+ePRUfH68uXboon9c5AQDAz9gabsrKytS9e3dNmzbNo/MLCgp09dVX67LLLtOGDRt033336Y477tCSJUv8XKln+vfvr5iYGKWkpGjy5Ml2lwMAQEQyTNM07S5CcvWzvffee7r22msbPeehhx7SwoUL9e2337qP3XTTTTp06JAWL17s0fcpKSlRSkqKDh8+bOnCmQ31E7Zt21b79u2z7HsAsEhZGW9LISAqKipUUFCgzp07KyEhwe5yvHLppZeqR48emjJliiX3Gzp0qA4dOnTCXpoTPS9vPr9DaszN6tWrlZ2dXe/YgAEDtHr16kavqaysVElJSb3Nav3792/weHFxMS04QDCKjpauv961/XyFcCCIFRYW6uOPP1ZhYaHdpQS9kAo3RUVFSk1NrXcsNTVVJSUlOnr0aIPXTJw4USkpKe7N4XBYXteqVasa/bO5c+da/v0ANFFCgvR//+faQuy3aYQ20zRVVlbm9fbSSy+pU6dOuvzyy9WpUye99NJLXt/Dm46aoUOH6pNPPtELL7wgwzBkGIa2b9+ub7/9VldddZWaN2+u1NRU3Xrrrdq/f7/7ujlz5qhbt25KTEzUKaecouzsbJWVlenxxx/XrFmz9MEHH7jvt2LFCj88YZewn8RvzJgxysvLc39dUlJiecC56KKLtGzZsgb/7De/+Y2l3wsAELrKy8vVvK5L1EdOp1MjRozQiBEjvLqutLRUzTzsgn3hhRe0ZcsWnXfeeXriiSckSbGxscrKytIdd9yh559/XkePHtVDDz2kG2+8UR999JH27Nmjm2++WZMmTdJ1112nI0eOaOXKlTJNU/fff782bdqkkpISvfHGG5Kk1q1be/eDeyGkwk379u21d+/eesf27t2r5ORkJSYmNnhNfHy84uPj/VrX0qVLGx1z8/NgBQBAKEhJSVFcXJySkpLUvn17SdKf//xn/epXv9KECRPc573++utyOBzasmWLSktLVVNTo9/85jfq1KmTJKlbt27ucxMTE1VZWem+nz+FVLjp06ePFi1aVO/Y0qVL1adPH5sqOsY0TfXs2VNfffWVJOm5554j2ADBigHFsElSUpJKS0u9umbXrl3q2rVrvYU3o6OjtXHjRnXs2NGr790UX3/9tT7++OMGW55++OEHXXHFFfr1r3+tbt26acCAAbriiit0/fXXq1WrVk36vr6wNdyUlpZq69at7q8LCgq0YcMGtW7dWqeeeqrGjBmjXbt26c0335Qk3XXXXZo6daoefPBBDRs2TB999JHeffddLVy40K4foZ5Jkyapf//+6tatG8EGAHAcwzA87hqqc+aZZ+rVV1/VH/7wB9XW1io6OlqvvPKKzjzzTD9V2bDS0lLl5OTo6aefPu7P0tLSFB0draVLl+rzzz/Xhx9+qBdffFGPPvqovvjiC3Xu3Dmgtdoabr788ktddtll7q/rAkFubq7y8/O1Z88e7dixw/3nnTt31sKFCzVq1Ci98MILSk9P12uvvaYBAwYEvHYAAAJl+PDhGjBggLZu3aouXbooPT3d798zLi6u3hpPPXv21N///ndlZGQoJqbh+GAYhvr27au+fftq7Nix6tSpk9577z3l5eUddz9/sjXcXHrppSccvd3Q7MOXXnqpu+sHAIBIkZ6eHpBQUycjI0NffPGFtm/frubNm2vEiBGaMWOGbr75Zj344INq3bq1tm7dqtmzZ+u1117Tl19+qeXLl+uKK65Qu3bt9MUXX6i4uFhdu3Z132/JkiXavHmzTjnlFKWkpDRp5e8TCalXwQEAQGDcf//9io6O1jnnnKO2bduqqqpKn332mWpra3XFFVeoW7duuu+++9SyZUtFRUUpOTlZn376qQYOHKgzzzxTjz32mJ577jldddVVkqTf//73Ouuss9SrVy+1bdtWn332md9qD6kBxQAAIDDOPPPMBifJbWz+tq5du55wtYC2bdvqww8/tKy+E6HlBgAAhBVabgBEnuhoaeDAY/sAwgrhBkDkSUiQgmQKCQDWo1sKAAA/82Zdp0hm1XMi3AAA4CfR/+n2rKqqsrmS0FD3nKKb2F1Mt5QflJaWqrCwMKDzEQDwQlmZ1K6da3/fPpZfgN/ExMQoKSlJxcXFio2NVVQUbQqNcTqdKi4uVlJSUqOTBHqKcGOhf/zjH5Jcy0g4HA699tprGj58uM1VAWhQebndFSACGIahtLQ0FRQU6Mcff7S7nKAXFRWlU089tcHFqL1hmBHWEVhSUqKUlBQdPnxYycnJlt23sLBQDofjuOM7d+6kBQcINiyciQBzOp10TXkgLi6u0dYtbz6/abmxyPz58xs8vmDBAt11110BrgYAEEyioqKUkJBgdxkRg84/i2zevLnB41u2bAlwJQAARDbCjUXa1Q1O/IW2bdsGuBIAACIb4cYiXbp08eo4AADwD8bcWKRz584NHs/IyAhsIQBOLipKuuSSY/sAwgr/qi1SUFDQ4PHt27cHthAAJ5eYKK1Y4doSE+2uBoDFCDcAACCsEG4scuGFFzY46dC7775rQzUAAEQuwo1F0tPT9cgjjxx3fM6cOVq7dq0NFQFoVFmZ1Lataysrs7saABYj3FiosVkVFy5cGOBKAJzU/v2uDUDYIdxYqLEWmoqKigBXAgBA5CLcWKSwsFBLlixp8M9YTwQAgMAh3Fjk+++/V2NrkPI6OAAAgUO4sUjzuhWGG/Dee++psLAwgNUAABC5CDcWaWwSvzqrV68OUCUAAEQ2wk2A3HjjjZo5c6bdZQCQXEsu9Orl2lh+AQg7htnYQJEwVVJSopSUFB0+fFjJycmW3bewsFAOh+Ok5+3cuVPp6emWfV8AACKBN5/f/MpikfT0dN1+++0nPW/BggUBqAYAgMhFuLHQlVdeedJz1q1bF4BKAACIXIQbC82bN8/uEgB4orxcyshwbeXldlcDwGIxdhcQLgoLC/X222+f9LxTTjklANUAOCHTlH788dg+gLBCy41FPv/8c4/OO3DggJ8rAQAgshFuAmzNmjV2lwAAQFgj3Fikc+fOHp33r3/9i9mKAQDwI8KNRUpLSz0+l9fBAQDwH8KNRU60ttQvffrpp36sBACAyMbbUhbxpuVm7969fqwEwEkZhnTOOcf2AYQVwo1FzjjjDEVFRcnpdJ703BYtWgSgIgCNSkqSvvvO7ioA+AndUhZJT0/Xq6++KoPfAgEAsBXhxkLDhw/Xn//855OeV11dHYBqAACITIQbGzBLMWCz8nLp3HNdG8svAGGHMTcW27dv30nPeeuttxQVFaX8/Hz/FwTgeKYpbdx4bB9AWKHlxmJnnXWWR+fNmjVLa9eu9XM1AABEHsKNxXJycjweVPzoo4/q7rvvZlI/AAAsRLixWHp6umbMmKGoqJM/2qVLl2r69OnKyclRZmZmAKoDACD8EW78YPjw4frxxx81efJkj6/58ssvde+99/qxKgAAIgPhxk/S09N1ww03eHXN1KlTWVQTAIAmItz4UXp6un796197dc1bb73lp2oAuBmG1KmTa2PiTSDsEG78bOLEiV6dP3v2bD9VAsAtKUnavt21JSXZXQ0AixFu/CwzM1Opqaken79//34/VgMAQPgj3ATAa6+95vG5p556qh8rAQAg/BFuAmDQoEFq1qyZR+cyoBgIgKNHpcxM13b0qN3VALAY4SZAbrrpJo/OKywsZOZiwN+cTunLL12b02l3NQAsRrgJkD/84Q8en5uVlaXHHnvMj9UAABC+CDcBkpmZqdzcXI/Pf/LJJ72eJwcAAEiGaUbWkrglJSVKSUnR4cOHlZycHPDvv3btWn322WdyOp0aPXr0Sc9fs2YNSzMAVisrk5o3d+2XlkoejokDYB9vPr8JNzbyZIHNHj16aM+ePYqJiVFeXp7y8vICUBkQ5gg3QMgh3JxAMIWbuLg4VVdXe3VN27ZttW/fPj9VBEQIwg0Qcrz5/GbMjY369u3r9TXFxcVeLcgJoBFt2rg2AGGHlhsbFRYWyuFweH0drTcAgEhDy02ISE9P92r24joHDx7Uxx9/zIR/AAA0gHBjs+HDh2vnzp0677zzPL6mtrZWl19+uRwOh+666y5CDgAAP0O4CQLp6en65ptvfLr2lVdekcPh0MyZMy2uCghjR49Kl17q2lh+AQg7toebadOmKSMjQwkJCerdu7fWrFlzwvOnTJmis846S4mJiXI4HBo1apQqKioCVG3wuuOOO/TQQw/RigN4wumUPvnEtbH8AhB2bA0377zzjvLy8jRu3DitX79e3bt314ABAxodLPvXv/5VDz/8sMaNG6dNmzZp5syZeuedd/TII48EuHL/OOuss5p0/aRJk2jFAQBEPFvflurdu7cyMzM1depUSZLT6ZTD4dC9996rhx9++Ljz77nnHm3atEnLly93Hxs9erS++OILrVq1yqPvGUxvS/2Sr29PNWTnzp1KT0+35F5A2GGeGyDkhMTbUlVVVVq3bp2ys7OPFRMVpezsbK1evbrBay688EKtW7fO3XW1bds2LVq0SAMHDmz0+1RWVqqkpKTeFqx8fXuqIeHSmgUAgLdsCzf79+9XbW2tUlNT6x1PTU1VUVFRg9fccssteuKJJ3TRRRcpNjZWp59+ui699NITfpBPnDhRKSkp7s2qlhF/+fnbUzExMbrooovUqVMnr+/z4Ycf1vu6sLCQ18cBABHB9gHF3lixYoUmTJigl156SevXr9fcuXO1cOFCjR8/vtFrxowZo8OHD7u3nTt3BrBi39S9PVVdXa2VK1dq+/btGjp0qFf32Lt3rxYsWKCbbrpJhmHI4XC4Xx9v3ry58vPz/VI7AAB2s23MTVVVlZKSkjRnzhxde+217uO5ubk6dOiQPvjgg+Ou6devn/7f//t/euaZZ9zH/vd//1d33nmnSktLFRV18qwWzGNuTqawsNDdZffNN9+cMNR54vTTT9fWrVutKA0ILWVlUrt2rv19+xhzA4SAkBhzExcXpwsuuKDe4GCn06nly5erT58+DV5TXl5+XICJjo6WJEXCKhLp6em64YYbdMMNN+iJJ55Q27Ztm3S/H374gRYcRKZmzVwBp6yMYAOEIVu7pfLy8jRjxgzNmjVLmzZt0h//+EeVlZXp9ttvlyTddtttGjNmjPv8nJwcTZ8+XbNnz1ZBQYGWLl2qP/3pT8rJyXGHnEiyb9++JgecumcNAEC4iLHzmw8ePFjFxcUaO3asioqK1KNHDy1evNg9yHjHjh31Wmoee+wxGYahxx57TLt27VLbtm2Vk5OjJ5980q4fwXYLFy5UVlZWk+5hGEZEtHwBACIDq4KHgaFDh2rWrFlNvk+E/VVAJKuokH77W9f+3/8uJSTYWw+AkwqJMTewTn5+/kmXrfCEYRgWVAOEgNpaadEi11Zba3c1ACxGuAkTmZmZMk1TSUlJTboPAQcAEOoIN2GmrKxMsbGxxx3Pzc31ePbj++67z+KqAAAIHMJNGKqqqtLIkSOVlpamiy++WGvWrFF+fr579uOTsWoJCAAA7MCA4gh1su6nCPtrgUjDwplAyGFAMU7qZOFl7NixAaoEAABrEW4iWPO631wbMH78eM2cOTOA1QAAYA3CTQQbPnz4Cf/8jjvuUFxcHEs0IPw0ayaZpmujSwoIO4y5iXCevvrdsWNHFRYW+rkaAAAaxpgbeCwmxrMVOHbt2qULL7zQz9UAANB0hJsI99u6Keg9sHr1amVlZSk1NVWGYeicc87xY2WAH1VUSDfc4NoqKuyuBoDF6JaCoqOj5XQ6fb4+wv4KIRzwKjgQcuiWgldqa2s1ePBgn69nyQYAQDAh3ECSNHv2bJmmqRYtWvh0fV3AWbt2rcaOHavp06czABkAYAvPRpMiYpSUlGjt2rXKysry+tpftuDcfffdeu211076yjkAAFai5QbHyczM1Jo1ayy51x133EELDgAgoAg3aFBmZqZyc3MtuddVV11lyX0AAPAE4QaNys/P15o1a3TzzTc36T7ffvutmjVrpvvuu8+awgAAOAFeBYfHFixYoMWLF+u0007T6NGjfbpHXFycKisrLa4M8JJpSuXlrv2kJIk3/oCg583nNwOK4bFBgwZp0KBBkqR//etfmjVrltf3qKqqkmEYysnJ0bx586wuEfCMYTC3DRDG6JaCT+q6rEaNGqW4uDivr58/fz7z4wAA/IJwA59lZmZq8uTJqqyslGmaPs1UbBgGY3EQeJWV0tChro1uUiDsMOYGlvO1RSY+Pl5DhgzRXXfdpczMTIurAn6G5ReAkMPyC7CVr3m5srJSr7/+urKysliUEwDgM8IN/MI0Tf3pT3/y+fpNmzYxJgcA4BPCDfzmiSeekGmaGjlypM/3IOAAALxFuIHfTZkyRaZp+rykAwEHAOANwg0CJjMzU6Zp6uqrr/b6WsMw3JuvK5cDACID4QYBt2DBAu3cuVOtWrXy6frS0lJ30ElMTNTkyZMtrhAAEMoIN7BFenq6Dh48KNM0lZ2d7fN9KioqNHr0aHfY6dGjh3VFInwlJUn79rm2pCS7qwFgMea5QVCxanxNhP21BoCwxzw3CFlWhRLDMFRYWGjJvQAAoYVwg6BjVcBxOBxKTEy05F4IM5WV0ogRro3lF4CwQ7hBUGrqWJw6FRUV9d60SktLs6A6hLyaGumll1xbTY3d1QCwGOEGQWvp0qXuBTlN09Rzzz2nqKim/ZUtKipi3hwACHOEG4SMvLw81dbWyjRNde/evUn3IuAAQPgi3CAkbdiwwd2i42v3FQEHAMIT4QYhr677yheGYahfv34WVwQAsBPhBmHDNE0NGzbM6+tWrVolwzB8njEZABBcCDcIKzNnzvQ55Bw6dIiuKgAIA4QbhKW6kFO3ecMwDKWkpPipMgSFxESpoMC1MRcSEHZi7C4ACATTNL1qlSkpKZFhGCzjEK6ioqSMDLurAOAntNwgYsyfP9/ra+imAoDQQ7hBxBg0aJAuvPBCr68j4IShqirpgQdcW1WV3dUAsBjhBhHls88+0/z583X99dd79XaUYRhasGCBHytDQFVXS88+69qqq+2uBoDFDDPCBhV4s2Q6IoM3LTPdunXTv/71Lz9Wg4AoK5OaN3ftl5ZKzZrZWw+Ak/Lm85uWG0Q80zTVvO6D7iS++eYbxcQwDh8AghnhBpB05MgRj9+Mqq2tZRwOAAQxwg3wM9700hJwACA4EW6AX/A24MTGxmrt2rV+rAgA4A3CDdAA0zSVk5Pj0bk1NTXKysqSYRhyOBx+rgwAcDKEG6AR8+bN02uvvebVNYWFhXRXhYLEROnbb10byy8AYYdXwYGTKCws9KlFJsL+aQGAX/EqOGCh9PR0n4IKLTgAYA8m7AA85O3im5JYfDNYVVVJEya49h95RIqLs7ceAJai5Qbwgmmauuiii7y6xjAM9e/f308VwSfV1dL//I9rY/kFIOwQbgAvrVy5UqZpav78+R635CxbtkyGYeiMM87wc3UAAMIN4KNBgwbJ6XR61e20detWGYahZqxlBAB+Q7gBLODtuJry8nIZhqEePXr4pyAAiGCEG8Aivgwc/vrrr3mrCgAsRrgBLOTrm1G04ACAdXx6Fby2tlb5+flavny59u3bJ6fTWe/PP/roI0uKA0KRaZrq3Lmztm/f7vE1X3/9tRISEjRkyBDNnDnTf8UBQATwaYbie+65R/n5+br66quVlpZ2XLP6888/b1mBVmOGYgRSu3btVFxc7NU1hmEc9wsDLFZbK61f79rv2VOKjra3HgAn5c3nt0/hpk2bNnrzzTc1cOBAn4usM23aND3zzDMqKipS9+7d9eKLLyorK6vR8w8dOqRHH31Uc+fO1cGDB9WpUydNmTLF41oIN7CDty05kjR//nwNGjTIPwUBQIjx+/ILcXFx6tKli0/F/dw777yjvLw8jRs3TuvXr1f37t01YMAA7du3r8Hzq6qq1L9/f23fvl1z5szR5s2bNWPGDHXs2LHJtQD+VFBQINM0vQrUOTk56tu3rx+rAoDw5FPLzXPPPadt27Zp6tSpTXrTo3fv3srMzNTUqVMlSU6nUw6HQ/fee68efvjh485/+eWX9cwzz+jf//63YmNjffqetNzAbt7+m6EFxw+qqqQXXnDtjxzJ8gtACPB7t9R1112njz/+WK1bt9a55557XNCYO3fuSe9RVVWlpKQkzZkzR9dee637eG5urg4dOqQPPvjguGsGDhyo1q1bKykpSR988IHatm2rW265RQ899JCiG+kzr6ysVGVlpfvrkpISORwOwg1s5W3A2blzp9LT0/1UTQQqK5OaN3ftl5ZKTKoIBD1vwo1Pb0u1bNlS1113nU/F1dm/f79qa2uVmppa73hqaqr+/e9/N3jNtm3b9NFHH2nIkCFatGiRtm7dqrvvvlvV1dUaN25cg9dMnDhR//M//9OkWgGrmaap/v37a9myZR6d73A43NcBAE7Mp3DzxhtvWF2HR5xOp9q1a6dXX31V0dHRuuCCC7Rr1y4988wzjYabMWPGKC8vz/11XcsNYLelS5dKklJSUlRSUuLRNawyDgAn51O4qVNcXKzNmzdLks466yy1bdvW42vbtGmj6Oho7d27t97xvXv3qn379g1ek5aWptjY2HpdUF27dlVRUZGqqqoU10C/eXx8vOLj4z2uCwi0w4cPS/K8q4qAAwAn5tPbUmVlZRo2bJjS0tJ08cUX6+KLL1aHDh00fPhwlZeXe3SPuLg4XXDBBVq+fLn7mNPp1PLly9WnT58Gr+nbt6+2bt1abw6QLVu2KC0trcFgA4SSzMxMj881DENjx471YzUAELp8Cjd5eXn65JNPNH/+fB06dMg9APiTTz7R6NGjvbrPjBkzNGvWLG3atEl//OMfVVZWpttvv12SdNttt2nMmDHu8//4xz/q4MGDGjlypLZs2aKFCxdqwoQJGjFihC8/BhBU1qxZ49X548ePV/O6QbEAADefuqX+/ve/a86cObr00kvdxwYOHKjExETdeOONmj59ukf3GTx4sIqLizV27FgVFRWpR48eWrx4sXuQ8Y4dOxQVdSx/ORwOLVmyRKNGjdL555+vjh07auTIkXrooYd8+TGAoGOaprKysrR27VqPzi8rK9OgQYO0YMECP1cGAKHDp1fBk5KStG7dOnXt2rXe8e+++05ZWVkqKyuzrECrMc8NQkV+fr67FfNkWrdurQMHDvi5ojBSWyutXOna79eP5ReAEOD3eW5+/etf65RTTtGbb76phIQESdLRo0eVm5urgwcPevx6qx0INwg13syJw0BjAOHK7/PcvPDCCxowYIDS09PVvXt3ScdWNV6yZIkvtwTQCNM0eZMKALzgU8uNJJWXl+vtt992T7jXtWtXDRkyRImJiZYWaDVabhCqWrRoodLSUo/OzcnJ0bx58/xcUQirrpZefdW1f+edko/LuQAIHL93S4Uywg1CmTeDjSW6qRrF8gtAyPFLt9S8efN01VVXKTY29qS/EV5zzTWe3haAF9asWaOoqCiPQ4thGFqzZo1Xc+gAQKjzuOUmKipKRUVFateuXb3Xs4+7oWGotrbWsgKtRssNwsFNN92kd955x6trDMOoNwFmRKPlBgg5fmm5+fn/FPkfJGCv2bNn68CBA169mVg3MJmuKgDhzqcZihty6NAhq24FwAN1C296y5tXywEgFPkUbp5++ul6TeI33HCDWrdurY4dO+rrr7+2rDgAJ2aaprKzs72+zjAMtWvXzg8VAYD9fAo3L7/8shwOhyTXb4/Lli3T4sWLddVVV+mBBx6wtEAAJ7Z06VKZpul1d1NxcTGtOADCkk+T+BUVFbnDzYIFC3TjjTfqiiuuUEZGhnr37m1pgQA8582Ef3UichxOfLxUtx5XfLy9tQCwnE8tN61atdLOnTslSYsXL3Y3i5umGdRvSgGRwDRNDRs2zKtrDMNQXFycnyoKQjEx0tVXu7YYn37HAxDEfAo3v/nNb3TLLbeof//+OnDggK666ipJ0ldffaUuXbpYWiAA782cOdPrrqrq6moZhuHesrKy/FghAPiPT7+yPP/888rIyNDOnTs1adIkNf/PfBF79uzR3XffbWmBAJrGl64qSVq7dm34dllVV0tvv+3aHzKE5ReAMMPyC0CEcDgcKiws9Pn6zMxMrVmzxsKKbMQkfkDIYfkFAMfZuXOn2rVrp+LiYp+uD+uWHABhheUXgAgzefJkjR492ufrW7VqpYMHD1pYkQ1ouQFCjjef3x4PKHY6ne5Jv5xOZ6NbMAcbAFJeXp5M0/R58P9PP/0kwzBooQUQtCxbfgFAaPn+++9lmqaSkpJ8un7+/PlMAgggKPkUbv77v/9bf/nLX447PnXqVN13331NrQlAAJWVlblfG/dlwDCvjgMINj6Fm7///e/q27fvcccvvPBCzZkzp8lFAbBHZmamz11WdQOOm/JGFgBYwadwc+DAAaWkpBx3PDk5Wfv3729yUQDsVddl5UtLjsPhkGEYSktL80NlFomPl95917Wx/AIQdnwKN126dNHixYuPO/6Pf/xDp512WpOLAhAcMjMzlZub69O1RUVF7i6roGvNiYmRbrjBtbH8AhB2fPpXnZeXp3vuuUfFxcW6/PLLJUnLly/Xc889pylTplhZHwCb5efna8SIEU0aU1PXmuN0Oi2sDAAa5vMMxdOnT9eTTz6p3bt3S5IyMjL0+OOP67bbbrO0QKsxzw3gu8LCQjkcjibfp0uXLvr+++8tqMhHNTXSe++59q+7jtYbIAR48/nd5OUXiouLlZiY6F5fKtgRboCmO+WUUyybyG/NmjXKzMy05F4eYxI/IOT4ZRK/X6qpqdGyZcs0d+5c93Tsu3fvVmlpqa+3BBAiDhw44PWq443JysqSYRiaPHmyBZUBgI8tNz/++KOuvPJK7dixQ5WVldqyZYtOO+00jRw5UpWVlXr55Zf9UaslaLkB/MOqCf0yMjJUUFBgyb0aRcsNEHL83nIzcuRI9erVSz/99JMSExPdx6+77jotX77cl1sCCHF1LTmtW7du0n22b98uwzA0duxYiyoDEGl8CjcrV67UY489pri4uHrHMzIytGvXLksKAxCa6rqscnJymnSf8ePHu18lBwBv+BRuGlsgs7CwUC1atGhyUQBC37x582Saplq2bNnkexFyAHjDp3BzxRVX1JvPxjAMlZaWaty4cRo4cKBVtQEIAz/99JNlg4/rQk7Qz4AMwFY+Te7w7LPP6sorr9Q555yjiooK3XLLLfr+++/Vpk0b/e1vf7O6RgBh4ucBp6ktMXUzIPs0Z05cnPTGG8f2AYQVn+e5qamp0TvvvKOvv/5apaWl6tmzp4YMGVJvgHEw4m0pIHgMHz5cr7/+uiX3sqJlCEDw8uskftXV1Tr77LO1YMECde3atUmF2oFwAwQnK8bUEHCA8OXN57fX3VKxsbGqqKjwuTgAaEhdMImJiWnwhQVPGIbhWcCpqZGWLHHtDxjA8gtAmPFpQPGIESP09NNPq6amxup6AES4mpqaJs2X8/NBx61atWr4pMpKadAg11ZZ2YRqAQQjn35dWbt2rZYvX64PP/xQ3bp1U7NfzO45d+5cS4oDELkOHDggSTrnnHO0adMmn+5x6NAhd3cXXVZA5PAp3LRs2VK//e1vra4FAI6zcePGel/HxcWpurra6/v8fEyPyRp4QFjzKtw4nU4988wz2rJli6qqqnT55Zfr8ccfD/o3pACEj6qqKklNG4DcrHlzlVlVEICg49WYmyeffFKPPPKImjdvro4dO+ovf/mLRowY4a/aAKBRVnUzNatbQBNA2PAq3Lz55pt66aWXtGTJEr3//vuaP3++3n77bTmdTn/VBwCNsirgsLQDEF68Cjc7duyot7xCdna2DMPQ7t27LS8MADxhmqYyMjKafB8CDhA+vBpzU1NTo4SEhHrHYmNjfRrcBwBWKSgoqPf1yYJKlaQRP9v/+XW8VQWEPq/CjWmaGjp0qOLj493HKioqdNddd9V7HZxXwQHYqS6g9O/fX8uWLTvuz2skvdTItbw6DoQ+r8JNbm7uccd+97vfWVYMAFhp6dKl7v3o6GivxgcahqE33nhDQ4cO9UNlAPzJ54UzQxVrSwGINgz1+8/+SkmeRJ5hw4Zp5syZfqwKwIl48/nt0/ILABDKaktLtULSCkkJJz7V7fXXX5dhGJo8ebLf6gJgDcINAHhh9OjRMgzjuGVnAAQPwg0A+KC8vJzXx4EgRbgBENHKSkvVvXt3n68n4ADBh3ADIOJt2LBBpmnqoosu8ul6wzAIOUAQIdwAwH+sXLmySfPbGIaha665xsKKAPiCcAMAv2Capnvz1vz582UYhhITE/1QGQBPeDWJHwCEhdhYadKkY/snUBdwvO12qqioYDkHwCaEGwCRJy5OeuABry7xNeTUnd+6dWsdOHDAq2sB+IZuKQDwgq8tMQcPHmTQMRAghBsAkae2Vlq71rXV1np9uWmaysjI8Olb82YV4H+EGwCRp6JCyspybRUVPt2ioKBApmkqJyfHp+sJOYD/EG4AoAnmzZvX5NfHAViLcAMAFvD11XGJVhzAaoQbALCQaZqKi4vz6VrDMDR8+HCLKwIiD+EGACxWWVnpc0vO66+/TisO0ERBEW6mTZumjIwMJSQkqHfv3lqzZo1H182ePVuGYejaa6/1b4EA4KOmdFUB8I3t4eadd95RXl6exo0bp/Xr16t79+4aMGCA9u3bd8Lrtm/frvvvv1/9+vULUKUA4Ju6VpzBgwd7dV3dWByCDuAdw7R5bvDevXsrMzNTU6dOlSQ5nU45HA7de++9evjhhxu8pra2VhdffLGGDRumlStX6tChQ3r//fcbPLeyslKVlZXur0tKSuRwOHT48GElJydb/vMACAFVVdKECa79Rx5xzVgcQL6GFZZyQCQrKSlRSkqKR5/ftrbcVFVVad26dcrOznYfi4qKUnZ2tlavXt3odU888YTatWvn0cC7iRMnKiUlxb05HA5LagcQwuLipMcfd20BDjaSK6RcdNFFXl9X14pTWFjoh6qA8GFruNm/f79qa2uVmppa73hqaqqKiooavGbVqlWaOXOmZsyY4dH3GDNmjA4fPuzedu7c2eS6AaCpVq5c6XNLjMPhoKsKOAHbx9x448iRI7r11ls1Y8YMtWnTxqNr4uPjlZycXG8DEOGcTum771yb02lrKaZp+vxLl2EYSktLs7giIPTZuip4mzZtFB0drb1799Y7vnfvXrVv3/6483/44Qdt37693nTnzv/8jykmJkabN2/W6aef7t+iAYS+o0el885z7ZeWSs2a2VpOenq6TNP0qTWmqKjIfR1jcgAXW1tu4uLidMEFF2j58uXuY06nU8uXL1efPn2OO//ss8/WN998ow0bNri3a665Rpdddpk2bNjAeBoAIc00TXXt2tXn63mzCnCxteVGkvLy8pSbm6tevXopKytLU6ZMUVlZmW6//XZJ0m233aaOHTtq4sSJSkhI0Hl1v239R8uWLSXpuOMAEIo2btzo3vc1qNRd1717d23YsMGKsoCQYnu4GTx4sIqLizV27FgVFRWpR48eWrx4sXuQ8Y4dOxQVFVJDgwDAEqZp6pprrtH8+fN9uv7rr7+WYRh0VyHi2D7PTaB58548gDBVViY1b+7aD4IxN55oSsipE2H/u0eYCZl5bgAAnpk3bx5jcgAPEW4AIIRs3LixyS0wdSGnf//+FlUFBBfbx9wAQMDFxkr3339sPwTVBZy0tLRGJz09mWXLlskwDMXExKi6utrK8gBbEW4ARJ64OOmZZ+yuwhJ79uyRJC1YsKDeHGDeqKmpcbfmOG2e1BCwAt1SABAGBg0a5F593Fd1EwkyLgehjnADIPI4ndL27a4tDFsqTNPUyJEjm3QPQg5CGeEGQOQ5elTq3Nm1HT1qdzV+MWXKlCa/XSURchCaCDcAEMbq3q6KbeLAaUIOQgnhBgAiQFVVVZPH5EjHQg5r+SGYEW4AIMJYEXIKCwvdQSc/P9+awgCLEG4AIEJZEXIk6fbbb6fbCkGFcAMAEc6qkCO5uq3Gjh1ryb0AXxFuAACSrAs548ePpxUHtmKGYgCRJyZGuvvuY/uopy7gNDWg1F3PauQINFpuAESe+Hhp2jTXFh9vdzVBq64lx9dlHeowHgeBxq8sAIATmjdvnnu/KSGFlhwECi03ACKPaUrFxa6ND1qv1LXmPPfccz7fo64lp0WLFhZWBhxjmBEWoUtKSpSSkqLDhw8rOTnZ7nIA2KGsTGre3LVfWio1a2ZvPSGuqV1OEfYxBB958/lNyw0AoEma+pYV43FgNcINAMASpmmqdevWPl3LoGNYiXADALDMgQMHmtyKQ8hBUxFuAACWs6Kr6pRTTrGwIkQSwg0AwG+aEnIOHjxIKw58QrgBAPhdXcjxJegQcOAtJvEDEHliYqTc3GP7CCjTNL0OLEwACG/QcgMg8sTHS/n5ro3lF2xhmqaGDRvm9XWGYWjt2rV+qAjhhEn8AAC28rXbqXXr1jpw4IDF1SBYefP5TXssgMhjmlJ5uWs/KUliTIetfF2FvG7AsWEYcjqd/igNIYpuKQCRp7zctfxC8+bHQg5s5+uAY1/G8CC8EW4AAEHF19ESda04BB0QbgAAQaepw0EJOZGNcAMACEpNneVYIuREKsINACComaap+fPnN+kedSGnX79+FlWFYEa4AQAEvUGDBlnSkrNq1SpCTgQg3AAAQoqVIQfhiXADIPJER0vXX+/aoqPtrgY+Mk1TgwcPbtI9DMNQYWGhRRUhWDBDMQAgLFjREhNhH4khxZvPb1puAABhgberUIdwAwAIK3Uhx5eFOesYhqEYVowPWYQbAJGnrMy1npRhuPYRlmbOnNmk1pza2loZhqH+/ftbXBn8jXADAAh7TQk5y5Yto7sqxBBuAAARgzE5kYFwAwCIKKZpKjMzs0n3IOQEN0ZLAQAizpo1a9z7TQkpddfyCnlwoeUGABDReIU8/BBuAACQdSEH9iPcAIg80dHSwIGujeUX8AtNHZNDK479GHMDIPIkJEgLF9pdBYKYFWNyGI9jH1puAAA4gaZ2V9GSE3iEGwAAPGBVyOnXr5+FVaEhhBsAkaesTGrWzLWx/AK81NSQs2rVKlpy/IxwAyAylZe7NsBHVrTk5OfnW1cQ3Ag3AAA0QVMCzu23304rjh8QbgAAaCIGHQcXwg0AABaxKuRMnjzZwqoiD+EGAACLNTXkjB49mpacJiDcAADgJ3Uhx9egQ8DxDTMUA4g8UVHSJZcc2wcCwDRNn8LKz69htmPPEG4ARJ7ERGnFCrurQAQyTVOFhYVyOBw+XU/Q8Qy/sgAAEEDp6emWBBO6rBpHuAEAwAZNHXQs8Qp5Ywg3ACJPWZnUtq1rY/kF2Kypg44lWnF+iTE3ACLT/v12VwAcx9dBx9KxgMNYnCBpuZk2bZoyMjKUkJCg3r17a82aNY2eO2PGDPXr10+tWrVSq1atlJ2dfcLzAQAIJaZpKicnx+fracUJgnDzzjvvKC8vT+PGjdP69evVvXt3DRgwQPv27Wvw/BUrVujmm2/Wxx9/rNWrV8vhcOiKK67Qrl27Alw5AAD+MW/ePHdXVUyM950skT4WxzBtbr/q3bu3MjMzNXXqVEmS0+mUw+HQvffeq4cffvik19fW1qpVq1aaOnWqbrvttuP+vLKyUpWVle6vS0pK5HA4dPjwYSUnJ1v3gwAIHWVlUvPmrv3SUqlZM3vrATzkS2AJl26qkpISpaSkePT5bWvLTVVVldatW6fs7Gz3saioKGVnZ2v16tUe3aO8vFzV1dVq3bp1g38+ceJEpaSkuDdf5xYAAMBuvgSVulacFi1a+KGi4GRruNm/f79qa2uVmppa73hqaqqKioo8usdDDz2kDh061AtIPzdmzBgdPnzYve3cubPJdQMAYBdf36wqLS2NmO6qkH5b6qmnntLs2bO1YsUKJSQkNHhOfHy84uPjA1wZgKAWFSX16nVsHwhBTX2zKly6qxpia7hp06aNoqOjtXfv3nrH9+7dq/bt25/w2meffVZPPfWUli1bpvPPP9+fZQIIN4mJ0tq1dlcBNFldQGnKmlXhGHJs/ZUlLi5OF1xwgZYvX+4+5nQ6tXz5cvXp06fR6yZNmqTx48dr8eLF6lX32xcAABGKCQDrs71bKi8vT7m5uerVq5eysrI0ZcoUlZWV6fbbb5ck3XbbberYsaMmTpwoSXr66ac1duxY/fWvf1VGRoZ7bE7z5s3VvO7tBwAAIkxTW3HCqQXH9nAzePBgFRcXa+zYsSoqKlKPHj20ePFi9yDjHTt2KOpnfeLTp09XVVWVrr/++nr3GTdunB5//PFAlg4gVJWXS+ec49rfuFFKSrK3HsBCvo7FCaduKtvnuQk0b96TBxCmmOcGESRc5sYJmXluAACAf/ny6nioj8Mh3AAAEAF8CTihGnIINwAARIhIacUh3AAAEGHCPeAQbgAAiEDhHHBsfxUcAALOMI69Ch5C/8MGrObt3DihMh8O4QZA5ElKkr77zu4qgKDhzdw4oRBw6JYCAABeBZZg76Ii3AAAAEnevU0VzAGHcAMg8pSXS+ee69rKy+2uBgg6wd7tdDKMuQEQeUzTtaZU3T6A43gyDidYx9/QcgMAABrkSXAJxu4pwg0AAGiSYAs4hBsAANCoYOx2OhnCDQAAOKFQ654i3AAAgJMKpYDD21IAIo9hSJ06HdsHEFYINwAiT1KStH273VUAISdUXg+nWwoAAHgsFLqnCDcAAMBydgYcwg2AyHP0qJSZ6dqOHrW7GiDk2N3tdDKMuQEQeZxO6csvj+0D8Jon42/sQssNAADwSbC24BBuAACAX9jVskO4AQAAYYVwAwAAwgrhBgAA+CwYx93wthSAyNSmjd0VABHBjhmLCTcAIk+zZlJxsd1VAPATuqUAAEBYIdwAAIAmCbZxN4QbAJHn6FHp0ktdG8svAGGHMTcAIo/TKX3yybF9AGGFlhsAABBWCDcAACCsEG4AAECTNTao2I7BxoQbAABgiV8GGbveomJAMQAAsEwwvBZOuAEQmZKS7K4AgJ8QbgBEnmbNpLIyu6sA4CeMuQEAAGGFcAMAAMIK4QZA5KmokK6+2rVVVNhdDQCLMeYGQOSprZUWLTq2DyCs0HIDAADCCuEGAACEFcINAAAIK4QbAAAQVgg3AAAgrETc21J1a16UlJTYXAkA2/x8duKSEt6YAkJA3ee2J2tXRVy4OXLkiCTJ4XDYXAmAoNChg90VAPDCkSNHlJKScsJzDDMYlu8MIKfTqd27d6tFixYyDMPSe5eUlMjhcGjnzp1KTk629N44huccGDznwOA5Bw7POjD89ZxN09SRI0fUoUMHRUWdeFRNxLXcREVFKT093a/fIzk5mX84AcBzDgyec2DwnAOHZx0Y/njOJ2uxqcOAYgAAEFYINwAAIKwQbiwUHx+vcePGKT4+3u5SwhrPOTB4zoHBcw4cnnVgBMNzjrgBxQAAILzRcgMAAMIK4QYAAIQVwg0AAAgrhBsAABBWCDdemjZtmjIyMpSQkKDevXtrzZo1Jzz///7v/3T22WcrISFB3bp106JFiwJUaWjz5jnPmDFD/fr1U6tWrdSqVStlZ2ef9L8LXLz9+1xn9uzZMgxD1157rX8LDBPePudDhw5pxIgRSktLU3x8vM4880z+3+EBb5/zlClTdNZZZykxMVEOh0OjRo1SRUVFgKoNTZ9++qlycnLUoUMHGYah999//6TXrFixQj179lR8fLy6dOmi/Px8v9cpEx6bPXu2GRcXZ77++uvmd999Z/7+9783W7Zsae7du7fB8z/77DMzOjranDRpkrlx40bzscceM2NjY81vvvkmwJWHFm+f8y233GJOmzbN/Oqrr8xNmzaZQ4cONVNSUszCwsIAVx5avH3OdQoKCsyOHTua/fr1M//rv/4rMMWGMG+fc2VlpdmrVy9z4MCB5qpVq8yCggJzxYoV5oYNGwJceWjx9jm//fbbZnx8vPn222+bBQUF5pIlS8y0tDRz1KhRAa48tCxatMh89NFHzblz55qSzPfee++E52/bts1MSkoy8/LyzI0bN5ovvviiGR0dbS5evNivdRJuvJCVlWWOGDHC/XVtba3ZoUMHc+LEiQ2ef+ONN5pXX311vWO9e/c2//CHP/i1zlDn7XP+pZqaGrNFixbmrFmz/FViWPDlOdfU1JgXXnih+dprr5m5ubmEGw94+5ynT59unnbaaWZVVVWgSgwL3j7nESNGmJdffnm9Y3l5eWbfvn39Wmc48STcPPjgg+a5555b79jgwYPNAQMG+LEy06RbykNVVVVat26dsrOz3ceioqKUnZ2t1atXN3jN6tWr650vSQMGDGj0fPj2nH+pvLxc1dXVat26tb/KDHm+PucnnnhC7dq10/DhwwNRZsjz5TnPmzdPffr00YgRI5SamqrzzjtPEyZMUG1tbaDKDjm+POcLL7xQ69atc3ddbdu2TYsWLdLAgQMDUnOksOtzMOIWzvTV/v37VVtbq9TU1HrHU1NT9e9//7vBa4qKiho8v6ioyG91hjpfnvMvPfTQQ+rQocNx/6BwjC/PedWqVZo5c6Y2bNgQgArDgy/Pedu2bfroo480ZMgQLVq0SFu3btXdd9+t6upqjRs3LhBlhxxfnvMtt9yi/fv366KLLpJpmqqpqdFdd92lRx55JBAlR4zGPgdLSkp09OhRJSYm+uX70nKDsPLUU09p9uzZeu+995SQkGB3OWHjyJEjuvXWWzVjxgy1adPG7nLCmtPpVLt27fTqq6/qggsu0ODBg/Xoo4/q5Zdftru0sLJixQpNmDBBL730ktavX6+5c+dq4cKFGj9+vN2lwQK03HioTZs2io6O1t69e+sd37t3r9q3b9/gNe3bt/fqfPj2nOs8++yzeuqpp7Rs2TKdf/75/iwz5Hn7nH/44Qdt375dOTk57mNOp1OSFBMTo82bN+v000/3b9EhyJe/z2lpaYqNjVV0dLT7WNeuXVVUVKSqqirFxcX5teZQ5Mtz/tOf/qRbb71Vd9xxhySpW7duKisr05133qlHH31UUVH87m+Fxj4Hk5OT/dZqI9Fy47G4uDhdcMEFWr58ufuY0+nU8uXL1adPnwav6dOnT73zJWnp0qWNng/fnrMkTZo0SePHj9fixYvVq1evQJQa0rx9zmeffba++eYbbdiwwb1dc801uuyyy7RhwwY5HI5Alh8yfPn73LdvX23dutUdHiVpy5YtSktLI9g0wpfnXF5eflyAqQuUJksuWsa2z0G/DlcOM7Nnzzbj4+PN/Px8c+PGjeadd95ptmzZ0iwqKjJN0zRvvfVW8+GHH3af/9lnn5kxMTHms88+a27atMkcN24cr4J7wNvn/NRTT5lxcXHmnDlzzD179ri3I0eO2PUjhARvn/Mv8baUZ7x9zjt27DBbtGhh3nPPPebmzZvNBQsWmO3atTP//Oc/2/UjhARvn/O4cePMFi1amH/729/Mbdu2mR9++KF5+umnmzfeeKNdP0JIOHLkiPnVV1+ZX331lSnJnDx5svnVV1+ZP/74o2mapvnwww+bt956q/v8ulfBH3jgAXPTpk3mtGnTeBU8GL344ovmqaeeasbFxZlZWVnmP//5T/efXXLJJWZubm698999913zzDPPNOPi4sxzzz3XXLhwYYArDk3ePOdOnTqZko7bxo0bF/jCQ4y3f59/jnDjOW+f8+eff2727t3bjI+PN0877TTzySefNGtqagJcdejx5jlXV1ebjz/+uHn66aebCQkJpsPhMO+++27zp59+CnzhIeTjjz9u8P+3dc82NzfXvOSSS467pkePHmZcXJx52mmnmW+88Ybf6zRMk/Y3AAAQPhhzAwAAwgrhBgAAhBXCDQAACCuEGwAAEFYINwAAIKwQbgAAQFgh3AAAgLBCuAEAAGGFcAMAkgzD0Pvvvy9J2r59uwzD0IYNG2ytCYBvCDcAbDd06FAZhiHDMBQbG6vOnTvrwQcfVEVFhd2lAQhBMXYXAACSdOWVV+qNN95QdXW11q1bp9zcXBmGoaefftru0gCEGFpuAASF+Ph4tW/fXg6HQ9dee62ys7O1dOlSSZLT6dTEiRPVuXNnJSYmqnv37pozZ06967/77jsNGjRIycnJatGihfr166cffvhBkrR27Vr1799fbdq0UUpKii655BKtX78+4D8jgMAg3AAIOt9++60+//xzxcXFSZImTpyoN998Uy+//LK+++47jRo1Sr/73e/0ySefSJJ27dqliy++WPHx8froo4+0bt06DRs2TDU1NZKkI0eOKDc3V6tWrdI///lPnXHGGRo4cKCOHDli288IwH/olgIQFBYsWKDmzZurpqZGlZWVioqK0tSpU1VZWakJEyZo2bJl6tOnjyTptNNO06pVq/TKK6/okksu0bRp05SSkqLZs2crNjZWknTmmWe673355ZfX+16vvvqqWrZsqU8++USDBg0K3A8JICAINwCCwmWXXabp06errKxMzz//vGJiYvTb3/5W3333ncrLy9W/f/9651dVVelXv/qVJGnDhg3q16+fO9j80t69e/XYY49pxYoV2rdvn2pra1VeXq4dO3b4/ecCEHiEGwBBoVmzZurSpYsk6fXXX1f37t01c+ZMnXfeeZKkhQsXqmPHjvWuiY+PlyQlJiae8N65ubk6cOCAXnjhBXXq1Enx8fHq06ePqqqq/PCTALAb4QZA0ImKitIjjzyivLw8bdmyRfHx8dqxY4cuueSSBs8///zzNWvWLFVXVzfYevPZZ5/ppZde0sCBAyVJO3fu1P79+/36MwCwDwOKAQSlG264QdHR0XrllVd0//33a9SoUZo1a5Z++OEHrV+/Xi+++KJmzZolSbrnnntUUlKim266SV9++aW+//57vfXWW9q8ebMk6YwzztBbb72lTZs26YsvvtCQIUNO2toDIHTRcgMgKMXExOiee+7RpEmTVFBQoLZt22rixInatm2bWrZsqZ49e+qRRx6RJJ1yyin66KOP9MADD+iSSy5RdHS0evToob59+0qSZs6cqTvvvFM9e/aUw+HQhAkTdP/999v54wHwI8M0TdPuIgAAAKxCtxQAAAgrhBsAABBWCDcAACCsEG4AAEBYIdwAAICwQrgBAABhhXADAADCCuEGAACEFcINAAAIK4QbAAAQVgg3AAAgrPx/58PsfinPUgQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.7697836756706238 with F-Score 0.49163636363636365 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "8a3090403cd94960b03b01f7d7309521",
            "ed3250ecf4c149388e6ea71cc716a5b3",
            "3bfb44b1335c40669f44d2b59982bd7d",
            "789508369f374336aa7816cbe1311c16",
            "e51a25f24f9a4b7e83233d0b4e5598f4",
            "1b0643a1b29c43978dc5daa606c91a57",
            "0583a41199544770b071217c51db4d3b",
            "8d47b4dbae5343a4986399efc2110184"
          ]
        },
        "outputId": "d59f7af7-7c69-41a7-b426-027751c59278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 90.23481083274166 %\n",
            "Final Test Precision: 46.24844720496895 %\n",
            "Final Test Recall: 52.451394759087066 %\n",
            "Final Test F1 Score: 49.15500396091893 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a3090403cd94960b03b01f7d7309521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Train F1</td><td>▁▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▃▃▄▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>Val Acc</td><td>▁▃▁▁▃▄█▃█▆▆▆▇▃▅▅▆▇▆▇</td></tr><tr><td>Val F1</td><td>▁▂▁▁▂▄█▂█▆▅▅▆▂▅▅▅▆▆▇</td></tr><tr><td>Val Loss</td><td>▇▆██▆▅▁█▁▃▄▄▃█▅▅▄▃▃▃</td></tr><tr><td>Val Precision</td><td>▁▂▁▁▂▃█▂█▆▅▅▆▂▄▅▅▆▆▇</td></tr><tr><td>Val Recall</td><td>▇▆██▇▆▁█▂▅▅▅▄█▆▆▆▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.38158</td></tr><tr><td>Train F1</td><td>0.22149</td></tr><tr><td>Train Loss</td><td>1.50772</td></tr><tr><td>Train Precision</td><td>0.12487</td></tr><tr><td>Val Acc</td><td>0.6179</td></tr><tr><td>Val F1</td><td>0.30767</td></tr><tr><td>Val Loss</td><td>691.52587</td></tr><tr><td>Val Precision</td><td>0.18376</td></tr><tr><td>Val Recall</td><td>0.94482</td></tr><tr><td>test_accuracy</td><td>0.90235</td></tr><tr><td>test_f1_score</td><td>0.49155</td></tr><tr><td>test_precision</td><td>0.46248</td></tr><tr><td>test_recall</td><td>0.52451</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">custom BCE weighted loss function Balanced Class Weights</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/vxpf2ow0' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/vxpf2ow0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240107_064314-vxpf2ow0/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "# test_f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import roc_curve, plot_roc_curve,\n"
      ],
      "metadata": {
        "id": "ZT0UR8kxTws1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "\n",
        "    # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "    CM = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch in rest_notacc_loader:  # tqdm()\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "        outputs = model(samples)\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "\n",
        "        total_predictions += len(outputs)\n",
        "\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Computer accuracy, precision, recall, and f1 metrics\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # f1_score = f1_score(total_outputs.flatten(), total_labels.flatten(), task=\"binary\", num_classes=2).item()\n",
        "    print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "    print(f\"Rest not Precision: {precision * 100} %\")\n",
        "    print(f\"Rest not Recall: {recall * 100} %\")\n",
        "    print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "\n",
        "    # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "7260ed7e-1df8-43f0-9684-99552c1f0295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/custom BCE weighted loss function Balanced Class Weights01-07-07-03-19-Sequential-model-0.0001lr-20epochs.pt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'kernel_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-b889e9ec794f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_save_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mCNNModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_CNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"model saved at {datetime_str}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CNNModel.py\u001b[0m in \u001b[0;36msave_CNNModel\u001b[0;34m(model_save_path, model)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_CNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     checkpoint = {\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;34m\"kernel_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"embed_dim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"num_filters1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_filters1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'kernel_size'"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "CNNModel.save_CNNModel(model_save_path, model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8daa35c-bdd4-4a31-c467-46ae597e655c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c25fbe-4b3a-42bd-f2e0-59c3ca38aeb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "      outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "print(\"Predicted\", len(np_probs[np_probs>0.5]), \"true values out of \", len(np_probs), \" total\")\n",
        "not_probs = np_probs[np_probs<=0.5]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.5]\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "f83fa5bd-a17a-4a81-ac5a-505d3eec5afb"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 106817 true values out of  269315  total\n",
            "\n",
            "not accessible probs [1.55029923e-07 7.14487896e-07 1.07927224e-06 ... 4.99995589e-01\n",
            " 4.99997377e-01 4.99998808e-01]\n",
            "accessible probs [0.99861193 0.99704295 0.99652404 ... 0.50001699 0.50001192 0.50000554]\n",
            "\n",
            "first 10\n",
            " ([0.9986119270324707], [0.9970429539680481], [0.9965240359306335], [0.9961392283439636], [0.9950131773948669], [0.9945319890975952], [0.9940463304519653], [0.9935500621795654], [0.9934105277061462], [0.9933835864067078])\n",
            "last 10 of top 10000\n",
            " ([0.8839777708053589], [0.8839734196662903], [0.883966863155365], [0.8839585781097412], [0.8839547038078308], [0.8839465975761414], [0.8839383721351624], [0.883936882019043], [0.883929431438446], [0.8839290738105774])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "91b06c6b-a5db-449c-cf1b-fc765c8328e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "bc3bfdcc-292a-452f-f8fd-c18578010b2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1679aa5d-30d6-42a3-b8d7-810fcda54231\", \"Balanced Class Weights01-07-03-48-53-CNNModel-model-0.0001lr-20epochs.pt\", 1758403)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "529323d2-8ad7-4818-f41c-f359476681b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b154f938-ba3d-479d-aa5e-d4a766dab61a\", \"predictions.zip\", 33556)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a3090403cd94960b03b01f7d7309521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed3250ecf4c149388e6ea71cc716a5b3",
              "IPY_MODEL_3bfb44b1335c40669f44d2b59982bd7d"
            ],
            "layout": "IPY_MODEL_789508369f374336aa7816cbe1311c16"
          }
        },
        "ed3250ecf4c149388e6ea71cc716a5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e51a25f24f9a4b7e83233d0b4e5598f4",
            "placeholder": "​",
            "style": "IPY_MODEL_1b0643a1b29c43978dc5daa606c91a57",
            "value": "0.016 MB of 0.016 MB uploaded\r"
          }
        },
        "3bfb44b1335c40669f44d2b59982bd7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0583a41199544770b071217c51db4d3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d47b4dbae5343a4986399efc2110184",
            "value": 1
          }
        },
        "789508369f374336aa7816cbe1311c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51a25f24f9a4b7e83233d0b4e5598f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0643a1b29c43978dc5daa606c91a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0583a41199544770b071217c51db4d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d47b4dbae5343a4986399efc2110184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}