{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeFFJzVy9Rm3"
      },
      "outputs": [],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foXB0nMJ9Rm4"
      },
      "outputs": [],
      "source": [
        "import dna_dataset, constants, utils, CNNModel, LSTMCNNModel\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os\n",
        "from datetime import datetime\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(constants)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "importlib.reload(LSTMCNNModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oJn5c8qK-APD"
      },
      "outputs": [],
      "source": [
        "# !mkdir Files\n",
        "# !mv reduced_nonaccessible.fasta Files\n",
        "# !mv accessible.fasta Files\n",
        "# !mv test.fasta Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFk_Lek79Rm5"
      },
      "source": [
        "Unzip the datafile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "!unzip $constants.DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wApXJhry9Rm6"
      },
      "outputs": [],
      "source": [
        "full_dataset = dna_dataset.DNADataset(constants.ACCESSIBLE_FILE, constants.NOT_ACCESSIBLE_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrCkS5X19Rm6"
      },
      "outputs": [],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', len(full_dataset.sequences))\n",
        "print('num accessible', full_dataset.accessible_count)\n",
        "print('num not accessible', full_dataset.not_accessible_count)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = full_dataset[i]\n",
        "print(\"label\", item['labels'])\n",
        "# print(item['sequences'])\n",
        "\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(full_dataset.accessible_count):\n",
        "    if full_dataset[i]['labels'] != constants.ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX76lE8Y9Rm7"
      },
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "full_size = len(full_dataset)\n",
        "temp_size = round(constants.VALIDATION_SPLIT * 2 * full_size)  # * 2 for both validation and test split\n",
        "train_size = full_size - temp_size\n",
        "\n",
        "train_dataset, temp_dataset = torch.utils.data.random_split(full_dataset, [train_size, temp_size])\n",
        "\n",
        "val_size = temp_size // 2\n",
        "test_size = temp_size - val_size\n",
        "assert(val_size + test_size == temp_size)\n",
        "\n",
        "val_dataset, test_dataset = torch.utils.data.random_split(temp_dataset, [val_size, test_size])\n",
        "\n",
        "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "assert(len(train_dataset) + len(val_dataset) + len(test_dataset) == full_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "importlib.reload(CNNModel)\n",
        "importlib.reload(LSTMCNNModel)\n",
        "torch.manual_seed(0)\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "model = CNNModel.CNNModel(kernel_size=2,\n",
        "                           embed_dim=4,\n",
        "                           num_filters1=128,\n",
        "                           num_filters2=64,\n",
        "                           pool_kernel_size=2,\n",
        "                           hidden_dense1=128,\n",
        "                           hidden_dense2=64,\n",
        "                           dropout_rate_Dense=0.5\n",
        "                           )\n",
        "\n",
        "# model = LSTMCNNModel.LSTMCNNModel(\n",
        "#                             kernel_size=2,\n",
        "#                             embed_dim=4,\n",
        "#                             num_filters1=128,\n",
        "#                             num_filters2=64,\n",
        "#                             pool_kernel_size=2,\n",
        "#                             hidden_dense1=128,\n",
        "#                             hidden_dense2=64,\n",
        "#                             dropout_rate_Dense=0.5,\n",
        "#                             lstm_units=1\n",
        "# )\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = .0001\n",
        "# n_eval = constants.N_EVAL\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # weight_decay=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "XsGb6Nm49Rm8"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, # shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "\n",
        "    note = f\"{learning_rate}lr-{batch_size}batch_size\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}colab_run2_balanced_data\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader):  # show the times for each batch\n",
        "        # Forward propagate\n",
        "        samples, labels = batch[\"sequences\"].to(device), batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(samples)\n",
        "        labels = labels.reshape(-1,1).float()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = torch.round(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        # Compute validation loss and accuracy.\n",
        "        # accuracy = utils.compute_accuracy(outputs, labels)  # only does current batch\n",
        "        val_loss, val_acc = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataset)\n",
        "        epoch_acc = running_corrects / len(train_dataset)\n",
        "        print(f\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # # deep copy the model\n",
        "        # if val_accuracy > best_acc:\n",
        "        #     best_acc = epoch_acc\n",
        "        #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        if USING_WANDB:\n",
        "            wandb.log({\"Train Loss\": epoch_loss,\n",
        "                        \"Train Acc\": epoch_acc,\n",
        "                        \"Val Loss\": val_loss,\n",
        "                        \"Val Acc\": val_acc,\n",
        "                        \"Epoch\": epoch\n",
        "            })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMFy_P4E9Rm9"
      },
      "outputs": [],
      "source": [
        "# INFERENCE\n",
        "\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in tqdm(test_loader):\n",
        "    test_samples, test_labels = batch['sequences'].to(device), batch['labels'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "    # print(torch.round(val_outputs))\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_correct += (torch.round(test_outputs) == test_labels).sum().item()\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "model.train()\n",
        "test_accuracy = total_correct / total_predictions\n",
        "print(f\"Final Test Accuracy: {test_accuracy * 100} %\")\n",
        "\n",
        "wandb.summary['test_accuracy'] = test_accuracy\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMXK8qqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(constants.PRETRAINED_DIR):\n",
        "    os.mkdir(constants.PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    constants.PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "CNNModel.save_CNNModel(model_save_path, model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"/content/pretrained/12-10-05-30-17-CNNModel-model-10-epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Test File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apmvzG7E9Rm9"
      },
      "outputs": [],
      "source": [
        "competition_dataset = dna_dataset.TestDataset(constants.TEST_FILE) # TODO\n",
        "competition_loader = torch.utils.data.DataLoader(\n",
        "    competition_dataset, batch_size=batch_size, # shuffle=True\n",
        ")\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qT3UBun9Rm9"
      },
      "outputs": [],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "for batch in tqdm(competition_loader):\n",
        "\n",
        "    samples, ids = batch[\"sequences\"].to(device), batch['ids'] # not a tensor\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd2EaK1Z9Rm9",
        "outputId": "fdf60a39-1eeb-463a-cfa4-e502071b5485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61838 true values out of  269315  total\n",
            "[2.82697332e-09 4.94747887e-09 8.38561309e-09 ... 5.00000000e-01\n",
            " 5.00000000e-01 5.00000000e-01]\n",
            "[0.99988699 0.99984121 0.99983728 ... 0.50001532 0.5000146  0.50001037]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "print(len(np_probs[np_probs>0.5]), \"true values out of \", len(np_probs), \" total\")  # assumes exactly 1\n",
        "not_zero = np_probs[np_probs<=0.5]\n",
        "not_zero.sort()\n",
        "not_one = np_probs[np_probs>0.5]\n",
        "not_one[::-1].sort()\n",
        "print(not_zero)\n",
        "print(not_one)\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG7R8WVS9Rm9",
        "outputId": "b2898d2c-f1b8-4b05-c74b-438fadab95c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first 10\n",
            " ([0.9998869895935059], [0.9998412132263184], [0.9998372793197632], [0.9997877478599548], [0.9997790455818176], [0.9997734427452087], [0.999725878238678], [0.9996953010559082], [0.9996765851974487], [0.9996603727340698])\n",
            "last 10\n",
            " ([0.9155594110488892], [0.9155588150024414], [0.9155481457710266], [0.9155474901199341], [0.9155178666114807], [0.9155153632164001], [0.9155153632164001], [0.9155087471008301], [0.9155052304267883], [0.915500283241272])\n"
          ]
        }
      ],
      "source": [
        "probs.sort(reverse=True)\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000\n",
        "\n",
        "with open(constants.SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10\\n\", list(zip(*probs[9990:10000]))[0])  # probs only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "a9f4ac2e-5070-4a8f-8d1a-c441f995c085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $constants.SOLUTION_FILE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "c0aed455-b2f4-45ee-bdb3-951c28840f1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3b2724d-3383-46bc-8682-8adac702d515\", \"0.0001lr-64batch_size12-12-02-19-27-CNNModel-model-0.0001lr-20epochs.pt\", 1751728)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "dir = 'pretrained'\n",
        "model_file = os.path.join(dir, os.listdir(dir)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "af19813d-03d4-4503-ee82-c5570da44c85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b50dd548-ba98-47e0-9ca2-4028f9483728\", \"predictions.zip\", 33497)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cZo5-r0JUaY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}