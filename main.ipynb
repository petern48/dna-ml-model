{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install scikit-learn\n",
        "# !pip install torch\n",
        "!pip install wandb &> /dev/null\n",
        "# No longer in used: !pip install gensim &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeVDVIETZoB8"
      },
      "source": [
        "You may set `USING_WANDB` to True if you have a Weights and Bias Account and want to log metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "XeFFJzVy9Rm3",
        "outputId": "c50cad3a-7753-473e-cb01-bfdfe23586bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "# For logging metrics to Weights and Biases Platform.\n",
        "USING_WANDB = False  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4w8yS3yZoB9"
      },
      "source": [
        "I was developing from Colab, using the convenience of loading files straight from drives. This code has been commented out for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTxLO6GibEAN"
      },
      "outputs": [],
      "source": [
        "# This was for developing in Colab. It was\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "outputs": [],
      "source": [
        "data_folder = \"Files\"\n",
        "# data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"  # for loading straight from Colab\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test percentage\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\"\n",
        "UPSAMPLE = 1\n",
        "DOWNSAMPLE = -1\n",
        "NORMAL = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foXB0nMJ9Rm4"
      },
      "outputs": [],
      "source": [
        "import dna_dataset, utils, CNNModel, HybridModel\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from torchvision.ops import sigmoid_focal_loss\n",
        "# from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, random\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# For development, this updates the import after uploading a new version in Colab\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "importlib.reload(HybridModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TqvTd3Ano27X"
      },
      "outputs": [],
      "source": [
        "# Credit: https://github.com/sberbank-ai/ru-dalle/blob/e96631a867fcadcfaa52eecb20b1e42b88aa4386/rudalle/utils.py\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "SEED = 1\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru2XMdhrZoB_"
      },
      "source": [
        "Set `USING_HYBRID` to True to try using the Hybrid Model.  \n",
        "Note: It takes longer to load the data. I achieved decent results with the hybrid model, but the CNN model was still better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5ywsKACdzurF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef6832a-c984-4195-9897-ba79eff8f61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n"
          ]
        }
      ],
      "source": [
        "USING_HYBRID = False  # one hot and kmers concatenated\n",
        "hybrid_k = 5  # kmer size\n",
        "if not USING_HYBRID:\n",
        "  hybrid_k = -1  # for not hybrid model\n",
        "  print(hybrid_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gxjgFVQv9Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca5f80a-6224-44a3-824d-628843f743e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Files.zip\n",
            "  inflating: Files/accessible.fasta  \n",
            "  inflating: Files/notaccessible.fasta  \n",
            "  inflating: Files/test.fasta        \n"
          ]
        }
      ],
      "source": [
        "# Unzip the zip file\n",
        "!unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JPjFJP1xwLgS"
      },
      "outputs": [],
      "source": [
        "# Read the data from data files\n",
        "# Hybrid data\n",
        "if USING_HYBRID:\n",
        "    pass  # read from .pt files instead\n",
        "    # acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, hybrid_k=hybrid_k, shuffle=True)\n",
        "    # not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, hybrid_k=hybrid_k, shuffle=True)\n",
        "    # reduced_notaccessible_file\n",
        "else:\n",
        "    acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "    not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxvAVcHM9RUI"
      },
      "outputs": [],
      "source": [
        "# During development, this was used because out of memory issues for the hybrid\n",
        "# model with k=6\n",
        "\n",
        "# # Check how much storage each variable takes\n",
        "# import sys\n",
        "# def sizeof_fmt(num, suffix='B'):\n",
        "#     ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
        "#     for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "#         if abs(num) < 1024.0:\n",
        "#             return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "#         num /= 1024.0\n",
        "#     return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
        "# for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
        "#                           locals().items())), key= lambda x: -x[1])[:10]:\n",
        "#     print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YtfXGjW86xbU"
      },
      "outputs": [],
      "source": [
        "# Originally used to save the hybrid data tensors to files\n",
        "acc_seq_file = os.path.join(data_folder, f\"{hybrid_k}k-acc_sequences.pt\")\n",
        "acc_lab_file = os.path.join(data_folder, f\"{hybrid_k}k-acc_labels.pt\")\n",
        "not_seq_file = os.path.join(data_folder, f\"{hybrid_k}k-not_sequences.pt\")\n",
        "not_lab_file = os.path.join(data_folder, f\"{hybrid_k}k-not_labels.pt\")\n",
        "# not_seq_file = os.path.join(data_folder, \"balanced_not_sequences.pt\")\n",
        "# not_lab_file = os.path.join(data_folder, \"balanced_not_labels.pt\")\n",
        "# reduced_seq_file = os.path.join(data_folder, \"reduced_not_sequences.pt\")\n",
        "# reduced_lab_file = os.path.join(data_folder, \"reduced_not_labels.pt\")\n",
        "\n",
        "# Directly save the tensors for faster future loading (takes lots of space)\n",
        "# torch.save(acc_sequences, acc_seq_file)  # acc\n",
        "# torch.save(acc_labels, acc_lab_file)\n",
        "# torch.save(not_sequences, not_seq_file)  # not\n",
        "# torch.save(not_labels, not_lab_file)\n",
        "# torch.save(not_sequences, reduced_seq_file)  # reduced\n",
        "# torch.save(not_labels, reduced_lab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-87tFUPd7ix0",
        "outputId": "c3eb22b3-a31c-4f7d-ed6a-0617495ed87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 200])\n"
          ]
        }
      ],
      "source": [
        "# Load data tensors directly from files\n",
        "# acc_sequences = torch.load(acc_seq_file)\n",
        "# acc_labels = torch.load(acc_lab_file)\n",
        "# not_sequences = torch.load(not_seq_file)\n",
        "# not_labels = torch.load(not_lab_file)\n",
        "# print(not_seq_file)\n",
        "# not_sequences = torch.load(not_seq_file)\n",
        "# not_labels = torch.load(not_lab_file)\n",
        "# print(len(not_sequences))\n",
        "assert(len(not_sequences) == len(not_labels))\n",
        "assert(len(acc_sequences) == len(acc_labels))\n",
        "print(not_sequences[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjuyUZcZoB_"
      },
      "source": [
        "For CNNModel (non-hybrid), the input shape should be (4,200)  \n",
        "For HybridModel, the input shape should be (4, 200 + 4**k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI1DI3jPj_Ze",
        "outputId": "bb3888ac-9d05-4bc3-b246-42c0e4000199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "acc_sequences[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXU-lDrkZoCA"
      },
      "source": [
        "Split the data into Train / Validation / Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zU84Mb84jze",
        "outputId": "96196efb-ecdb-41e1-8a48-0f1ab527efba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ],
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=SEED)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=SEED)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=SEED)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80TrCZetX20E"
      },
      "source": [
        "(Optional): Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)\n",
        "\n",
        "This is something I experimented with but found better results using weighted loss with the full dataset instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6L73jcLX2Fe",
        "outputId": "8e605f9e-96d3-4a85-a5cd-cda663bc73fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ],
      "source": [
        "SAMPLING = NORMAL  # UPSAMPLE or DOWNSAMPLE or NORMAL\n",
        "\n",
        "if SAMPLING == UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "# downsample the majority\n",
        "if SAMPLING == DOWNSAMPLE:\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "    # Consider using the rest of data in test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    # consider upweighting for calibration\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVmtEjhyh3F1",
        "outputId": "090b7d90-4466-4743-aa85-4b9469cd1b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ],
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "# if SAMPLING == DOWNSAMPLE:\n",
        "#     rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "#     print(\"rest not samples\", len(rest_notacc_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "7ec35807-2021-44e7-ef2d-7375f1a00a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n",
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "properly shuffled\n"
          ]
        }
      ],
      "source": [
        "# Check things are the right size and that the dataset is loaded properly\n",
        "if SAMPLING == DOWNSAMPLE:\n",
        "    print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "    assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif SAMPLING == UPSAMPLE:\n",
        "    pass\n",
        "else:\n",
        "    print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "    assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "\n",
        "# Ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('properly shuffled')\n",
        "        break\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7SLRPi59Rm7",
        "outputId": "bd4160e4-1758-4ddf-a539-8bf21a522395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (Convs): ModuleList(\n",
              "    (0): Conv1d(4, 200, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): Conv1d(200, 300, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (2-3): 2 x Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=3600, out_features=256, bias=True)\n",
              "    (1): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
              "  (dropout_Conv): Dropout(p=0.2, inplace=False)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)  # in case we uploaded new version of files\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "importlib.reload(HybridModel)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "kernel_size = 3     # kernel_size should preferably be odd\n",
        "embed_dim = 4\n",
        "conv_filters = [200,300,300,300] #[64, 128, 256, 384, 448]  # [64, 128]\n",
        "pool_kernel_size = 2  # 2\n",
        "linear_neurons = [256]  #[64,32]\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# For HybridModel\n",
        "cnn_out_size=128\n",
        "ffn_out_size=16\n",
        "\n",
        "if USING_HYBRID:\n",
        "    base_model = HybridModel.HybridModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                            linear_neurons, dropout_rate_Dense, cnn_out_size, ffn_out_size, k=hybrid_k)\n",
        "    total_hidden = sum(conv_filters) + sum(linear_neurons) - (4 + 1)\n",
        "    print(f\"{total_hidden} total hidden in CNNModel\")\n",
        "else:\n",
        "    base_model = CNNModel.CNNModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                            linear_neurons, dropout_rate_Dense)\n",
        "\n",
        "base_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fbL8N68ZoCB"
      },
      "source": [
        "Weight Loss. Set to None to use unweighted loss.  \n",
        "\n",
        "I experimented with multiple different loss functions and weighting schemes (from online). It turns out the weighing schemes were basically equivalent and the regular BCELoss worked best compared to other loss functions such as sigmoid_focal_loss, and a soft f1_loss. BCEWithLogitsLoss was used instead of BCELoss because it has a more convenient way to do class weighting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nV9SwXn009g",
        "outputId": "7cb732f6-5738-47a1-90fc-99fea2fb9478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor([10.1283], device='cuda:0')\n",
            "weight for class 0 tensor([2.1975], device='cuda:0')\n",
            "weight for class 1 tensor([22.2567], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Loss Function and weight\n",
        "# All weights were the same\n",
        "# WEIGHTED_LOSS = None\n",
        "WEIGHTED_LOSS = \"sklearn type weight\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "# WEIGHTED_LOSS = \"sigmoid_focal_loss\"  # not weighted, but I felt too lazy to change the name of the var\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":  # same results as sklearn type weight\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":  # same results as sklearn type weight\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weight_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weight_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "if WEIGHTED_LOSS == \"sigmoid_focal_loss\":\n",
        "    loss_fn = sigmoid_focal_loss\n",
        "\n",
        "elif WEIGHTED_LOSS != None:\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy  # custom function\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    # loss_fn = utils.f1_loss\n",
        "    # loss_fn = utils.macro_double_soft_f1\n",
        "\n",
        "# if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "# The Models don't use sigmoid by default (so they were with BCEWithLogitsLoss)\n",
        "if loss_fn.__class__.__name__ != \"BCEWithLogitsLoss\":\n",
        "    model = nn.Sequential(base_model, nn.Sigmoid())\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = base_model\n",
        "model.to(device);  # quiet model output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5SzzDWI9dfGe"
      },
      "outputs": [],
      "source": [
        "epochs = 6\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "weight_decay = .01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "# Not sure if this was needed, but this was for making the results deterministic\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(SEED)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJwMVxMXCh23",
        "outputId": "5af9dc25-36d6-4e56-948b-23ce3df9ab96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200, 300, 300, 300]-conv-lin-[256]-CNNModel\n"
          ]
        }
      ],
      "source": [
        "# Note for development to keep track of models\n",
        "if model.__class__.__name__ == \"HybridModel\":\n",
        "    note = f\"{conv_filters}-conv-{linear_neurons}-{cnn_out_size}-{ffn_out_size}lin-{model.__class__.__name__}\"\n",
        "else:\n",
        "    note = f\"{conv_filters}-conv-lin-{linear_neurons}-{model.__class__.__name__}\"\n",
        "print(note)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2-tfMvuZoCB"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"weight decay\": weight_decay,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        if loss_fn.__class__.__name__ == \"function\" and loss_fn.__name__ == \"weighted_binary_cross_entropy\":\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels) #, reduction=\"mean\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # Compute validation metrics\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1, val_pr_auc = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}\n",
        "          PR auc: {val_pr_auc:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                    # \"Val ROC AUC\": val_roc_auc\n",
        "                    \"Val PR AUC\": val_pr_auc\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q5FF0pqhpXy",
        "outputId": "d5fd9bcd-a726-45a2-9fdc-cecd40557b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.8364567160606384 with F-Score 0.6172942237015464 for test dataset\n"
          ]
        }
      ],
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "total_labels = np.empty(0)  # don't need to have same order\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = model(samples, use_sigmoid=True)\n",
        "    else:\n",
        "        outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "    total_labels = np.concatenate((total_labels, labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9QwCBzHZoCC"
      },
      "outputs": [],
      "source": [
        "# Code for plotting the precision recall curve and optimal threshold it interested\n",
        "# plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# plt.xlabel('Recall')\n",
        "# plt.ylabel('Precision')\n",
        "# plt.legend()\n",
        "\n",
        "# Plot the best threshold\n",
        "# plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "# plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TfGw4CB9GcYy"
      },
      "outputs": [],
      "source": [
        "# Plot for AUC RUC if interested\n",
        "# fpr, tpr, roc_thresholds = metrics.roc_curve(total_labels, total_probs)\n",
        "# roc_auc = metrics.auc(fpr, tpr)\n",
        "# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
        "# display.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFRau3yRZoCC"
      },
      "source": [
        "Evaluate on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMFy_P4E9Rm9",
        "outputId": "06fdca6a-c9a4-4d2e-f453-23969251c364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.8364567160606384\n",
            "Final Test Accuracy: 92.98610406734963 %\n",
            "Final Test Precision: 60.65886196569562 %\n",
            "Final Test Recall: 62.778247393632014 %\n",
            "Final Test F1 Score: 61.70036001107727 %\n",
            "Final roc_auc: 79.39069151633043 %\n",
            "Final pr_auc: 41.44753610437754 %\n"
          ]
        }
      ],
      "source": [
        "CM = 0  # confusion matrix\n",
        "total_probs = np.empty(0)\n",
        "total_labels = np.empty(0)\n",
        "\n",
        "model.eval()\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        test_outputs = model(test_samples, use_sigmoid=True)\n",
        "    else:\n",
        "        test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, test_outputs.flatten().cpu().detach().numpy()))\n",
        "    total_labels = np.concatenate((total_labels, test_labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "fpr, tpr, roc_thresholds = metrics.roc_curve(total_labels, total_probs)\n",
        "pr_auc = average_precision_score(total_labels, total_probs)\n",
        "# auc_score = metrics.roc_auc_score(total_labels, total_probs)  # both the same\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "print(f\"Final roc_auc: {roc_auc * 100} %\")\n",
        "print(f\"Final pr_auc: {pr_auc * 100} %\")\n",
        "# display.plot()\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "    wandb.summary['roc_auc'] = roc_auc\n",
        "    wandb.summary['pr_auc'] = pr_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-Fmre3LGkmH"
      },
      "outputs": [],
      "source": [
        "wandb.finish()  # end wandb run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMXK8qqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "if model.__class__.__name__ == \"CNNModel\":\n",
        "    CNNModel.save_CNNModel(model_save_path, base_model)  # model without the added sigmoid\n",
        "elif model.__class__.__name__ == \"HybridModel\":\n",
        "    HybridModel.save_HybridModel(model_save_path, base_model)\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Set model_save_path to the path of the model's .pt file\n",
        "# ALSO set the using HYBRID correctly for the corresponding model\n",
        "model_save_path = \"\"\n",
        "if USING_HYBRID:\n",
        "    model = HybridModel.load_HybridModel(model_save_path)\n",
        "else:\n",
        "    model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apmvzG7E9Rm9"
      },
      "outputs": [],
      "source": [
        "# Load Competitation Data\n",
        "if USING_HYBRID:\n",
        "    pass\n",
        "    comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, hybrid_k=hybrid_k, shuffle=False)\n",
        "else:\n",
        "    comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evkKWnCGP_VP"
      },
      "outputs": [],
      "source": [
        "# For development to save and load up data faster\n",
        "\n",
        "# Load tensors directly from data files\n",
        "# comp_seq_file = os.path.join(data_folder, f\"{hybrid_k}k-comp_sequences.pt\")\n",
        "# comp_id_file = os.path.join(data_folder, f\"{hybrid_k}k-comp_ids.pt\")\n",
        "\n",
        "# Save tensors directly to a file\n",
        "# torch.save(comp_sequences, comp_seq_file)\n",
        "# torch.save(comp_ids, comp_id_file)\n",
        "\n",
        "# Load directly from tensor\n",
        "# comp_sequences = torch.load(comp_seq_file)\n",
        "# comp_ids = torch.load(comp_id_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4UDNvg_hI01"
      },
      "outputs": [],
      "source": [
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3EgUWe95dJH"
      },
      "outputs": [],
      "source": [
        "# loss_fn = nn.BCEWithLogitsLoss()  # For using the proper if statement below in case model was just loaded in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qT3UBun9Rm9",
        "outputId": "9ed47d88-da38-4d19-afc0-d4007161d430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of (probability, id)\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = model(samples, use_sigmoid=True)\n",
        "    else:\n",
        "        outputs = model(samples)\n",
        "\n",
        "    # ensure all probs are [0,1]  (sigmoid was used)\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        print(outputs[outputs>1][0])\n",
        "        print(outputs[outputs<0][0])\n",
        "        raise\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VRLcNR55uRt"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    threshold = best_threshold\n",
        "# incase model was not just trained\n",
        "except:\n",
        "    threshold = 0.8  # maybe slightly inaccurate\n",
        "print(f\"using threshold {best_threshold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "95973ff0-7bd5-4d90-d761-e7c17228892a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted 33358 true values out of  269315  total 12.386239162319217 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [1.26218425e-18 5.25878006e-18 7.18765358e-18 ... 6.80541396e-01\n",
            " 6.80581212e-01 6.80588722e-01]\n",
            "accessible probs [1.         1.         1.         ... 0.68066913 0.68066883 0.68064821]\n",
            "\n",
            "first 10\n",
            " ([1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0])\n",
            "last 10 of top 10000\n",
            " ([0.9781096577644348], [0.9780938029289246], [0.9780675768852234], [0.9780647158622742], [0.9780580401420593], [0.9780543446540833], [0.9780460596084595], [0.9780424237251282], [0.9780421853065491], [0.9780341982841492])\n"
          ]
        }
      ],
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=threshold]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>threshold]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt2IFKOZoCM"
      },
      "source": [
        "Write to the file and zip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "de52950e-03de-41eb-b7ae-7b41bb280992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: predictions.csv (deflated 66%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeGoYYeKZoCM"
      },
      "source": [
        "If using colab, download the zip and model files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n5ZovGlABTe"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbEhngYS9Rm9"
      },
      "outputs": [],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}