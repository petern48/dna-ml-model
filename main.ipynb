{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer\n",
        "- early stopping (less epochs)"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "# !pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ea32192c-83d7-4e34-d95f-85286d8783f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "5ce4780c-bd12-4b61-c81c-26b374f06332"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "# rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190a3687-840b-471a-c264-534c5bed2d86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd, random\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "# from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/sberbank-ai/ru-dalle/blob/e96631a867fcadcfaa52eecb20b1e42b88aa4386/rudalle/utils.py\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(1)"
      ],
      "metadata": {
        "id": "TqvTd3Ano27X"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24ac8f8-c897-4fe2-bf7d-886ddceff79e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ef9974-ee2f-46c6-ce90-ac1c4af91827"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d3d75d-0160-4693-a321-719215082972"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "60952a43-906e-4c97-a386-fd7954e6f8fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ed356c-33c1-4925-c358-6d85ef9b98f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "l7SLRPi59Rm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91a240a-6ea2-4402-82f1-602afc095f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3344 total hidden\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (Convs): ModuleList(\n",
              "    (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=3200, out_features=32, bias=True)\n",
              "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout_Dense): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "conv_filters = [32, 64]  # [64, 128]\n",
        "# num_filters1 = 64  # 64\n",
        "# num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "# hidden_dense1 = 64  # 64\n",
        "# hidden_dense2 = 32  # 32\n",
        "linear_neurons = [32, 16]  #[64,32]\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "# CNN = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "#                            hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, conv_filters, pool_kernel_size,\n",
        "                           linear_neurons, dropout_rate_Dense)\n",
        "total_hidden = sum(conv_filters) + sum(linear_neurons) - (4 + 1)\n",
        "print(f\"{total_hidden} total hidden\")\n",
        "CNN.to(device)  # quiet output\n",
        "# sum(linear_neurons)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Based on a test, using [1,pos_weight] gives the same results as [weight0, weight1]"
      ],
      "metadata": {
        "id": "Kx6jTrrcqZ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "# WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "WEIGHTED_LOSS = \"sklearn type weight\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weighted_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weighted_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()  # (reduction='none') ??\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    # loss_fn = utils.macro_double_soft_f1\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf14cf9-c643-4705-9f37-843b6ee4cf42"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor([10.1283], device='cuda:0')\n",
            "weight for class 0 tensor([2.1975], device='cuda:0')\n",
            "weight for class 1 tensor([22.2567], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "weight_decay = .01\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True\n",
        "note = f\"{conv_filters}-conv-{linear_neurons}-lin-{weight_decay}-weight-decay-adamW-{WEIGHTED_LOSS}\"\n",
        "note"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5234385c-c192-40ee-ed18-fbf203a440c8"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[4, 32, 64]-conv-[3200, 32, 16, 1]-lin-0.01-weight-decay-adamW-sklearn type weight'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "8z_gnhTp9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "078a72b4-e962-43bc-e2c1-586407150092"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240109_052158-jol49wwn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/petern0408/dna_ml_model/runs/jol49wwn' target=\"_blank\">[4, 32, 64]-conv-[3200, 32, 16, 1]-lin-0.01-weight-decay-adamW-sklearn type weight</a></strong> to <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/petern0408/dna_ml_model' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/petern0408/dna_ml_model/runs/jol49wwn' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/jol49wwn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n",
            "Training Loss: 1.0276 Acc: 0.8192 F1: 0.2977\n",
            "          Precision 0.2287 Recall: 0.4263\n",
            "Validation Loss: 609.8106 Acc: 0.8506 \n",
            "          Precision 0.2680 Recall: 0.3815 F1: 0.3149\n",
            "\n",
            "Epoch 2 of 20\n",
            "Training Loss: 0.9501 Acc: 0.8263 F1: 0.3462\n",
            "          Precision 0.2615 Recall: 0.5117\n",
            "Validation Loss: 580.5951 Acc: 0.8662 \n",
            "          Precision 0.3173 Recall: 0.4233 F1: 0.3627\n",
            "\n",
            "Epoch 3 of 20\n",
            "Training Loss: 0.9170 Acc: 0.8369 F1: 0.3742\n",
            "          Precision 0.2856 Recall: 0.5429\n",
            "Validation Loss: 568.2463 Acc: 0.8670 \n",
            "          Precision 0.3262 Recall: 0.4491 F1: 0.3779\n",
            "\n",
            "Epoch 4 of 20\n",
            "Training Loss: 0.8953 Acc: 0.8411 F1: 0.3892\n",
            "          Precision 0.2973 Recall: 0.5636\n",
            "Validation Loss: 559.3824 Acc: 0.8686 \n",
            "          Precision 0.3358 Recall: 0.4705 F1: 0.3919\n",
            "\n",
            "Epoch 5 of 20\n",
            "Training Loss: 0.8763 Acc: 0.8443 F1: 0.4011\n",
            "          Precision 0.3065 Recall: 0.5801\n",
            "Validation Loss: 552.0419 Acc: 0.8688 \n",
            "          Precision 0.3403 Recall: 0.4884 F1: 0.4012\n",
            "\n",
            "Epoch 6 of 20\n",
            "Training Loss: 0.8595 Acc: 0.8473 F1: 0.4120\n",
            "          Precision 0.3150 Recall: 0.5955\n",
            "Validation Loss: 545.5436 Acc: 0.8679 \n",
            "          Precision 0.3426 Recall: 0.5096 F1: 0.4097\n",
            "\n",
            "Epoch 7 of 20\n",
            "Training Loss: 0.8452 Acc: 0.8498 F1: 0.4208\n",
            "          Precision 0.3220 Recall: 0.6069\n",
            "Validation Loss: 539.5792 Acc: 0.8673 \n",
            "          Precision 0.3451 Recall: 0.5289 F1: 0.4177\n",
            "\n",
            "Epoch 8 of 20\n",
            "Training Loss: 0.8333 Acc: 0.8518 F1: 0.4281\n",
            "          Precision 0.3277 Recall: 0.6171\n",
            "Validation Loss: 535.3896 Acc: 0.8677 \n",
            "          Precision 0.3481 Recall: 0.5390 F1: 0.4230\n",
            "\n",
            "Epoch 9 of 20\n",
            "Training Loss: 0.8234 Acc: 0.8534 F1: 0.4341\n",
            "          Precision 0.3323 Recall: 0.6259\n",
            "Validation Loss: 531.2401 Acc: 0.8658 \n",
            "          Precision 0.3462 Recall: 0.5530 F1: 0.4258\n",
            "\n",
            "Epoch 10 of 20\n",
            "Training Loss: 0.8149 Acc: 0.8546 F1: 0.4390\n",
            "          Precision 0.3361 Recall: 0.6330\n",
            "Validation Loss: 528.4640 Acc: 0.8660 \n",
            "          Precision 0.3481 Recall: 0.5607 F1: 0.4295\n",
            "\n",
            "Epoch 11 of 20\n",
            "Training Loss: 0.8076 Acc: 0.8556 F1: 0.4433\n",
            "          Precision 0.3392 Recall: 0.6396\n",
            "Validation Loss: 525.9183 Acc: 0.8653 \n",
            "          Precision 0.3477 Recall: 0.5672 F1: 0.4311\n",
            "\n",
            "Epoch 12 of 20\n",
            "Training Loss: 0.8009 Acc: 0.8570 F1: 0.4477\n",
            "          Precision 0.3428 Recall: 0.6451\n",
            "Validation Loss: 523.5571 Acc: 0.8641 \n",
            "          Precision 0.3459 Recall: 0.5737 F1: 0.4316\n",
            "\n",
            "Epoch 13 of 20\n",
            "Training Loss: 0.7946 Acc: 0.8581 F1: 0.4513\n",
            "          Precision 0.3458 Recall: 0.6495\n",
            "Validation Loss: 521.0054 Acc: 0.8626 \n",
            "          Precision 0.3443 Recall: 0.5829 F1: 0.4329\n",
            "\n",
            "Epoch 14 of 20\n",
            "Training Loss: 0.7887 Acc: 0.8588 F1: 0.4542\n",
            "          Precision 0.3479 Recall: 0.6539\n",
            "Validation Loss: 518.3254 Acc: 0.8619 \n",
            "          Precision 0.3443 Recall: 0.5922 F1: 0.4355\n",
            "\n",
            "Epoch 15 of 20\n",
            "Training Loss: 0.7833 Acc: 0.8597 F1: 0.4571\n",
            "          Precision 0.3504 Recall: 0.6575\n",
            "Validation Loss: 515.9566 Acc: 0.8604 \n",
            "          Precision 0.3428 Recall: 0.6012 F1: 0.4366\n",
            "\n",
            "Epoch 16 of 20\n",
            "Training Loss: 0.7782 Acc: 0.8602 F1: 0.4591\n",
            "          Precision 0.3519 Recall: 0.6601\n",
            "Validation Loss: 513.3282 Acc: 0.8599 \n",
            "          Precision 0.3429 Recall: 0.6088 F1: 0.4387\n",
            "\n",
            "Epoch 17 of 20\n",
            "Training Loss: 0.7734 Acc: 0.8611 F1: 0.4621\n",
            "          Precision 0.3544 Recall: 0.6640\n",
            "Validation Loss: 511.1768 Acc: 0.8593 \n",
            "          Precision 0.3425 Recall: 0.6127 F1: 0.4394\n",
            "\n",
            "Epoch 18 of 20\n",
            "Training Loss: 0.7691 Acc: 0.8616 F1: 0.4641\n",
            "          Precision 0.3559 Recall: 0.6668\n",
            "Validation Loss: 509.4552 Acc: 0.8588 \n",
            "          Precision 0.3422 Recall: 0.6168 F1: 0.4402\n",
            "\n",
            "Epoch 19 of 20\n",
            "Training Loss: 0.7650 Acc: 0.8620 F1: 0.4658\n",
            "          Precision 0.3572 Recall: 0.6693\n",
            "Validation Loss: 508.1620 Acc: 0.8587 \n",
            "          Precision 0.3422 Recall: 0.6188 F1: 0.4407\n",
            "\n",
            "Epoch 20 of 20\n",
            "Training Loss: 0.7612 Acc: 0.8626 F1: 0.4675\n",
            "          Precision 0.3586 Recall: 0.6713\n",
            "Validation Loss: 506.7979 Acc: 0.8589 \n",
            "          Precision 0.3422 Recall: 0.6165 F1: 0.4401\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"weight decay\": weight_decay,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "        if loss_fn.__class__.__name__ == \"function\":  # custom loss function\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels) #, [weight_class0, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "fvZAvEIsoFo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# [4, 32, 64, 128]-conv-[6400, 64, 32, 1] resulted in\n",
        "# mat1 and mat2 shapes cannot be multiplied (128x3200 and 6400x64)\n",
        "\n",
        "# [4, 16, 32, 64]-conv-[3200, 64, 32, 1]-lin\n",
        "# mat1 and mat2 shapes cannot be multiplied (128x1600 and 3200x64)  # inside for loop of linears # flatten size prob not righ"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "# total_labels = np.empty(0)  # don't need to have same order\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "    # total_labels = np.concatenate((total_labels, labels.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "41719188-5f66-4da3-e4d3-e95401738c80"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-122-07a454fd5c07>:35: RuntimeWarning: invalid value encountered in divide\n",
            "  fscores = (2 * precisions * recalls) / (precisions + recalls)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 0.7486209273338318 with F-Score 0.4616326031085547 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564,
          "referenced_widgets": [
            "c83477469acc46ff96226d1972d388a6",
            "ee3b4cda50254cc5a5b59e647040f789",
            "9828e995614048f684ad918a48003355",
            "63c6dd55d8ed4de18eb95f468f431df6",
            "8c99a538e8e947409d152ab8f8602789",
            "f9b1589869c54c9e8833b832f1e7892d",
            "082af47df39c44fbaf92fb29cac632d8",
            "588c5550a5b2435f99b58ba302ea93ce"
          ]
        },
        "outputId": "254f2d32-b2a1-4a18-90cc-bb7a11370a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 0.7486209273338318\n",
            "Final Test Accuracy: 88.82873516583832 %\n",
            "Final Test Precision: 40.75752670767238 %\n",
            "Final Test Recall: 53.21217244294167 %\n",
            "Final Test F1 Score: 46.15948670944088 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c83477469acc46ff96226d1972d388a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▂▄▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Train F1</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Val Acc</td><td>▁▇▇███▇█▇▇▇▆▆▅▅▅▄▄▄▄</td></tr><tr><td>Val F1</td><td>▁▄▅▅▆▆▇▇▇▇▇▇████████</td></tr><tr><td>Val Loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Val Precision</td><td>▁▅▆▇▇████████████▇▇▇</td></tr><tr><td>Val Recall</td><td>▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.86256</td></tr><tr><td>Train F1</td><td>0.46749</td></tr><tr><td>Train Loss</td><td>0.76118</td></tr><tr><td>Train Precision</td><td>0.3586</td></tr><tr><td>Val Acc</td><td>0.85887</td></tr><tr><td>Val F1</td><td>0.44012</td></tr><tr><td>Val Loss</td><td>506.79789</td></tr><tr><td>Val Precision</td><td>0.3422</td></tr><tr><td>Val Recall</td><td>0.61654</td></tr><tr><td>test_accuracy</td><td>0.88829</td></tr><tr><td>test_f1_score</td><td>0.46159</td></tr><tr><td>test_precision</td><td>0.40758</td></tr><tr><td>test_recall</td><td>0.53212</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">[4, 32, 64]-conv-[3200, 32, 16, 1]-lin-0.01-weight-decay-adamW-sklearn type weight</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/jol49wwn' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/jol49wwn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240109_052158-jol49wwn/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        test_outputs = sigmoid(test_outputs)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note: Actual Test {len(acc_seq_test)} accessible and {len(not_seq_test)} notaccessible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iniAmj4jhpX",
        "outputId": "a51d0cdf-cce0-452e-f200-6a6d28ace571"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Actual Test 7086 accessible and 71768 notaccessible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test on rest of nonaccessible\n",
        "# if DOWNSAMPLE:\n",
        "#     # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "#     rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "#     # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "#     CM = 0\n",
        "#     total_correct = 0\n",
        "#     total_predictions = 0\n",
        "#     model.eval()\n",
        "#     for batch in rest_notacc_loader:  # tqdm()\n",
        "#         samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "#         outputs = model(samples)\n",
        "#         preds = utils.get_preds(outputs)\n",
        "#         total_predictions += len(outputs)\n",
        "#         CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "#     # Computer accuracy, precision, recall, and f1 metrics\n",
        "#     acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "#     print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "#     print(f\"Rest not Precision: {precision * 100} %\")\n",
        "#     print(f\"Rest not Recall: {recall * 100} %\")\n",
        "#     print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "#     # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "#     # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r pretrained\n",
        "# !rm predictions.zip"
      ],
      "metadata": {
        "id": "N_USYmjft93K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f79f56-b7fe-4b72-f6bc-6e5ed74ca610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-05-05-08-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-09-05-05-08\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "CNNModel.save_CNNModel(model_save_path, CNN)  # model\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "QwvJ7kqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "fca51986-fa71-4490-d81b-d459a5be5875"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for CNNModel:\n\tMissing key(s) in state_dict: \"Convs.2.weight\", \"Convs.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tsize mismatch for Convs.0.weight: copying a param with shape torch.Size([128, 4, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3]).\n\tsize mismatch for Convs.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for Convs.1.weight: copying a param with shape torch.Size([256, 128, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3]).\n\tsize mismatch for Convs.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for linears.0.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([12800, 12800]).\n\tsize mismatch for linears.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([12800]).\n\tsize mismatch for linears.1.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([64, 12800]).\n\tsize mismatch for linears.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for linears.2.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for linears.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([32]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-6a4c75863c77>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the new path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/pretrained/[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-04-59-28-CNNModel-model-0.0001lr-20epochs.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_CNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CNNModel.py\u001b[0m in \u001b[0;36mload_CNNModel\u001b[0;34m(model_save_path)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mdropout_rate_Dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dropout_rate_Dense\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNModel:\n\tMissing key(s) in state_dict: \"Convs.2.weight\", \"Convs.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tsize mismatch for Convs.0.weight: copying a param with shape torch.Size([128, 4, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3]).\n\tsize mismatch for Convs.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for Convs.1.weight: copying a param with shape torch.Size([256, 128, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3]).\n\tsize mismatch for Convs.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for linears.0.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([12800, 12800]).\n\tsize mismatch for linears.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([12800]).\n\tsize mismatch for linears.1.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([64, 12800]).\n\tsize mismatch for linears.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for linears.2.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for linears.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([32])."
          ]
        }
      ],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"/content/pretrained/[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-04-59-28-CNNModel-model-0.0001lr-20epochs.pt\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef58b2ee-75ae-4d0c-a7ee-7ca570f3156e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64ff514-a4e5-49d8-eff1-a01d0c782b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "        outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=0.7]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.7]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "cb5ead5b-50b9-46b7-f7a6-8d78735af09d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 39832 true values out of  269315  total 14.790115663813749 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [4.43731841e-17 1.39795972e-16 1.48277114e-16 ... 6.99953020e-01\n",
            " 6.99996710e-01 6.99996889e-01]\n",
            "accessible probs [1.         0.99999988 0.99999976 ... 0.70002598 0.70001978 0.70001554]\n",
            "\n",
            "first 10\n",
            " ([1.0], [0.9999998807907104], [0.9999997615814209], [0.9999994039535522], [0.9999992847442627], [0.9999992847442627], [0.9999992847442627], [0.9999991655349731], [0.9999991655349731], [0.999998927116394])\n",
            "last 10 of top 10000\n",
            " ([0.9793400764465332], [0.9793400764465332], [0.9793326258659363], [0.9793269634246826], [0.9793263673782349], [0.9793241024017334], [0.9793235063552856], [0.9793227910995483], [0.9793142676353455], [0.9793060421943665])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "673e19d5-f384-4863-9539-40eb170e8e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "6dc7f784-d366-4149-f599-4715ee71907a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c483cfa7-f05a-4f14-b798-492f02132fab\", \"[4, 128, 256]-conv-[12800, 64, 32, 1]-lin-0.01-weight-decay-adamW-sklearn type weight01-09-04-59-28-CNNModel-model-0.0001lr-20epochs.pt\", 3693518)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "be4ce88f-c8c4-4a88-f213-b3f5ff726e1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a52adc2-f15e-4acd-94ec-e6fa11d06dde\", \"predictions.zip\", 33513)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c83477469acc46ff96226d1972d388a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee3b4cda50254cc5a5b59e647040f789",
              "IPY_MODEL_9828e995614048f684ad918a48003355"
            ],
            "layout": "IPY_MODEL_63c6dd55d8ed4de18eb95f468f431df6"
          }
        },
        "ee3b4cda50254cc5a5b59e647040f789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c99a538e8e947409d152ab8f8602789",
            "placeholder": "​",
            "style": "IPY_MODEL_f9b1589869c54c9e8833b832f1e7892d",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "9828e995614048f684ad918a48003355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082af47df39c44fbaf92fb29cac632d8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_588c5550a5b2435f99b58ba302ea93ce",
            "value": 1
          }
        },
        "63c6dd55d8ed4de18eb95f468f431df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c99a538e8e947409d152ab8f8602789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b1589869c54c9e8833b832f1e7892d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "082af47df39c44fbaf92fb29cac632d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588c5550a5b2435f99b58ba302ea93ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}