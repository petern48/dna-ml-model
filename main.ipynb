{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- try soft f1 loss function\n",
        "- test weighted loss function to see if working how i want\n",
        "- one hot vs label binarizer\n",
        "- early stopping (less epochs)"
      ],
      "metadata": {
        "id": "4BxmfNwOq25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76HJQ9yr9Rm1"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install tqdm  # pip install ipywidgets or something\n",
        "!pip install wandb &> /dev/null\n",
        "# !pip install gensim &> /dev/null\n",
        "!pip install torchmetrics &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeFFJzVy9Rm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "543ccce4-ca36-43aa-e585-c333571a73e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "USING_WANDB = True  # Set to false if not Peter\n",
        "\n",
        "if USING_WANDB:\n",
        "    import wandb\n",
        "    wandb.login();\n",
        "    # !wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxLO6GibEAN",
        "outputId": "e24814e1-38ee-4915-8972-400f3ac34ab1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/dna_ml_model_data\"\n",
        "accessible_file = f\"{data_folder}/accessible.fasta\"\n",
        "notaccessible_file = f\"{data_folder}/notaccessible.fasta\"\n",
        "reduced_nonaccessible_file = f\"{data_folder}/reduced_nonaccessible.fasta\"\n",
        "comp_file = f\"{data_folder}/test.fasta\"\n",
        "# rest_notaccessible_file = f\"{data_folder}/rest_nonaccessible.fasta\"\n",
        "\n",
        "DATA_ZIP_FILE = \"Files.zip\"\n",
        "LINES_PER_SEQUENCE = 4\n",
        "ACCESSIBLE_LABEL = 1\n",
        "NOT_ACCESSIBLE_LABEL = 0\n",
        "TEMP_SPLIT = 0.30  # validation + test\n",
        "TEST_SPLIT = 0.15\n",
        "PRETRAINED_DIR = \"pretrained\"\n",
        "SOLUTION_FILE = \"predictions.csv\""
      ],
      "metadata": {
        "id": "zpsAv0N3bHF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "foXB0nMJ9Rm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87687ff-85ae-4696-87fb-8efa0b6f05f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'CNNModel' from '/content/CNNModel.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import dna_dataset, utils, CNNModel # , LSTMCNNModel, constants\n",
        "import torch.nn as nn, torch.optim as optim, torch\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib, os, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "# from torchmetrics.functional import f1_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "# importlib.reload(LSTMCNNModel)\n",
        "# importlib.reload(constants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gxjgFVQv9Rm6"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file\n",
        "# !unzip $DATA_ZIP_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VRsIPhjS9Rm6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from data files\n",
        "acc_sequences, acc_labels, _ = dna_dataset.read_data_file(accessible_file, accessible=True, shuffle=True)\n",
        "# not_sequences, not_labels, _ = dna_dataset.read_data_file(reduced_nonaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "GT8Q1al6hNk-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_sequences, not_labels, _ = dna_dataset.read_data_file(notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "ml9lGOuQMv1a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_acc = len(acc_sequences)\n",
        "num_not = len(not_sequences)\n",
        "full_size = num_acc + num_not\n",
        "print(f\"full size: {full_size} num_acc: {num_acc} num_not: {num_not}\")\n",
        "\n",
        "# Split accessible data into train val test split\n",
        "acc_seq_train, acc_seq_temp, acc_lab_train, acc_lab_temp = train_test_split(acc_sequences, acc_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "acc_seq_val, acc_seq_test, acc_lab_val, acc_lab_test = train_test_split(acc_seq_temp, acc_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "# Split not accessible data into train val test split\n",
        "not_seq_train, not_seq_temp, not_lab_train, not_lab_temp = train_test_split(not_sequences, not_labels, test_size=TEMP_SPLIT, random_state=1)\n",
        "not_seq_val, not_seq_test, not_lab_val, not_lab_test = train_test_split(not_seq_temp, not_lab_temp, test_size=TEST_SPLIT/TEMP_SPLIT, random_state=1)\n",
        "\n",
        "assert(len(acc_sequences) == len(acc_labels) == len(acc_seq_train) + len(acc_seq_val) + len(acc_seq_test))\n",
        "assert(len(not_sequences) == len(not_labels) == len(not_lab_train) + len(not_lab_val) + len(not_lab_test))"
      ],
      "metadata": {
        "id": "7zU84Mb84jze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ff4e0d-5e9d-4b26-bd25-7da085b7aaa9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full size: 525688 num_acc: 47239 num_not: 478449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample or Downsample the dataset  \n",
        "(AFTER splitting to train/validation/test to prevent data leakage)"
      ],
      "metadata": {
        "id": "80TrCZetX20E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UPSAMPLE = False\n",
        "DOWNSAMPLE = False\n",
        "\n",
        "\n",
        "if UPSAMPLE:\n",
        "    num_diff = len(not_seq_train) - len(acc_seq_train)\n",
        "    # upscale the minority\n",
        "    upsampled_acc_seq, upsampled_acc_lab = resample(acc_seq_train, acc_lab_train, n_samples=num_diff, random_state=1)\n",
        "\n",
        "    actual_acc_seq_train = acc_seq_train + upsampled_acc_seq\n",
        "    actual_acc_lab_train = acc_lab_train + upsampled_acc_lab\n",
        "else:\n",
        "    actual_acc_seq_train = acc_seq_train\n",
        "    actual_acc_lab_train = acc_lab_train\n",
        "\n",
        "# consider upweighting for calibration\n",
        "if DOWNSAMPLE:\n",
        "    # downsample the majority\n",
        "    # downsampled_not_seq, downsampled_not_lab = resample(not_seq_train, not_lab_train, n_samples=len(acc_seq_train), random_state=1)\n",
        "    # just take the first part len(acc_seq_train) samples\n",
        "    actual_not_seq_train = not_seq_train[:len(acc_seq_train)]\n",
        "    actual_not_lab_train = not_lab_train[:len(acc_seq_train)]\n",
        "\n",
        "    # Adding rest of data to test and val\n",
        "    rest_not_sequences, rest_not_labels = not_seq_train[len(acc_seq_train):], not_lab_train[len(acc_seq_train):]\n",
        "\n",
        "    print(\"Rest not seq and labs \", len(rest_not_sequences), len(rest_not_labels))\n",
        "    assert(len(rest_not_sequences) + len(actual_not_seq_train) == len(not_seq_train))\n",
        "\n",
        "    # ensure the data is now equal\n",
        "    assert(len(actual_acc_seq_train) == len(actual_not_seq_train))\n",
        "\n",
        "else:\n",
        "    actual_not_seq_train = not_seq_train\n",
        "    actual_not_lab_train = not_lab_train\n",
        "\n",
        "print(\"Actual train not seq and labs \", len(actual_not_seq_train), len(actual_not_lab_train))\n",
        "print(\"Actual train acc seq and labs \", len(actual_acc_seq_train), len(actual_acc_lab_train))"
      ],
      "metadata": {
        "id": "k6L73jcLX2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383e0d82-cdb7-4560-894c-7ae6676c53fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual train not seq and labs  334914 334914\n",
            "Actual train acc seq and labs  33067 33067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the (shuffled) datasets, after appending the lists\n",
        "sequences_train = actual_acc_seq_train + actual_not_seq_train\n",
        "labels_train = actual_acc_lab_train + actual_not_lab_train\n",
        "# sequences_train, labels_train = dna_dataset.shuffle_lists(sequences_train, labels_train)\n",
        "# df_train = pd.DataFrame({\"sequences\": sequences_train, \"labels\": labels_train})\n",
        "train_dataset = dna_dataset.DNADataset(sequences_train, labels_train)\n",
        "num_train = len(train_dataset)\n",
        "print(\"train samples\", num_train)\n",
        "assert(len(sequences_train) == len(labels_train) == num_train)\n",
        "\n",
        "sequences_val = acc_seq_val + not_seq_val\n",
        "labels_val = acc_lab_val + not_lab_val\n",
        "val_dataset = dna_dataset.DNADataset(sequences_val, labels_val)\n",
        "print(\"val samples\", len(val_dataset))\n",
        "\n",
        "sequences_test = acc_seq_test + not_seq_test\n",
        "labels_test = acc_lab_test + not_lab_test\n",
        "test_dataset = dna_dataset.DNADataset(sequences_test, labels_test)\n",
        "print(\"test samples\", len(test_dataset))\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    rest_notacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    print(\"rest not samples\", len(rest_notacc_dataset))"
      ],
      "metadata": {
        "id": "fVmtEjhyh3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac1334f-15a4-4082-91cb-bedfb01a5f55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples 367981\n",
            "val samples 78853\n",
            "test samples 78854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check things are the right size\n",
        "if DOWNSAMPLE:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) + len(rest_not_sequences) == full_size)\n",
        "elif UPSAMPLE:\n",
        "  pass\n",
        "else:\n",
        "  print(len(sequences_train) + len(sequences_val) + len(sequences_test), full_size)\n",
        "  assert(len(sequences_train) + len(sequences_val) + len(sequences_test) == full_size)\n",
        "# except:\n",
        "#   print(rest_not_sequences)\n",
        "#   raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaI7xT5gbUnh",
        "outputId": "61b2081d-2160-4ca6-dfc4-7c3866d83744"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525688 525688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qrCkS5X19Rm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64559abb-4f9e-4f83-b5a6-da5ecdaa7da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sequences 525688\n",
            "num accessible 47239\n",
            "num not accessible 478449\n",
            "example entry 0\n",
            "label 0\n",
            "shuffled\n"
          ]
        }
      ],
      "source": [
        "# ensure the DNADataset is loaded properly\n",
        "print('total sequences', full_size)\n",
        "print('num accessible', num_acc)\n",
        "print('num not accessible', num_not)\n",
        "i = 0\n",
        "print(f\"example entry {i}\")\n",
        "item = train_dataset[i]\n",
        "# print(item['sequence'])  # long answer\n",
        "print(\"label\", item['label'])\n",
        "# ensure dataset was shuffled properly\n",
        "# check that not all the accessible labels are at the front\n",
        "for i in range(len(train_dataset)):\n",
        "    if train_dataset[i]['label'] != ACCESSIBLE_LABEL:\n",
        "        print('shuffled')\n",
        "        break\n",
        "\n",
        "# Balanced: total sequences 94478  num accessible 47239  num not accessible 47239\n",
        "\n",
        "# Full (imbalanced) total sequences 525688  num accessible 47239  num not accessible 478449"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Free up memory\n",
        "# del sequences_train, labels_train, sequences_val, labels_val, sequences_test, labels_test\n",
        "# del acc_seq_train, not_seq_train, acc_lab_train, not_lab_train\n",
        "# del acc_seq_val, not_seq_val, acc_lab_val, not_lab_val\n",
        "# del acc_seq_test, not_seq_test, acc_lab_test, not_lab_test"
      ],
      "metadata": {
        "id": "zu8NO2kgwj61"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "l7SLRPi59Rm7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "importlib.reload(dna_dataset)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(CNNModel)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "kernel_size = 3     # 2  # should use odd size\n",
        "embed_dim = 4  # 4\n",
        "num_filters1 = 64  # 64\n",
        "num_filters2 = 128  # 128\n",
        "pool_kernel_size = 2  # 2\n",
        "hidden_dense1 = 64  # 64\n",
        "hidden_dense2 = 32  # 32\n",
        "dropout_rate_Dense = 0.5  # .5\n",
        "\n",
        "# insert torch model here, that takes sequence as input and output a label 0 or 1\n",
        "CNN = CNNModel.CNNModel(kernel_size, embed_dim, num_filters1, num_filters2, pool_kernel_size,\n",
        "                           hidden_dense1, hidden_dense2, dropout_rate_Dense)\n",
        "CNN.to(device);  # quiet output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Based on a test, using [1,pos_weight] gives the same results as [weight0, weight1]"
      ],
      "metadata": {
        "id": "Kx6jTrrcqZ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "\n",
        "# WEIGHTED_LOSS = \"Inverse Class Frequency Weight\"\n",
        "WEIGHTED_LOSS = \"Balanced Class Weights\"\n",
        "# WEIGHTED_LOSS = None\n",
        "# WEIGHTED_LOSS = \"sklearn type loss\"\n",
        "# WEIGHTED_LOSS = \"Inverse Sqrt Weight\"\n",
        "\n",
        "# https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4\n",
        "\n",
        "weight_class0 = 1\n",
        "\n",
        "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
        "if WEIGHTED_LOSS == \"sklearn type weight\":\n",
        "    weight_class0 = torch.Tensor([num_train / len(actual_not_seq_train) * 2]).to(device)\n",
        "    weight_class1 = torch.Tensor([num_train / len(actual_acc_seq_train) * 2]).to(device)\n",
        "    # = (n_0 + n_1) / (2.0 * n_1)\n",
        "\n",
        "# Balanced class weights: weight = total_samples / (num_classes * frequency)\n",
        "elif WEIGHTED_LOSS == \"Balanced Class Weight\":\n",
        "    weight_class1 = num_train / len(actual_acc_seq_train) * 2\n",
        "\n",
        "# Inverse class frequency: weight = 1 / frequency\n",
        "elif WEIGHTED_LOSS == \"Inverse Class Frequency Weight\":\n",
        "    weight_class1 = len(actual_not_seq_train) / len(actual_acc_seq_train)\n",
        "\n",
        "# Slightly worse then the rest\n",
        "elif WEIGHTED_LOSS == \"Inverse Sqrt Weight\":\n",
        "    weighted_class0 = 1 / np.sqrt(len(actual_not_seq_train))\n",
        "    weighted_class1 = 1 / np.sqrt(len(actual_acc_seq_train))\n",
        "\n",
        "\n",
        "if WEIGHTED_LOSS != None:\n",
        "    # loss_fn = nn.BCELoss()\n",
        "    pos_weight = weight_class1 / weight_class0\n",
        "    print(f\"pos_weight {pos_weight}\")\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([pos_weight]).to(device))\n",
        "    # loss_fn = utils.weighted_binary_cross_entropy\n",
        "    # loss_fn = nn.BCELoss(weight=torch.Tensor([weight_class0, weight_class1]))\n",
        "    try:\n",
        "      print(\"weight for class 0\", weight_class0)\n",
        "    except:\n",
        "      pass\n",
        "    print(\"weight for class 1\", weight_class1)\n",
        "else:\n",
        "    loss_fn = nn.BCEWithLogitsLoss()  # (reduction='none') ??\n",
        "    # loss_fn = nn.BCELoss()\n",
        "\n",
        "if loss_fn.__class__.__name__ == \"BCELoss\" or loss_fn.__class__.__name__ == \"function\":\n",
        "    model = nn.Sequential(CNN, nn.Sigmoid())  # Add Softmax to model if using BCELoss\n",
        "    print(\"Added sigmoid\")\n",
        "else:\n",
        "    model = CNN\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "6nV9SwXn009g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa3cab3-fc5f-4e31-92c1-d48392495281"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor([22.2567], device='cuda:0')\n",
            "weight for class 0 1\n",
            "weight for class 1 tensor([22.2567], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = utils.macro_double_soft_f1"
      ],
      "metadata": {
        "id": "KYoGe1OkH1o5"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "uuRPn9rw9Rm8"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = .0001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # weight_decay=1\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=.01)  # weight_decay=1\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # pretty bad\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size) # shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "# del train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING_WANDB = True"
      ],
      "metadata": {
        "id": "gJwMVxMXCh23"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z_gnhTp9Rm8"
      },
      "outputs": [],
      "source": [
        "# TRAINING LOOP\n",
        "# USING_WANDB = False\n",
        "if USING_WANDB:\n",
        "    note = f\"{WEIGHTED_LOSS}\"\n",
        "    # note = f\"{optimizer.__class__.__name__}-{kernel_size}-kernel-{num_filters1}-{num_filters2}-conv-{hidden_dense1}-{hidden_dense2}-dense\" # \"lstm_no_dropout\" # \"0.5_dropout\"\n",
        "    wandb.init(\n",
        "        project=\"dna_ml_model\",\n",
        "        # name=f\"experiment_{run}\"\n",
        "        name=f\"{note}\",\n",
        "        settings=wandb.Settings(start_method=\"fork\"),\n",
        "        config = {\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"loss fn\": loss_fn.__class__.__name__,\n",
        "            \"weighted loss1\": WEIGHTED_LOSS,\n",
        "            \"notes\": note\n",
        "    })\n",
        "\n",
        "\n",
        "# step = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "\n",
        "    CM = 0  # confusion matrix\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:  # tqdm()\n",
        "\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label'].to(device)\n",
        "\n",
        "        outputs = model(samples).flatten()\n",
        "\n",
        "        labels = labels.reshape(-1,1).float().flatten()\n",
        "\n",
        "        # Backpropagation and gradient descent\n",
        "\n",
        "        # if USE_WEIGHTED_LOSS:\n",
        "        #     acc_weight = (labels==ACCESSIBLE_LABEL) * weight_class0\n",
        "        #     not_weight = (labels==NOT_ACCESSIBLE_LABEL) * weight_class1\n",
        "        #     acc_weight[acc_weight==0] = 1\n",
        "        #     not_weight[not_weight==0] = 1\n",
        "        #     outputs *= acc_weight\n",
        "        #     outputs *= not_weight\n",
        "        if loss_fn.__class__.__name__ == \"function\":  # custom loss function\n",
        "            loss = loss_fn(outputs, labels, [weight_class0, weight_class1])\n",
        "        else:\n",
        "            loss = loss_fn(outputs, labels) #, [weight_class0, weight_class1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  # reset gradients before next iteration\n",
        "\n",
        "        running_loss += loss.item() * samples.size(0)  # loss per sample times batch size\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "        running_corrects += torch.sum(preds == labels.data).item()\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Calculate recall, precision, f1 score\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    # if step % n_eval == 0:\n",
        "    # Compute training loss and accuracy.\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = utils.evaluate(val_loader, model, loss_fn, device)\n",
        "\n",
        "    epoch_loss = running_loss / num_train\n",
        "    epoch_acc = running_corrects / num_train\n",
        "    print(f\"\"\"Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f}\n",
        "          Precision {precision:.4f} Recall: {recall:.4f}\"\"\")\n",
        "    print(f\"\"\"Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\n",
        "          Precision {val_precision:.4f} Recall: {val_recall:.4f}\"\"\")\n",
        "\n",
        "    # # deep copy the model\n",
        "    # if val_accuracy > best_acc:\n",
        "    #     best_acc = epoch_acc\n",
        "    #     torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    if USING_WANDB:\n",
        "        wandb.log({\"Train Loss\": epoch_loss,\n",
        "                    \"Val Loss\": val_loss,\n",
        "                    \"Train Precision\": precision,\n",
        "                    \"Val Precision\": val_precision,\n",
        "                    \"Val Recall\": val_recall,\n",
        "                    \"Train F1\": f1,\n",
        "                    \"Val F1\": val_f1,\n",
        "                    \"Val Acc\": val_acc,\n",
        "                    \"Train Acc\": epoch_acc,\n",
        "                  #  \"Epoch\": epoch\n",
        "        })\n",
        "        # step += 1\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "ZVKK_y2Q8j0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall plot for finding optimal threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "which_dataset = \"val\"  # test\n",
        "which_dataset = \"test\"\n",
        "dataset = val_dataset if which_dataset == \"val\" else test_dataset\n",
        "dataloader = val_loader if which_dataset == \"val\" else test_loader\n",
        "\n",
        "total_probs = np.empty(0)\n",
        "model.eval()\n",
        "# Calculate the probs\n",
        "for batch in dataloader:\n",
        "    samples, labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "\n",
        "    outputs = model(samples)\n",
        "\n",
        "    total_probs = np.concatenate((total_probs, outputs.flatten().cpu().detach().numpy()))\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(dataset.list2, total_probs)\n",
        "# dataset.list2  # list of all labels\n",
        "\n",
        "plt.plot(recalls, precisions, marker='.', label=which_dataset, color=\"black\")\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "fscores = (2 * precisions * recalls) / (precisions + recalls)\n",
        "\n",
        "# Turn nan values to 0\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscores)\n",
        "best_threshold = thresholds[ix]\n",
        "plt.plot(recalls[ix], precisions[ix], color=\"red\")\n",
        "plt.axvline(recalls[ix], ls='--', color=\"red\", label=\"Best F-Score\")\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(f\"Best Threshold {thresholds[ix]} with F-Score {fscores[ix]} for {which_dataset} dataset\")\n",
        "# Best Threshold 42.7\n",
        "# 87.3 for val, 79.4 for test\n",
        "# correct 80.4 val, 85.2 test  # now after fixing utils.compute_metrics(), although idt that affects this\n"
      ],
      "metadata": {
        "id": "6q5FF0pqhpXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "17f67cba-6e7c-4bcb-fa2f-097e884caf99"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-158-a47b6370a70d>:28: RuntimeWarning: invalid value encountered in divide\n",
            "  fscores = (2 * precisions * recalls) / (precisions + recalls)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold 1.1292049884796143 with F-Score 0.47129791788285663 for test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "BMFy_P4E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546,
          "referenced_widgets": [
            "76eae67e149f4fe68abf7ce209710062",
            "3ad84c6943054951b76bff6b8e5b31f8",
            "3c02488721bf42718400a240ecb5d107",
            "762fd05492d64081b843033410d192ed",
            "cde48c654e024d8c9e2f25fa6446dab8",
            "6fd0498c01f44107b6b398de889afbc1",
            "057ad36ca9d14b998661c31242b734df",
            "a5eb46da944e4309878716a5b8ac88e2"
          ]
        },
        "outputId": "ed2eec4d-ca20-4c4f-cef6-ecaa587cb0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold 1.1292049884796143\n",
            "Final Test Accuracy: 91.00060858099198 %\n",
            "Final Test Precision: 50.0 %\n",
            "Final Test Recall: 0.08453085376162299 %\n",
            "Final Test F1 Score: 0.16877637130801687 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76eae67e149f4fe68abf7ce209710062"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>Train F1</td><td>▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Precision</td><td>▁▂▃▃▄▄▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>Val Acc</td><td>▄▆▆▅▅▅▁▄▇█▅▆▂▅▆▇▄▂█▇</td></tr><tr><td>Val F1</td><td>▁▃▄▅▅▆▄▅▇█▆▇▅▇▇▇▆▅██</td></tr><tr><td>Val Loss</td><td>█▇▆▅▄▄▃▃▃▃▂▂▁▂▂▂▁▁▂▁</td></tr><tr><td>Val Precision</td><td>▁▃▄▄▄▄▁▄▇█▄▅▂▅▅▆▃▂█▆</td></tr><tr><td>Val Recall</td><td>▁▂▂▄▄▅█▆▄▃▆▅█▆▅▅▇█▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.85509</td></tr><tr><td>Train F1</td><td>0.34481</td></tr><tr><td>Train Loss</td><td>1.51439</td></tr><tr><td>Train Precision</td><td>0.29039</td></tr><tr><td>Val Acc</td><td>0.84887</td></tr><tr><td>Val F1</td><td>0.44974</td></tr><tr><td>Val Loss</td><td>379.60132</td></tr><tr><td>Val Precision</td><td>0.33423</td></tr><tr><td>Val Recall</td><td>0.68727</td></tr><tr><td>test_accuracy</td><td>0.91001</td></tr><tr><td>test_f1_score</td><td>0.00169</td></tr><tr><td>test_precision</td><td>0.5</td></tr><tr><td>test_recall</td><td>0.00085</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">256-batchsize-AdamW-Inverse Sqrt Weight</strong> at: <a href='https://wandb.ai/petern0408/dna_ml_model/runs/71ip6xxy' target=\"_blank\">https://wandb.ai/petern0408/dna_ml_model/runs/71ip6xxy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240107_213630-71ip6xxy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# EVALUATE on test dataset\n",
        "total_predictions = 0\n",
        "total_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "CM = 0  # confusion matrix\n",
        "\n",
        "print(f\"Using threshold {best_threshold}\")\n",
        "for batch in test_loader:  # tqdm()\n",
        "\n",
        "    test_samples, test_labels = batch['sequence'].to(device), batch['label'].to(device)\n",
        "    test_outputs = model(test_samples)\n",
        "\n",
        "    test_preds = utils.get_preds(test_outputs, threshold=best_threshold)\n",
        "\n",
        "    test_labels = test_labels.reshape(-1, 1).float()\n",
        "\n",
        "    test_loss = loss_fn(test_outputs, test_labels).item()  # change tensor to single val\n",
        "\n",
        "    total_predictions += len(test_outputs)\n",
        "\n",
        "    CM += confusion_matrix(test_labels.flatten().cpu().detach().numpy(), test_preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "# Computer accuracy, precision, recall, and f1 metrics\n",
        "acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "print(f\"Final Test Accuracy: {acc_score * 100} %\")\n",
        "print(f\"Final Test Precision: {precision * 100} %\")\n",
        "print(f\"Final Test Recall: {recall * 100} %\")\n",
        "print(f\"Final Test F1 Score: {f1 * 100} %\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    wandb.summary['test_accuracy'] = acc_score\n",
        "    wandb.summary['test_precision'] = precision\n",
        "    wandb.summary['test_recall'] = recall\n",
        "    wandb.summary['test_f1_score'] = f1\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note: Actual Test {len(acc_seq_test)} accessible and {len(not_seq_test)} notaccessible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iniAmj4jhpX",
        "outputId": "f93360cd-575a-43d6-99ba-8c10808755d1"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Actual Test 7086 accessible and 71768 notaccessible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Potential solutions to out of gpu memory\n",
        "# import gc\n",
        "# gc.collect()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "# del total_outputs, total_labels"
      ],
      "metadata": {
        "id": "ARRRf1b5UL38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "# rest_not_sequences, rest_not_labels, _ = dna_dataset.read_data_file(rest_notaccessible_file, accessible=False, shuffle=True)"
      ],
      "metadata": {
        "id": "XgfpFLNzU6mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on rest of nonaccessible\n",
        "\n",
        "if DOWNSAMPLE:\n",
        "    # rest_nonacc_dataset = dna_dataset.DNADataset(rest_not_sequences, rest_not_labels)\n",
        "    rest_notacc_loader = torch.utils.data.DataLoader(rest_notacc_dataset, batch_size=batch_size)#, shuffle=True)\n",
        "    # total_preds = torch.empty(0)  # tuples of probability, id\n",
        "    CM = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "    model.eval()\n",
        "    for batch in rest_notacc_loader:  # tqdm()\n",
        "        samples, labels = batch[\"sequence\"].to(device), batch['label']  # know it's all 0 labels\n",
        "        outputs = model(samples)\n",
        "\n",
        "        preds = utils.get_preds(outputs)\n",
        "\n",
        "        total_predictions += len(outputs)\n",
        "\n",
        "        CM += confusion_matrix(labels.cpu().flatten().detach().numpy(), preds.cpu().flatten().detach().numpy())\n",
        "\n",
        "    # Computer accuracy, precision, recall, and f1 metrics\n",
        "    acc_score, precision, recall, f1 = utils.compute_metrics(CM)\n",
        "\n",
        "    print(f\"Rest not Accuracy: {acc_score * 100} %\")\n",
        "    print(f\"Rest not Precision: {precision * 100} %\")\n",
        "    print(f\"Rest not Recall: {recall * 100} %\")\n",
        "    print(f\"Rest not F1 Score: {f1 * 100} %\")\n",
        "\n",
        "    # wandb.summary['rest_nonacc_accuracy'] = acc_score\n",
        "\n",
        "    # wandb.finish()"
      ],
      "metadata": {
        "id": "p7fN6PocVSBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7XLQeg9Rm8"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r pretrained\n",
        "# !rm predictions.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_USYmjft93K",
        "outputId": "ed09515c-5bb6-4705-d014-5b56dbff98cb"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'pretrained': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "aMXK8qqk9Rm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5edf2026-c943-4a3e-8371-c8d9ee2bd38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_save_path pretrained/testBCElogits if same thresholdsklearn type loss01-07-20-58-33-CNNModel-model-0.0001lr-20epochs.pt\n",
            "model saved at 01-07-20-58-33\n"
          ]
        }
      ],
      "source": [
        "# Create pretrained directory if not yet created\n",
        "if not os.path.isdir(PRETRAINED_DIR):\n",
        "    os.mkdir(PRETRAINED_DIR)\n",
        "\n",
        "now = datetime.now()\n",
        "datetime_str = now.strftime(\"%m-%d-%H-%M-%S\")\n",
        "model_save_path = os.path.join(\n",
        "    PRETRAINED_DIR,\n",
        "    f'{note}{datetime_str}-{model.__class__.__name__}-model-{learning_rate}lr-{epochs}epochs.pt'\n",
        ")\n",
        "print('model_save_path', model_save_path)\n",
        "\n",
        "CNNModel.save_CNNModel(model_save_path, CNN)  # model\n",
        "print(f\"model saved at {datetime_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GFj5Dc9Rm8"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwvJ7kqk9Rm8"
      },
      "outputs": [],
      "source": [
        "# Add the new path\n",
        "model_save_path = \"\"\n",
        "model = CNNModel.load_CNNModel(model_save_path)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gWP9UWn9Rm9"
      },
      "source": [
        "Inference on Competition File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "apmvzG7E9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67282de6-24c4-4e91-dd02-ccf12386194b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Competitation Data\n",
        "# Set shuffle=False to save time, unnecessary for comp file\n",
        "comp_sequences, _, comp_ids = dna_dataset.read_data_file(comp_file, labeled=False, shuffle=False)\n",
        "competition_dataset = dna_dataset.DNADataset(comp_sequences, comp_ids, comp=True)\n",
        "competition_loader = torch.utils.data.DataLoader(competition_dataset, batch_size=batch_size)\n",
        "print(\"Competition dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "9qT3UBun9Rm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ccb3c4-cf81-4d52-a10b-b6159882a1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished inference\n"
          ]
        }
      ],
      "source": [
        "probs = []  # tuples of probability, id\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "model.eval()\n",
        "for batch in competition_loader:  # tqdm()\n",
        "    samples, ids = batch[\"sequence\"].to(device), batch['id']  # not a tensor\n",
        "    outputs = model(samples)\n",
        "\n",
        "    if loss_fn.__class__.__name__ == \"BCEWithLogitsLoss\":\n",
        "      outputs = sigmoid(outputs)\n",
        "\n",
        "    try:\n",
        "        assert(len(outputs[outputs>1]) == 0 and len(outputs[outputs<0]) == 0)  # ensure all probs are [0,1]\n",
        "    except:\n",
        "        placeholder = 0\n",
        "        # print(outputs[outputs>1][0])\n",
        "        # print(outputs[outputs<0][0])\n",
        "\n",
        "    out_list = outputs.tolist()\n",
        "    for i in range(len(out_list)):\n",
        "        probs.append((out_list[i], ids[i]))\n",
        "\n",
        "print(\"Finished inference\")\n",
        "\n",
        "# print(np_probs[np_probs>0.0 and np_probs<1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the results\n",
        "np_probs = np.array(list(zip(*probs))[0])\n",
        "not_probs = np_probs[np_probs<=0.7]\n",
        "not_probs.sort()\n",
        "acc_probs = np_probs[np_probs>0.7]\n",
        "print(\"Predicted\", len(acc_probs), \"true values out of \", len(np_probs), \" total\", len(acc_probs) * 100 / len(np_probs), \"percent\")\n",
        "print(f\"Note: 10,000 / {len(competition_dataset)} is {10000 / len(competition_dataset):.4f}\")\n",
        "acc_probs[::-1].sort()\n",
        "print()\n",
        "print(\"not accessible probs\", not_probs)\n",
        "print(\"accessible probs\", acc_probs)\n",
        "assert(len(np_probs[np_probs>1]) == 0 and len(np_probs[np_probs<0]) == 0)  # ensure all probs are [0,1]\n",
        "\n",
        "print()\n",
        "\n",
        "probs.sort(reverse=True)\n",
        "print(\"first 10\\n\", list(zip(*probs[:10]))[0])\n",
        "print(\"last 10 of top 10000\\n\", list(zip(*probs[9990:10000]))[0])  # probs only\n",
        "\n",
        "highest_probs = probs[:10000]  # top 10,000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK_U9F9_M1mB",
        "outputId": "cd8ca203-1008-4f77-dcb0-b3bd73d5607e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 50718 true values out of  269315  total 18.83222249039229 percent\n",
            "Note: 10,000 / 269315 is 0.0371\n",
            "\n",
            "not accessible probs [6.06939238e-07 8.41556925e-07 9.11698066e-07 ... 6.99969590e-01\n",
            " 6.99984312e-01 6.99985087e-01]\n",
            "accessible probs [0.99852079 0.99639672 0.99634796 ... 0.70001477 0.70001328 0.70000458]\n",
            "\n",
            "first 10\n",
            " ([0.9985207915306091], [0.9963967204093933], [0.996347963809967], [0.9957489967346191], [0.9950012564659119], [0.9948647618293762], [0.9946529865264893], [0.9945916533470154], [0.9945886135101318], [0.9945071339607239])\n",
            "last 10 of top 10000\n",
            " ([0.8886889815330505], [0.8886885046958923], [0.8886776566505432], [0.8886751532554626], [0.8886736035346985], [0.8886717557907104], [0.8886685371398926], [0.8886619210243225], [0.8886516094207764], [0.8886155486106873])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "FG7R8WVS9Rm9"
      },
      "outputs": [],
      "source": [
        "with open(SOLUTION_FILE, \"w\") as f:\n",
        "    for pair in highest_probs:\n",
        "        f.write(pair[1])\n",
        "        # f.write(\"a\")\n",
        "        f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW_tShqO9tN",
        "outputId": "983bc37d-bd9e-4f1c-8160-c912f6877e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: predictions.csv (deflated 65%)\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = \"predictions.zip\"\n",
        "!zip $zip_file_name $SOLUTION_FILE\n",
        "!rm $SOLUTION_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wbEhngYS9Rm9",
        "outputId": "025b7062-444a-4f43-cdd7-e1164b01475d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f339813-8796-4dd4-b203-93df9a223f02\", \"testBCElogits if same thresholdsklearn type loss01-07-20-58-33-CNNModel-model-0.0001lr-20epochs.pt\", 1759793)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ONLY for use on google colab. download files\n",
        "from google.colab import files\n",
        "import os\n",
        "model_file = os.path.join(PRETRAINED_DIR, os.listdir(PRETRAINED_DIR)[0])\n",
        "files.download(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-n5ZovGlABTe",
        "outputId": "cc73ba08-2f2e-48c7-ad45-9c610a675ebd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30e54087-3121-4a77-9444-91b8fe4a889c\", \"predictions.zip\", 33513)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7I-thUcFlTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76eae67e149f4fe68abf7ce209710062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ad84c6943054951b76bff6b8e5b31f8",
              "IPY_MODEL_3c02488721bf42718400a240ecb5d107"
            ],
            "layout": "IPY_MODEL_762fd05492d64081b843033410d192ed"
          }
        },
        "3ad84c6943054951b76bff6b8e5b31f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde48c654e024d8c9e2f25fa6446dab8",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd0498c01f44107b6b398de889afbc1",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "3c02488721bf42718400a240ecb5d107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057ad36ca9d14b998661c31242b734df",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5eb46da944e4309878716a5b8ac88e2",
            "value": 1
          }
        },
        "762fd05492d64081b843033410d192ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde48c654e024d8c9e2f25fa6446dab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd0498c01f44107b6b398de889afbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "057ad36ca9d14b998661c31242b734df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5eb46da944e4309878716a5b8ac88e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}